<?xml version="1.0" encoding="UTF-8" standalone="no"?><html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Four. Graphs</title>
<link href="9780132762564.css" rel="stylesheet" type="text/css"/>
<link href="page-template.xpgt" rel="stylesheet" type="application/vnd.adobe-page-template+xml"/>
<meta name="Adept.resource" value="urn:uuid:7baf5dbb-ffe1-4201-87bd-b993ed04f947"/>
</head>
<body>
<p><a id="ch04"/></p>
<h2><a id="page_514"/>Four. Graphs</h2>
<div class="sidebar">
<hr/>
<p><a id="ch04sb01"/></p>
<p class="indenthangingN"><strong><a href="#ch04sec1lev10">4.1</a></strong> <a href="#ch04sec1lev10">Undirected Graphs</a> <a href="#ch04sec1lev10">518</a></p>
<p class="indenthangingN"><strong><a href="#ch04sec1lev11">4.2</a></strong> <a href="#ch04sec1lev11">Directed Graphs</a> <a href="#ch04sec1lev11">566</a></p>
<p class="indenthangingN"><strong><a href="#ch04sec1lev12">4.3</a></strong> <a href="#ch04sec1lev12">Minimum Spanning Trees</a> <a href="#ch04sec1lev12">604</a></p>
<p class="indenthangingN"><strong><a href="ch04a.html#ch04sec1lev13">4.4</a></strong> <a href="ch04a.html#ch04sec1lev13">Shortest Paths</a> <a href="ch04a.html#ch04sec1lev13">638</a></p>
<hr/>
</div>
<p><a id="page_515"/>Pairwise connections between items play a critical role in a vast array of computational applications. The relationships implied by these connections lead immediately to a host of natural questions: Is there a way to connect one item to another by following the connections? How many other items are connected to a given item? What is the shortest chain of connections between this item and this other item?</p>
<p>To model such situations, we use abstract mathematical objects called <em>graphs</em>. In this chapter, we examine basic properties of graphs in detail, setting the stage for us to study a variety of algorithms that are useful for answering questions of the type just posed. These algorithms serve as the basis for attacking problems in important applications whose solution we could not even contemplate without good algorithmic technology.</p>
<p>Graph theory, a major branch of mathematics, has been studied intensively for hundreds of years. Many important and useful properties of graphs have been discovered, many important algorithms have been developed, and many difficult problems are still actively being studied. In this chapter, we introduce a variety of fundamental graph algorithms that are important in diverse applications.</p>
<p>Like so many of the other problem domains that we have studied, the algorithmic investigation of graphs is relatively recent. Although a few of the fundamental algorithms are centuries old, the majority of the interesting ones have been discovered within the last several decades and have benefited from the emergence of the algorithmic technology that we have been studying. Even the simplest graph algorithms lead to useful computer programs, and the nontrivial algorithms that we examine are among the most elegant and interesting algorithms known.</p>
<p>To illustrate the diversity of applications that involve graph processing, we begin our exploration of algorithms in this fertile area by introducing several examples.</p>
<p><a id="ch04sec1lev1"/></p>
<h4><a id="page_516"/><em>Maps</em></h4>
<p>A person who is planning a trip may need to answer questions such as “What is the shortest route from Providence to Princeton?” A seasoned traveler who has experienced traffic delays on the shortest route may ask the question “What is the fastest way to get from Providence to Princeton?” To answer such questions, we process information about connections (roads) between items (intersections).</p>
<p><a id="ch04sec1lev2"/></p>
<h4><em>Web content</em></h4>
<p>When we browse the web, we encounter pages that contain references (links) to other pages and we move from page to page by clicking on the links. The entire web is a graph, where the items are pages and the connections are links. Graph-processing algorithms are essential components of the search engines that help us locate information on the web.</p>
<p><a id="ch04sec1lev3"/></p>
<h4><em>Circuits</em></h4>
<p>An electric circuit comprises devices such as transistors, resistors, and capacitors that are intricately wired together. We use computers to control machines that make circuits and to check that the circuits perform desired functions. We need to answer simple questions such as “Is a short-circuit present?” as well as complicated questions such as “Can we lay out this circuit on a chip without making any wires cross?” The answer to the first question depends on only the properties of the connections (wires), whereas the answer to the second question requires detailed information about the wires, the devices that those wires connect, and the physical constraints of the chip.</p>
<p><a id="ch04sec1lev4"/></p>
<h4><em>Schedules</em></h4>
<p>A manufacturing process requires a variety of jobs to be performed, under a set of constraints that specify that certain tasks cannot be started until certain other tasks have been completed. How do we schedule the tasks such that we both respect the given constraints and complete the whole process in the least amount of time?</p>
<p><a id="ch04sec1lev5"/></p>
<h4><em>Commerce</em></h4>
<p>Retailers and financial instututions track buy/sell orders in a market. A connection in this situation represents the transfer of cash and goods between an institution and a customer. Knowledge of the nature of the connection structure in this instance may enhance our understanding of the nature of the market.</p>
<p><a id="ch04sec1lev6"/></p>
<h4><em>Matching</em></h4>
<p>Students apply for positions in selective institutions such as social clubs, universities, or medical schools. Items correspond to the students and the institutions; connections correspond to the applications. We want to discover methods for matching interested students with available positions.</p>
<p><a id="ch04sec1lev7"/></p>
<h4><em>Computer networks</em></h4>
<p>A computer network consists of interconnected sites that send, forward, and receive messages of various types. We are interested in knowing about the nature of the interconnection structure because we want to lay wires and build switches that can handle the traffic efficiently.</p>
<p><a id="ch04sec1lev8"/></p>
<h4><a id="page_517"/><em>Software</em></h4>
<p>A compiler builds graphs to represent relationships among modules in a large software system. The items are the various classes or modules that comprise the system; connections are associated either with the possibility that a method in one class might call another (static analysis) or with actual calls while the system is in operation (dynamic analysis). We need to analyze the graph to determine how best to allocate resources to the program most efficiently.</p>
<p><a id="ch04sec1lev9"/></p>
<h4><em>Social networks</em></h4>
<p>When you use a social network, you build explicit connections with your friends. Items correspond to people; connections are to friends or followers. Understanding the properties of these networks is a modern graph-processing applications of intense interest not just to compaines that support such networks, but also in politics, diplomacy, entertainment, education, marketing, and many other domains.</p>
<p><small>THESE EXAMPLES INDICATE THE RANGE OF APPLICATIONS</small> for which graphs are the appropriate abstraction and also the range of computational problems that we might encounter when we work with graphs. Thousands of such problems have been studied, but many problems can be addressed in the context of one of several basic graph models—we will study the most important ones in this chapter. In practical applications, it is common for the volume of data involved to be truly huge, so that efficient algorithms make the difference between whether or not a solution is at all feasible.</p>
<p class="image"><img alt="image" src="graphics/t0517-01.jpg"/></p>
<p>To organize the presentation, we progress through the four most important types of graph models: <em>undirected graphs</em> (with simple connections), <em>digraphs</em> (where the direction of each connection is significant), <em>edge-weighted graphs</em> (where each connection has an associated weight), and <em>edge-weighted digraphs</em> (where each connection has both a direction and a weight).</p>
<p><a id="ch04sec1lev10"/></p>
<h3><a id="page_518"/>4.1 Undirected Graphs</h3>
<p><small>OUR STARTING POINT</small> is the study of graph models where <em>edges</em> are nothing more than connections between <em>vertices</em>. We use the term <em>undirected graph</em> in contexts where we need to distinguish this model from other models (such as the title of this section), but, since this is the simplest model, we start with the following definition:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb02"/></p>
<p><strong>Definition.</strong> A <em>graph</em> is a set of <em>vertices</em> and a collection of <em>edges</em> that each connect a pair of vertices.</p>
<hr/>
</div>
<p>Vertex names are not important to the definition, but we need a way to refer to vertices. By convention, we use the names 0 through <em>V</em>−1 for the vertices in a <em>V</em>-vertex graph. The main reason that we choose this system is to make it easy to write code that efficiently accesses information corresponding to each vertex, using array indexing. It is not difficult to use a symbol table to establish a 1-1 mapping to associate <em>V</em> arbitrary vertex names with the <em>V</em> integers between 0 and <em>V</em>−1 (see page <a href="#page_548">548</a>), so the convenience of using indices as vertex names comes without loss of generality (and without much loss of efficiency). We use the notation <code>v-w</code> to refer to an edge that connects <code>v</code> and <code>w</code>; the notation <code>w-v</code> is an alternate way to refer to the same edge.</p>
<p class="image"><img alt="image" src="graphics/04_01-tinyg.jpg"/></p>
<p>We draw a graph with circles for the vertices and lines connecting them for the edges. A drawing gives us intuition about the structure of the graph; but this intuition can be misleading, because the graph is defined independently of the drawing. For example, the two drawings at left represent the same graph, because the graph is nothing more than its (unordered) set of vertices and its (unordered) collection of edges (vertex pairs).</p>
<p><a id="ch04sec2lev1"/></p>
<h4><em>Anomalies</em></h4>
<p>Our definition allows two simple anomalies:</p>
<p class="indenthangingB">• A <em>self-loop</em> is an edge that connects a vertex to itself.</p>
<p class="indenthangingB">• Two edges that connect the same pair of vertices are <em>parallel.</em></p>
<p class="image"><img alt="image" src="graphics/04_02-anomalies.jpg"/></p>
<p>Mathematicians sometimes refer to graphs with parallel edges as <em>multigraphs</em> and graphs with no parallel edges or self-loops as <em>simple</em> graphs. Typically, our implementations allow self-loops and parallel edges (because they arise in applications), but we do not include them in examples. Thus, we can refer to every edge just by naming the two vertices it connects.</p>
<p><a id="ch04sec2lev2"/></p>
<h4><a id="page_519"/>Glossary</h4>
<p>A substantial amount of nomenclature is associated with graphs. Most of the terms have straightforward definitions, and, for reference, we consider them in one place: here.</p>
<p>When there is an edge connecting two vertices, we say that the vertices are <em>adjacent to</em> one another and that the edge is <em>incident to</em> both vertices. The <em>degree</em> of a vertex is the number of edges incident to it. A <em>subgraph</em> is a subset of a graph’s edges (and associated vertices) that constitutes a graph. Many computational tasks involve identifying subgraphs of various types. Of particular interest are edges that take us through a <em>sequence</em> of vertices in a graph.</p>
<p class="image"><img alt="image" src="graphics/04_03-anatomyg.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb03"/></p>
<p><strong>Definition.</strong> A <em>path</em> in a graph is a sequence of vertices connected by edges. A <em>simple path</em> is one with no repeated vertices. A <em>cycle</em> is a path with at least one edge whose first and last vertices are the same. A <em>simple cycle</em> is a cycle with no repeated edges or vertices (except the requisite repetition of the first and last vertices). The <em>length</em> of a path or a cycle is its number of edges.</p>
<hr/>
</div>
<p>Most often, we work with simple cycles and simple paths and drop the <em>simple</em> modifer; when we want to allow repeated vertices, we refer to <em>general</em> paths and cycles. We say that one vertex is <em>connected to</em> another if there exists a path that contains both of them. We use notation like <code>u-v-w-x</code> to represent a path from <code>u</code> to <code>x</code> and <code>u-v-w-x-u</code> to represent a cycle from <code>u</code> to <code>v</code> to <code>w</code> to <code>x</code> and back to <code>u</code> again. Several of the algorithms that we consider find paths and cycles. Moreover, paths and cycles lead us to consider the structural properties of a graph as a whole:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb04"/></p>
<p><strong>Definition.</strong> A graph is <em>connected</em> if there is a path from every vertex to every other vertex in the graph. A graph that is <em>not connected</em> consists of a set of <em>connected components</em>, which are maximal connected subgraphs.</p>
<hr/>
</div>
<p>Intuitively, if the vertices were physical objects, such as knots or beads, and the edges were physical connections, such as strings or wires, a connected graph would stay in one piece if picked up by any vertex, and a graph that is not connected comprises two or more such pieces. Generally, processing a graph necessitates processing the connected components one at a time.</p>
<p><a id="page_520"/>An <em>acyclic</em> graph is a graph with no cycles. Several of the algorithms that we consider are concerned with finding acyclic subgraphs of a given graph that satisfy certain properties. We need additional terminology to refer to these structures:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb05"/></p>
<p><strong>Definition.</strong> A <em>tree</em> is an acyclic connected graph. A disjoint set of trees is called a <em>forest</em>. A <em>spanning tree</em> of a connected graph is a subgraph that contains all of that graph’s vertices and is a single tree. A <em>spanning forest</em> of a graph is the union of spanning trees of its connected components.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_04-tree.jpg"/></p>
<p>This definition of tree is quite general: with suitable refinements it embraces the trees that we typically use to model program behavior (function-call hierarchies) and data structures (BSTs, 2-3 trees, and so forth). Mathematical properties of trees are well-studied and intuitive, so we state them without proof. For example, a graph <em>G</em> with <em>V</em> vertices is a tree if and only if it satisfies any of the following five conditions:</p>
<p class="indenthangingB">• <em>G</em> has <em>V</em>−1 edges and no cycles.</p>
<p class="indenthangingB">• <em>G</em> has <em>V</em>−1 edges and is connected.</p>
<p class="indenthangingB">• <em>G</em> is connected, but removing any edge disconnects it.</p>
<p class="indenthangingB">• <em>G</em> is acyclic, but adding any edge creates a cycle.</p>
<p class="indenthangingB">• Exactly one simple path connects each pair of vertices in <em>G</em>.</p>
<p>Several of the algorithms that we consider find spanning trees and forests, and these properties play an important role in their analysis and implementation.</p>
<p class="image"><img alt="image" src="graphics/04_05-densesparse.jpg"/></p>
<p>The <em>density</em> of a graph is the proportion of possible pairs of vertices that are connected by edges. A <em>sparse</em> graph has relatively few of the possible edges present; a <em>dense</em> graph has relatively few of the possible edges missing. Generally, we think of a graph as being sparse if its number of different edges is within a small constant factor of <em>V</em> and as being dense otherwise. This rule of thumb <a id="page_521"/>leaves a gray area (when the number of edges is, say, ~ <em>c V</em><sup>3/2</sup>) but the distinction between sparse and dense is typically very clear in applications. The applications that we consider nearly always involve sparse graphs.</p>
<p>A <em>bipartite graph</em> is a graph whose vertices we can divide into two sets such that all edges connect a vertex in one set with a vertex in the other set. The figure at right gives an example of a bipartite graph, where one set of vertices is colored red and the other set of vertices is colored black. Bipartite graphs arise in a natural way in many situations, one of which we will consider in detail at the end of this section.</p>
<p class="image"><img alt="image" src="graphics/04_06-tinyb.jpg"/></p>
<p><small>WITH THESE PREPARATIONS</small>, we are ready to move on to consider graph-processing algorithms. We begin by considering an API and implementation for a graph data type, then we consider classic algorithms for searching graphs and for identifying connected components. To conclude the section, we consider real-world applications where vertex names need not be integers and graphs may have huge numbers of vertices and edges.</p>
<p><a id="ch04sec2lev3"/></p>
<h4><a id="page_522"/>Undirected graph data type</h4>
<p>Our starting point for developing graph-processing algorithms is an API that defines the fundamental graph operations. This scheme allows us to address graph-processing tasks ranging from elementary maintenance operations to sophisticated solutions of difficult problems.</p>
<p class="image"><img alt="image" src="graphics/t0522-01.jpg"/></p>
<p>This API contains two constructors, methods to return the number of vertices and edges, a method to add an edge, a <code>toString()</code> method, and a method <code>adj()</code> that allows client code to iterate through the vertices adjacent to a given vertex (the order of iteration is not specified). Remarkably, we can build all of the algorithms that we consider in this section on the basic abstraction embodied in <code>adj()</code>.</p>
<p>The second constructor assumes an input format consisting of 2<em>E</em> + 2 integer values: <em>V</em>, then <em>E</em>, then <em>E</em> pairs of values between 0 and <em>V</em>−1, each pair denoting an edge. As examples, we use the two graphs <code>tinyG.txt</code> and <code>mediumG.txt</code> that are depicted below.</p>
<p>Several examples of <code>Graph</code> client code are shown in the table on the facing page.</p>
<p class="image"><img alt="image" src="graphics/04_07-informat.jpg"/></p>
<p class="programlisting"><a id="page_523"/><img alt="image" src="graphics/p0523-01.jpg"/></p>
<p class="programlisting"><img alt="image" src="graphics/p0523-02.jpg"/></p>
<p><a id="ch04sec3lev1"/></p>
<h5><a id="page_524"/><em>Representation alternatives</em></h5>
<p>The next decision that we face in graph processing is which graph representation (data structure) to use to implement this API. We have two basic requirements:</p>
<p class="indenthangingB">• We must have the <em>space</em> to accommodate the types of graphs that we are likely to encounter in applications.</p>
<p class="indenthangingB">• We want to develop <em>time</em>-efficient implementations of <code>Graph</code> instance methods—the basic methods that we need to develop graph-processing clients.</p>
<p>These requirements are a bit vague, but they are still helpful in choosing among the three data structures that immediately suggest themselves for representing graphs:</p>
<p class="indenthangingB">• An <em>adjacency matrix</em>, where we maintain a <em>V</em>-by-<em>V</em> boolean array, with the entry in row <code>v</code> and column <code>w</code> defined to be <code>true</code> if there is an edge adjacent to both vertex <code>v</code> and vertex <code>w</code> in the graph, and to be <code>false</code> otherwise. This representation fails on the first count—graphs with millions of vertices are common and the space cost for the <em>V</em><sup>2</sup> boolean values needed is prohibitive.</p>
<p class="indenthangingB">• An <em>array of edges</em>, using an <code>Edge</code> class with two instance variables of type <code>int</code>. This direct representation is simple, but it fails on the second count—implementing <code>adj()</code> would involve examining all the edges in the graph.</p>
<p class="indenthangingB">• An <em>array of adjacency lists</em>, where we maintain a vertex-indexed array of lists of the vertices adjacent to each vertex. This data structure satisfies both requirements for typical applications and is the one that we will use throughout this chapter.</p>
<p class="image"><img alt="image" src="graphics/04_08-graphrepex.jpg"/></p>
<p>Beyond these performance objectives, a detailed examination reveals other considerations that can be important in some applications. For example, allowing parallel edges precludes the use of an adjacency matrix, since the adjacency matrix has no way to represent them.</p>
<p><a id="ch04sec3lev2"/></p>
<h5><a id="page_525"/><em>Adjacency-lists data structure</em></h5>
<p>The standard graph representation for graphs that are not dense is called the <em>adjacency-lists data structure</em>, where we keep track of all the vertices adjacent to each vertex on a linked list that is associated with that vertex. We maintain an array of lists so that, given a vertex, we can immediately access its list. To implement lists, we use our <code>Bag</code> ADT from <a href="ch01a.html#ch01sec1lev5"><small>SECTION 1.3</small></a> with a linked-list implementation, so that we can add new edges in constant time and iterate through adjacent vertices in constant time per adjacent vertex. The <code>Graph</code> implementation on page <a href="#ch04sb06">526</a> is based on this approach, and the figure on the facing page depicts the data structures built by this code for <code>tinyG.txt</code>. To add an edge connecting <code>v</code> and <code>w</code>, we add <code>w</code> to <code>v</code>’s adjacency list and <code>v</code> to <code>w</code>’s adjacency list. Thus, each edge appears <em>twice</em> in the data structure. This <code>Graph</code> implementation achieves the following performance characteristics:</p>
<p class="indenthangingB">• Space usage proportional to <em>V</em> + <em>E</em></p>
<p class="indenthangingB">• Constant time to add an edge</p>
<p class="indenthangingB">• Time proportional to the degree of <code>v</code> to iterate through vertices adjacent to <code>v</code> (constant time per adjacent vertex processed)</p>
<p>These characteristics are optimal for this set of operations, which suffice for the graph-processing applications that we consider. Parallel edges and self-loops are allowed (we do not check for them). <em>Note</em>: It is important to realize that the order in which edges are added to the graph determines the order in which vertices appear in the array of adjacency lists built by <code>Graph</code>. Many different arrays of adjacency lists can represent the same graph. When using the constructor that reads edges from an input stream, this means that the input format and the order in which edges are specified in the file determine the order in which vertices appear in the array of adjacency lists built by <code>Graph</code>. Since our algorithms use <code>adj()</code> and process all adjacent vertices without regard to the order in which they appear in the lists, this difference does not affect their correctness, but it is important to bear it in mind when debugging or following traces. To facilitate these activities, we assume that <code>Graph</code> has a test client that reads a graph from the input stream named as command-line argument and then prints it (relying on the <code>toString()</code> implementation on page <a href="#page_523">523</a>) to show the order in which vertices appear in adjacency lists, which is the order in which algorithms process them (see <a href="#ch04qa1q7"><small>EXERCISE 4.1.7</small></a>).</p>
<p class="image"><img alt="image" src="graphics/04_09-outformatle.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb06"/></p>
<h3><a id="page_526"/>Graph data type</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0526-01.jpg"/></p>
<p>This <code>Graph</code> implementation maintains a vertex-indexed array of lists of integers. Every edge appears twice: if an edge connects <code>v</code> and <code>w</code>, then <code>w</code> appears in <code>v</code>’s list and <code>v</code> appears in <code>w</code>’s list. The second constructor reads a graph from an input stream, in the format <em>V</em> followed by <em>E</em> followed by a list of pairs of <code>int</code> values between 0 and <em>V</em>−1. See page <a href="#page_523">523</a> for <code>toString().</code></p>
<hr/>
</div>
<p><a id="page_527"/><small>IT IS CERTAINLY REASONABLE</small> to contemplate other operations that might be useful in applications, and to consider methods for</p>
<p class="indenthangingB">• Adding a vertex</p>
<p class="indenthangingB">• Deleting a vertex</p>
<p>One way to handle such operations is to expand the API and use a symbol table (<code>ST</code>) instead of a vertex-indexed array (with this change we also do not need our convention that vertex names be integer indices). We might also consider methods for</p>
<p class="indenthangingB">• Deleting an edge</p>
<p class="indenthangingB">• Checking whether the graph contains the edge <code>v-w</code></p>
<p>To implement these two operations (and disallow parallel edges) we might use a <code>SET</code> instead of a <code>Bag</code> for adjacency lists. We refer to this alternative as an <em>adjacency set</em> representation. We do not use either of these two alternatives in this book for several reasons:</p>
<p class="indenthangingB">• Our clients do not need to add vertices, delete vertices and edges, or check whether an edge exists.</p>
<p class="indenthangingB">• When clients do need these operations, they typically are invoked infrequently or for short adjacency lists, so an easy option is to use a brute-force implementation that iterates through an adjacency list.</p>
<p class="indenthangingB">• The <code>SET</code> and <code>ST</code> representations slightly complicate algorithm implementation code, diverting attention from the algorithms themselves.</p>
<p class="indenthangingB">• A performance penalty of log <em>V</em> is involved in some situations.</p>
<p>It is not difficult to adapt our algorithms to accommodate other designs (for example disallowing parallel edges or self-loops) without undue performance penalties. The table below summarizes performance characteristics of the alternatives that we have mentioned. Typical applications process huge sparse graphs, so we use the adjacency-lists representation throughout.</p>
<p class="image"><img alt="image" src="graphics/p0527-01.jpg"/></p>
<p><a id="ch04sec3lev3"/></p>
<h5><a id="page_528"/><em>Design pattern for graph processing</em></h5>
<p>Since we consider a large number of graph-processing algorithms, our initial design goal is to decouple our implementations from the graph representation. To do so, we develop, for each given task, a task-specific class so that clients can create objects to perform the task. Generally, the constructor does some preprocessing to build data structures so as to efficiently respond to client queries. A typical client program builds a graph, passes that graph to an algorithm implementation class (as argument to a constructor), and then calls client query methods to learn various properties of the graph. As a warmup, consider this API:</p>
<p class="image"><img alt="image" src="graphics/p0528-01.jpg"/></p>
<p>We use the term <em>source</em> to distinguish the vertex provided as argument to the constructor from the other vertices in the graph. In this API, the job of the constructor is to find the vertices in the graph that are connected to the source. Then client code calls the instance methods <code>marked()</code> and <code>count()</code> to learn characteristics of the graph. The name <code>marked()</code> refers to an approach used by the basic algorithms that we consider throughout this chapter: they follow paths from the source to other vertices in the graph, marking each vertex encountered. The example client <code>TestSearch</code> shown on the facing page takes an input stream name and a source vertex number from the command line, reads a graph from the input stream (using the second <code>Graph</code> constructor), builds a <code>Search</code> object for the given graph and source, and uses <code>marked()</code> to print the vertices in that graph that are connected to the source. It also calls <code>count()</code> and prints whether or not the graph is connected (the graph is connected if and only if the search marked all of its vertices).</p>
<p><a id="page_529"/><small>WE HAVE ALREADY SEEN</small> one way to implement the <code>Search</code> API: the union-find algorithms of <a href="ch01.html#ch01"><small>CHAPTER 1</small></a>. The constructor can build a <code>UF</code> object, do a <code>union()</code> operation for each of the graph’s edges, and implement <code>marked(v)</code> by calling <code>connected(s, v)</code>. Implementing <code>count()</code> requires using a weighted <code>UF</code> implementation and extending its API to use a <code>count()</code> method that returns <code>wt[find(v)]</code> (see <a href="#ch04qa1q8"><small>EXERCISE 4.1.8</small></a>). This implementation is simple and efficient, but the implementation that we consider next is even simpler and more efficient. It is based on <em>depth-first search</em>, a fundamental recursive method that follows the graph’s edges to find the vertices connected to the source. Depth-first search is the basis for several of the graph-processing algorithms that we consider throughout this chapter.</p>
<p class="image"><img alt="image" src="graphics/p0529-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/p0529-02.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_10-tinygtwo.jpg"/></p>
<p><a id="ch04sec2lev4"/></p>
<h4><a id="page_530"/>Depth-first search</h4>
<p>We often learn properties of a graph by systematically examining each of its vertices and each of its edges. Determining some simple graph properties—for example, computing the degrees of all the vertices—is easy if we just examine each edge (in any order whatever). But many other graph properties are related to paths, so a natural way to learn them is to move from vertex to vertex along the graph’s edges. Nearly all of the graph-processing algorithms that we consider use this same basic abstract model, albeit with various different strategies. The simplest is a classic method that we now consider.</p>
<p class="image"><img alt="image" src="graphics/04_11-maze8.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_12-dfstrace6maze.jpg"/></p>
<p><a id="ch04sec3lev4"/></p>
<h5><em>Searching in a maze</em></h5>
<p>It is instructive to think about the process of searching through a graph in terms of an equivalent problem that has a long and distinguished history—finding our way through a maze that consists of passages connected by intersections. Some mazes can be handled with a simple rule, but most mazes require a more sophisticated strategy. Using the terminology <em>maze</em> instead of <em>graph</em>, <em>passage</em> instead of <em>edge</em>, and <em>intersection</em> instead of <em>vertex</em> is making mere semantic distinctions, but, for the moment, doing so will help to give us an intuitive feel for the problem. One trick for exploring a maze without getting lost that has been known since antiquity (dating back at least to the legend of Theseus and the Minotaur) is known as <em>Tremaux exploration</em>. To explore all passages in a maze:</p>
<p class="indenthangingB">• Take any unmarked passage, unrolling a string behind you.</p>
<p class="indenthangingB">• Mark all intersections and passages when you first visit them.</p>
<p class="indenthangingB">• Retrace steps (using the string) when approaching a marked intersection.</p>
<p class="indenthangingB">• Retrace steps when no unvisited options remain at an intersection encountered while retracing steps.</p>
<p>The string guarantees that you can always find a way out and the marks guarantee that you avoid visiting any passage or intersection twice. Knowing that you have explored the whole maze demands a more complicated argument that is better approached in the context of graph search. Tremaux exploration is an intuitive starting point, but it differs in subtle ways from exploring a graph, so we now move on to searching in graphs.</p>
<p><a id="ch04sec3lev5"/></p>
<h5><a id="page_531"/><em>Warmup</em></h5>
<p>The classic recursive method for searching in a connected graph (visiting all of its vertices and edges) mimics Tremaux maze exploration but is even simpler to describe. To search a graph, invoke a recursive method that visits vertices. To visit a vertex:</p>
<p class="indenthangingB">• Mark it as having been visited.</p>
<p class="indenthangingB">• Visit (recursively) all the vertices that are adjacent to it and that have not yet been marked.</p>
<p class="image"><img alt="image" src="graphics/p0531-01.jpg"/></p>
<p>This method is called <em>depth-first search</em> (DFS). An implementation of our <code>Search</code> API using this method is shown at right. It maintains an array of <code>boolean</code> values to mark all of the vertices that are connected to the source. The recursive method marks the given vertex and calls itself for any unmarked vertices on its adjacency list. If the graph is connected, every adjacency-list entry is checked.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb07"/></p>
<p><strong>Proposition A.</strong> DFS marks all the vertices connected to a given source in time proportional to the sum of their degrees.</p>
<p><strong>Proof:</strong> First, we prove that the algorithm marks all the vertices connected to the source <code>s</code> (and no others). Every marked vertex is connected to <code>s</code>, since the algorithm finds vertices only by following edges. Now, suppose that some unmarked vertex <code>w</code> is connected to <code>s</code>. Since <code>s</code> itself is marked, any path from <code>s</code> to <code>w</code> must have at least one edge from the set of marked vertices to the set of unmarked vertices, say <code>v-x</code>. But the algorithm would have discovered <code>x</code> after marking <code>v</code>, so no such edge can exist, a contradiction. The time bound follows because marking ensures that each vertex is visited once (taking time proportional to its degree to check marks).</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_13-dfsproof.jpg"/></p>
<p><a id="ch04sec3lev6"/></p>
<h5><a id="page_532"/><em>One-way passages.</em></h5>
<p>The method call–return mechanism in the program corresponds to the string in the maze: when we have processed all the edges incident to a vertex (explored all the passages leaving an intersection), we “return” (in both senses of the word). To draw a proper correspondence with Tremaux exploration of a maze, we need to imagine a maze constructed entirely of one-way passages (one in each direction). In the same way that we encounter each passage in the maze twice (once in each direction), we encounter each edge in the graph <em>twice</em> (once at each of its vertices). In Tremaux exploration, we either explore a passage for the first time or return along it from a marked vertex; in DFS of an undirected graph, we either do a recursive call when we encounter an edge <code>v-w</code> (if <code>w</code> is not marked) or skip the edge (if <code>w</code> is marked). The second time that we encounter the edge, in the opposite orientation <code>w-v</code>, we always ignore it, because the destination vertex <code>v</code> has certainly already been visited (the first time that we encountered the edge).</p>
<p class="image"><img alt="image" src="graphics/04_14-graphrepdfsex.jpg"/></p>
<p><a id="ch04sec3lev7"/></p>
<h5><em>Tracing DFS</em></h5>
<p>As usual, one good way to understand an algorithm is to trace its behavior on a small example. This is particularly true of depth-first search. The first thing to bear in mind when doing a trace is that the order in which edges are examined and vertices visited depends upon the <em>representation,</em> not just the graph or the algorithm. Since DFS only examines vertices connected to the source, we use the small connected graph depicted at left as an example for traces. In this example, vertex <code>2</code> is the first vertex visited after <code>0</code> because it happens to be first on <code>0</code>’s adjacency list. The second thing to bear in mind when doing a trace is that, as mentioned above, DFS traverses each edge in the graph twice, always finding a marked vertex the second time. One effect of this observation is that tracing a DFS takes twice as long as you might think! Our example graph has only eight edges, but we need to trace the action of the algorithm on the 16 entries on the adjacency lists.</p>
<p><a id="ch04sec3lev8"/></p>
<h5><a id="page_533"/><em>Detailed trace of depth-first search</em></h5>
<p>The figure at right shows the contents of the data structures just after each vertex is marked for our small example, with source 0. The search begins when the constructor calls the recursive <code>dfs()</code> to mark and visit vertex <code>0</code> and proceeds as follows:</p>
<p class="indenthangingB">• Since <code>2</code> is first on <code>0</code>’s adjacency list and is unmarked, <code>dfs()</code> recursively calls itself to mark and visit <code>2</code> (in effect, the system puts <code>0</code> and the current position on <code>0</code>’s adjacency list on a stack).</p>
<p class="image"><img alt="image" src="graphics/04_15-dfstrace6.jpg"/></p>
<p class="indenthangingB">• Now, <code>0</code> is first on <code>2</code>’s adjacency list and is marked, so <code>dfs()</code> skips it. Then, since <code>1</code> is next on <code>2</code>’s adjacency list and is unmarked, <code>dfs()</code> recursively calls itself to mark and visit <code>1</code>.</p>
<p class="indenthangingB">• Visiting <code>1</code> is different: since both vertices on its list (<code>0</code> and <code>2</code>) are already marked, no recursive calls are needed, and <code>dfs()</code> returns from the recursive call <code>dfs(1)</code>. The next edge examined is <code>2-3</code> (since <code>3</code> is the vertex after <code>1</code> on <code>2</code>’s adjacency list), so <code>dfs()</code> recursively calls itself to mark and visit <code>3</code>.</p>
<p class="indenthangingB">• Vertex <code>5</code> is first on <code>3</code>’s adjacency list and is unmarked, so <code>dfs()</code> recursively calls itself to mark and visit <code>5</code>.</p>
<p class="indenthangingB">• Both vertices on <code>5</code>’s list (<code>3</code> and <code>0</code>) are already marked, so no recursive calls are needed,</p>
<p class="indenthangingB">• Vertex <code>4</code> is next on <code>3</code>’s adjacency list and is unmarked, so <code>dfs()</code> recursively calls itself to mark and visit <code>4</code>, the last vertex to be marked.</p>
<p class="indenthangingB">• After <code>4</code> is marked, <code>dfs()</code> needs to check the vertices on its list, then the remaining vertices on <code>3</code>’s list, then <code>2</code>’s list, then <code>0</code>’s list, but no more recursive calls happen because all vertices are marked.</p>
<p><a id="page_534"/><small>THIS BASIC RECURSIVE SCHEME IS JUST A START</small>—depth-first search is effective for many graph-processing tasks. For example, in this section, we consider the use of depth-first search to address a problem that we first posed in <a href="ch01.html#ch01"><small>CHAPTER 1</small></a>:</p>
<p class="indenthanging"><strong><em>Connectivity.</em></strong> Given a graph, support queries of the form <em>Are two given vertices connected</em>? and <em>How many connected components does the graph have</em>?</p>
<p>This problem is easily solved within our standard graph-processing design pattern, and we will compare and contrast this solution with the union-find algorithms that we considered in <a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a>.</p>
<p>The question “Are two given vertices connected?” is equivalent to the question “Is there a path connecting two given vertices?” and might be named the <em>path detection</em> problem. However, the union-find data structures that we considered in <a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a> do not address the problems of <em>finding</em> such a path. Depth-first search is the first of several approaches that we consider to solve this problem, as well:</p>
<p class="indenthanging"><strong><em>Single-source paths.</em></strong> Given a graph and a source vertex <code>s</code>, support queries of the form <em>Is there a path from</em> <code>s</code> <em>to a given target vertex</em> <code>v</code>? <em>If so, find such a path.</em></p>
<p>DFS is deceptively simple because it is based on a familiar concept and is so easy to implement; in fact, it is a subtle and powerful algorithm that researchers have learned to put to use to solve numerous difficult problems. These two are the first of several that we will consider.</p>
<p><a id="ch04sec2lev5"/></p>
<h4><a id="page_535"/>Finding paths</h4>
<p>The single-source paths problem is fundamental to graph processing. In accordance with our standard design pattern, we use the following API:</p>
<p class="image"><img alt="image" src="graphics/p0535-01.jpg"/></p>
<p>The constructor takes a source vertex <code>s</code> as argument and computes paths from <code>s</code> to each vertex connected to <code>s</code>. After creating a <code>Paths</code> object for a source <code>s</code>, the client can use the instance method <code>pathTo()</code> to iterate through the vertices on a path from <code>s</code> to any vertex connected to <code>s</code>. For the moment, we accept any path; later, we shall develop implementations that find paths having certain properties. The test client at right takes a graph from the input stream and a source from the command line and prints a path from the source to each vertex connected to it.</p>
<p class="image"><img alt="image" src="graphics/p0535-02.jpg"/></p>
<p><a id="ch04sec3lev9"/></p>
<h5><em>Implementation</em></h5>
<p><a href="#ch04sb08"><small>ALGORITHM 4.1</small></a> on page <a href="#ch04sb08">536</a> is a DFS-based implementation of <code>Paths</code> that extends the <code>DepthFirstSearch</code> warmup on page <a href="#page_531">531</a> by adding as an instance variable an array <code>edgeTo[]</code> of <code>int</code> values that serves the purpose of the ball of string in Tremaux exploration: it gives a way to find a path back to <code>s</code> for every vertex connected to <code>s</code>. Instead of just keeping track of the path from the current vertex back to the start, we remember a path from <em>each</em> vertex to the start. To accomplish this, we remember the edge <code>v-w</code> that takes us to each vertex <code>w</code> <em>for the first time,</em> by setting <code>edgeTo[w]</code> to <code>v</code>. In other words, <code>v-w</code> is the last edge on the known path from <code>s</code> to <code>w</code>. The result of the search is a tree rooted at the source; <code>edgeTo[]</code> is a parent-link representation of that tree. A small example is drawn to <a id="page_537"/>the right of the code in <a href="#ch04sb08"><small>ALGORITHM 4.1</small></a>. To recover the path from <code>s</code> to any vertex <code>v</code>, the <code>pathTo()</code> method in <a href="#ch04sb08"><small>ALGORITHM 4.1</small></a> uses a variable <code>x</code> to travel up the tree, setting <code>x</code> to <code>edgeTo[x]</code>, just as we did for union-find in <a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a>, putting each vertex encountered onto a stack until reaching <code>s</code>. Returning the stack to the client as an <code>Iterable</code> enables the client to follow the path from <code>s</code> to <code>v</code>.</p>
<p class="image"><img alt="image" src="graphics/p0535-03.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb08"/></p>
<h3><a id="page_536"/>Algorithm 4.1 Depth-first search to find paths in a graph</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0536-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_16-dfstinypath.jpg"/></p>
<p>This <code>Graph</code> client uses depth-first search to find paths to all the vertices in a graph that are connected to a given start vertex <code>s</code>. Code from <code>DepthFirstSearch</code> (page <a href="#page_531">531</a>) is printed in gray. To save known paths to each vertex, this code maintains a vertex-indexed array <code>edgeTo[]</code> such that <code>edgeTo[w] = v</code> means that <code>v-w</code> was the edge used to access <code>w</code> for the first time. The <code>edgeTo[]</code> array is a parent-link representation of a tree rooted at <code>s</code> that contains all the vertices connected to <code>s</code>.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_17-dfstrace6paths.jpg"/></p>
<p><a id="ch04sec3lev10"/></p>
<h5><em>Detailed trace</em></h5>
<p>The figure at right shows the contents of <code>edgeTo[]</code> just after each vertex is marked for our example, with source <code>0</code>. The contents of <code>marked[]</code> and <code>adj[]</code> are the same as in the trace of <code>DepthFirstSearch</code> on page <a href="#page_533">533</a>, as is the detailed description of the recursive calls and the edges checked, so these aspects of the trace are omitted. The depth-first search adds the edges <code>0-2</code>, <code>2-1</code>, <code>2-3</code>, <code>3-5</code>, and <code>3-4</code> to <code>edgeTo[]</code>, in that order. These edges form a tree rooted at the source and provide the information needed for <code>pathTo()</code> to provide for the client the path from <code>0</code> to <code>1</code>, <code>2</code>, <code>3</code>, <code>4</code>, or <code>5</code>, as just described.</p>
<p><small>THE CONSTRUCTOR</small> in <code>DepthFirstPaths</code> differs only in a few assignment statements from the constructor in <code>DepthFirstSearch</code>, so <a href="#ch04sb07"><small>PROPOSITION A</small></a> on page <a href="#ch04sb07">531</a> applies. In addition, we have:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb09"/></p>
<p><strong>Proposition A (continued).</strong> DFS allows us to provide clients with a path from a given source to any marked vertex in time proportional its length.</p>
<p><strong>Proof:</strong> By induction on the number of vertices visited, it follows that the <code>edgeTo[]</code> array in <code>DepthFirstPaths</code> represents a tree rooted at the source. The <code>pathTo()</code> method builds the path in time proportional to its length.</p>
<hr/>
</div>
<p><a id="ch04sec2lev6"/></p>
<h4><a id="page_538"/>Breadth-first search</h4>
<p>The paths discovered by depth-first search depend not just on the graph, but also on the representation and the nature of the recursion. Naturally, we are often interested in solving the following problem:</p>
<p class="indenthanging"><strong><em>Single-source shortest paths.</em></strong> Given a graph and a source vertex <code>s</code>, support queries of the form <em>Is there a path from</em> <code>s</code> <em>to a given target vertex</em> <code>v</code>? If so, find a <em>shortest</em> such path (one with a minimal number of edges).</p>
<p>The classical method for accomplishing this task, called <em>breadth-first search</em> (BFS), is also the basis of numerous algorithms for processing graphs, so we consider it in detail in this section. DFS offers us little assistance in solving this problem, because the order in which it takes us through the graph has no relationship to the goal of finding shortest paths. In contrast, BFS is based on this goal. To find a shortest path from <code>s</code> to <code>v</code>, we start at <code>s</code> and check for <code>v</code> among all the vertices that we can reach by following one edge, then we check for <code>v</code> among all the vertices that we can reach from <code>s</code> by following two edges, and so forth. DFS is analogous to one person exploring a maze. BFS is analogous to a group of searchers exploring by fanning out in all directions, each unrolling his or her own ball of string. When more than one passage needs to be explored, we imagine that the searchers split up to expore all of them; when two groups of searchers meet up, they join forces (using the ball of string held by the one getting there first).</p>
<p class="image"><img alt="image" src="graphics/04_18-bfstrace6maze.jpg"/></p>
<p>In a program, when we come to a point during a graph search where we have more than one edge to traverse, we choose one and save the others to be explored later. In DFS, we use a pushdown stack (that is managed by the system to support the recursive search method) for this purpose. Using the LIFO rule that characterizes the pushdown stack corresponds to exploring passages that are close by in a maze. We choose, of the passages yet to be explored, the one that was most recently encountered. In BFS, we want to explore the vertices in order of their distance from the source. It turns out that this order is easily arranged: use a (FIFO) queue instead of a (LIFO) stack. We choose, of the passages yet to be explored, the one that was least recently encountered.</p>
<p><a id="ch04sec3lev11"/></p>
<h5><em>Implementation</em></h5>
<p><a href="#ch04sb10"><small>ALGORITHM 4.2</small></a> on page <a href="#ch04sb10">540</a> is an implementation of BFS. It is based on maintaining a queue of all vertices that have been marked but whose adjacency lists have not been checked. We put the source vertex on the queue, then perform the following steps until the queue is empty:</p>
<p class="indenthangingB">• Take the next vertex <code>v</code> from the queue and mark it.</p>
<p class="indenthangingB">• Put onto the queue all unmarked vertices that are adjacent to <code>v</code>.</p>
<p><a id="page_539"/>The <code>bfs()</code> method in <a href="#ch04sb10"><small>ALGORITHM 4.2</small></a> is <em>not</em> recursive. Instead of the implicit stack provided by recursion, it uses an explicit queue. The product of the search, as for DFS, is an array <code>edgeTo[]</code>, a parent-link representation of a tree rooted at <code>s</code>, which defines the shortest paths from <code>s</code> to every vertex that is connected to <code>s</code>. The paths can be constructed for the client using the same <code>pathTo()</code> implementation that we used for DFS in <a href="#ch04sb08"><small>ALGORITHM 4.1</small></a>.</p>
<p class="image"><img alt="image" src="graphics/04_20-bfstinypath.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_21-bfstrace6.jpg"/></p>
<p>The figure at right shows the step-by-step development of BFS on our sample graph, showing the contents of the data structures at the beginning of each iteration of the loop. Vertex <code>0</code> is put on the queue, then the loop completes the search as follows:</p>
<p class="indenthangingB">• Removes <code>0</code> from the queue and puts its adjacent vertices <code>2</code>, <code>1</code>, and <code>5</code> on the queue, marking each and setting the <code>edgeTo[]</code> entry for each to <code>0</code>.</p>
<p class="indenthangingB">• Removes <code>2</code> from the queue, checks its adjacent vertices <code>0</code> and <code>1</code>, which are marked, and puts its adjacent vertices <code>3</code> and <code>4</code> on the queue, marking each and setting the <code>edgeTo[]</code> entry for each to <code>2</code>.</p>
<p class="indenthangingB">• Removes <code>1</code> from the queue and checks its adjacent vertices <code>0</code> and <code>2</code>, which are marked.</p>
<p class="indenthangingB">• Removes <code>5</code> from the queue and checks its adjacent vertices <code>3</code> and <code>0</code>, which are marked.</p>
<p class="indenthangingB">• Removes <code>3</code> from the queue and checks its adjacent vertices <code>5</code>, <code>4</code>, and <code>2</code>, which are marked.</p>
<p class="indenthangingB">• Removes <code>4</code> from the queue and checks its adjacent vertices <code>3</code> and <code>2</code>, which are marked.</p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb10"/></p>
<h3><a id="page_540"/>Algorithm 4.2 Breadth-first search to find paths in a graph</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0540-01.jpg"/></p>
<p>This <code>Graph</code> client uses breadth-first search to find paths in a graph with the fewest number of edges from the source <code>s</code> given in the constructor. The <code>bfs()</code> method marks all vertices connected to <code>s</code>, so clients can use <code>hasPathTo()</code> to determine whether a given vertex <code>v</code> is connected to <code>s</code> and <code>pathTo()</code> to get a path from <code>s</code> to <code>v</code> with the property that no other such path from <code>s</code> to <code>v</code> has fewer edges.</p>
<hr/>
</div>
<p><a id="page_541"/>For this example, the <code>edgeTo[]</code> array is complete after the second step. As with DFS, once all vertices have been marked, the rest of the computation is just checking edges to vertices that have already been marked.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb11"/></p>
<p><strong>Proposition B.</strong> For any vertex <code>v</code> reachable from <code>s</code>, BFS computes a shortest path from <code>s</code> to <code>v</code> (no path from <code>s</code> to <code>v</code> has fewer edges).</p>
<p><strong>Proof:</strong> It is easy to prove by induction that the queue always consists of zero or more vertices of distance <em>k</em> from the source, followed by zero or more vertices of distance <em>k</em>+1 from the source, for some integer <em>k</em>, starting with <em>k</em> equal to 0. This property implies, in particular, that vertices enter and leave the queue in order of their distance from <code>s</code>. When a vertex <code>v</code> enters the queue, no shorter path to <code>v</code> will be found before it comes off the queue, and no path to <code>v</code> that is discovered after it comes off the queue can be shorter than <code>v</code>’s tree path length.</p>
<hr/>
</div>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb12"/></p>
<p><strong>Proposition B (continued).</strong> BFS takes time proportional to <em>V</em>+<em>E</em> in the worst case.</p>
<p><strong>Proof:</strong> As for <a href="#ch04sb07"><small>PROPOSITION A</small></a> (page <a href="#ch04sb07">531</a>), BFS marks all the vertices connected to <code>s</code> in time proportional to the sum of their degrees. If the graph is connected, this sum is the sum of the degrees of all the vertices, or 2<em>E</em>.</p>
<hr/>
</div>
<p>Note that we can also use BFS to implement the <code>Search</code> API that we implemented with DFS, since the solution depends on only the ability of the search to examine every vertex and edge connected to the source.</p>
<p>As implied at the outset, DFS and BFS are the first of several instances that we will examine of a general approach to searching graphs. We put the source vertex on the data structure, then perform the following steps until the data structure is empty:</p>
<p class="indenthangingB">• Take the next vertex <code>v</code> from the data structure and mark it.</p>
<p class="indenthangingB">• Put onto the data structure all unmarked vertices that are adjacent to <code>v</code>.</p>
<p>The algorithms differ only in the rule used to take the next vertex from the data structure (least recently added for BFS, most recently added for DFS). This difference leads to completely different views of the graph, even though all the vertices and edges connected to the source are examined no matter what rule is used.</p>
<p class="image"><img alt="image" src="graphics/p0541-01.jpg"/></p>
<p><a id="page_542"/><small>THE DIAGRAMS ON EITHER SIDE</small> of this page, which show the progress of DFS and BFS for our sample graph <code>mediumG.txt</code>, make plain the differences between the paths that are discovered by the two approaches. DFS wends its way through the graph, storing on the stack the points where other paths branch off; BFS sweeps through the graph, using a queue to remember the frontier of visited places. DFS explores the graph by looking for new vertices far away from the start point, taking closer vertices only when dead ends are encountered; BFS completely covers the area close to the starting point, moving farther away only when everything nearby has been examined. DFS paths tend to be long and winding; BFS paths are short and direct. Depending upon the application, one property or the other may be desirable (or properties of paths may be immaterial). In <a href="ch04a.html#ch04sec1lev13"><small>SECTION 4.4</small></a>, we will be considering other implementations of the <code>Paths</code> API that find paths having other specified properties.</p>
<p class="image"><img alt="image" src="graphics/04_22-dfstrace250.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_23-bellmanfordtrace250.jpg"/></p>
<p><a id="ch04sec2lev7"/></p>
<h4><a id="page_543"/>Connected components</h4>
<p>Our next direct application of depth-first search is to find the connected components of a graph. Recall from <a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a> (see page <a href="ch01a.html#ch01sec1lev7">216</a>) that “is connected to” is an <em>equivalence relation</em> that divides the vertices into <em>equivalence classes</em> (the connected components). For this common graph-processing task, we define the following API:</p>
<p class="image"><img alt="image" src="graphics/p0543-01.jpg"/></p>
<p>The <code>id()</code> method is for client use in indexing an array by component, as in the test client below, which reads a graph and then prints its number of connected components and then the vertices in each component, one component per line. To do so, it builds an array of <code>Bag</code> objects, then uses each vertex’s component identifier as an index into this array, to add the vertex to the appropriate <code>Bag</code>. This client is a model for the typical situation where we want to independently process connected components.</p>
<p class="image"><img alt="image" src="graphics/p0543-02.jpg"/></p>
<p><a id="ch04sec3lev12"/></p>
<h5><em>Implementation</em></h5>
<p>The implementation <code>CC</code> (<a href="#ch04sb13"><small>ALGORITHM 4.3</small></a> on the next page) uses our <code>marked[]</code> array to find a vertex to serve as the starting point for a depth-first search in each component. The first call to the recursive DFS is for vertex <code>0</code>—it marks all vertices connected to <code>0</code>. Then the <code>for</code> loop in the constructor looks for an unmarked vertex and calls the recursive <code>dfs()</code> to mark all vertices connected to that vertex. Moreover, it maintains a vertex-indexed array <code>id[]</code> that associates the same <code>int</code> value to every vertex in each component. This array makes the implementation of <code>connected()</code> simple, in precisely the same manner as <a id="page_546"/><code>connected()</code> in <a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a> (just check if identifiers are equal). In this case, the identifier <code>0</code> is assigned to all the vertices in the first component processed, <code>1</code> is assigned to all the vertices in the second component processed, and so forth, so that the identifiers are all between <code>0</code> and <code>count()-1</code>, as specified in the API. This convention enables the use of component-indexed arrays, as in the test client on page <a href="#page_543">543</a>.</p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb13"/></p>
<h3><a id="page_544"/>Algorithm 4.3 Depth-first search to find connected components in a graph</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0544-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/p0544-02.jpg"/></p>
<p>This <code>Graph</code> client provides its clients with the ability to independently process a graph’s connected components. Code from <code>DepthFirstSearch</code> (page <a href="#page_531">531</a>) is left in gray. The computation is based on a vertex-indexed array <code>id[]</code> such that <code>id[v]</code> is set to <code>i</code> if <code>v</code> is in the <code>i</code>th connected component processed. The constructor finds an unmarked vertex and calls the recursive <code>dfs()</code> to mark and identify all the vertices connected to it, continuing until all vertices have been marked and identified. Implementations of the instance methods <code>connected()</code>, <code>id()</code>, and <code>count()</code> are immediate.</p>
<hr/>
</div>
<p class="image"><a id="page_545"/><img alt="image" src="graphics/04_24-dfstracecc.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb14"/></p>
<p><strong>Proposition C.</strong> DFS uses preprocessing time and space proportional to <em>V</em>+<em>E</em> to support constant-time connectivity queries in a graph.</p>
<p><strong>Proof:</strong> Immediate from the code. Each adjacency-list entry is examined exactly once, and there are 2<em>E</em> such entries (two for each edge). Instance methods examine or return one or two instance variables.</p>
<hr/>
</div>
<p><a id="ch04sec3lev13"/></p>
<h5><em>Union-find</em></h5>
<p>How does the DFS-based solution for graph connectivity in <code>CC</code> compare with the union-find approach of <a href="ch01.html#ch01"><small>CHAPTER 1</small></a>? In theory, DFS is faster than union-find because it provides a constant-time guarantee, which union-find does not; in practice, this difference is negligible, and union-find is faster because it does not have to build a full representation of the graph. More important, union-find is an online algorithm (we can check whether two vertices are connected in near-constant time at any point, even while adding edges), whereas the DFS solution must first preprocess the graph. Therefore, for example, we prefer union-find when determining connectivity is our only task or when we have a large number of queries intermixed with edge insertions but may find the DFS solution more appropriate for use in a graph ADT because it makes efficient use of existing infrastructure.</p>
<p><small>THE PROBLEMS THAT WE HAVE SOLVED</small> with DFS are fundamental. It is a simple approach, and recursion provides us a way to reason about the computation and develop compact solutions to graph-processing problems. Two additional examples, for solving the following problems, are given in the table on the facing page.</p>
<p class="indenthanging"><strong><em>Cycle detection.</em></strong> Support this query: <em>Is a given graph acylic</em>?</p>
<p class="indenthanging"><strong><em>Two-colorability.</em></strong> Support this query: <em>Can the vertices of a given graph be assigned one of two colors in such a way that no edge connects vertices of the same color</em>? which is equivalent to this question: <em>Is the graph bipartite</em>?</p>
<p>As usual with DFS, the simple code masks a more sophisticated computation, so studying these examples, tracing their behavior on small sample graphs, and extending them to provide a cycle or a coloring, respectively, are worthwhile (and left for exercises).</p>
<p class="image"><a id="page_547"/><img alt="image" src="graphics/p0547-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/p0547-02.jpg"/></p>
<p><a id="ch04sec2lev8"/></p>
<h4><a id="page_548"/>Symbol graphs</h4>
<p>Typical applications involve processing graphs defined in files or on web pages, using strings, not integer indices, to define and refer to vertices. To accommodate such applications, we define an input format with the following properties:</p>
<p class="indenthangingB">• Vertex names are strings.</p>
<p class="indenthangingB">• A specified delimiter separates vertex names (to allow for the possibility of spaces in names).</p>
<p class="indenthangingB">• Each line represents a set of edges, connecting the first vertex name on the line to each of the other vertices named on the line.</p>
<p class="indenthangingB">• The number of vertices <em>V</em> and the number of edges <em>E</em> are both implicitly defined.</p>
<p>Shown below is a small example, the file <code>routes.txt</code>, which represents a model for a small transportation system where vertices are U.S. airport codes and edges connecting them are airline routes between the vertices. The file is simply a list of edges. Shown on the facing page is a larger example, taken from the file <code>movies.txt</code>, from the <em>Internet Movie Database</em> (IMDB), that we introduced in <a href="ch03a.html#ch03sec1lev5"><small>SECTION 3.5</small></a>. Recall that this file consists of lines listing a movie name followed by a list of the performers in the movie. In the context of graph processing, we can view it as defining a graph with movies and performers as vertices and each line defining the adjacency list of edges connecting each movie to its performers. Note that the graph is a <em>bipartite</em> graph—there are no edges connecting performers to performers or movies to movies.</p>
<p class="image"><img alt="image" src="graphics/04_25-graphairmodel.jpg"/></p>
<p><a id="ch04sec3lev14"/></p>
<h5><em>API</em></h5>
<p>The following API defines a <code>Graph</code> client that allows us to immediately use our graph-processing routines for graphs defined by such files:</p>
<p class="image"><img alt="image" src="graphics/t0548-01.jpg"/></p>
<p class="image"><a id="page_549"/><img alt="image" src="graphics/04_26-graphmovie.jpg"/></p>
<p><a id="page_550"/>This API provides a constructor to read and build the graph and client methods <code>name()</code> and <code>index()</code> for translating vertex names between the strings on the input stream and the integer indices used by our graph-processing methods.</p>
<p class="image"><img alt="image" src="graphics/p0550-01.jpg"/></p>
<p><a id="ch04sec3lev15"/></p>
<h5><em>Test client</em></h5>
<p>The test client at left builds a graph from the file named as the first command-line argument (using the delimiter as specified by the second command-line argument) and then takes queries from standard input. The user specifies a vertex name and gets the list of vertices adjacent to that vertex. This client immediately provides the useful inverted index functionality that we considered in <a href="ch03a.html#ch03sec1lev5"><small>SECTION 3.5</small></a>. In the case of <code>routes.txt</code>, you can type an airport code to find the direct flights from that airport, information that is not directly available in the data file. In the case of <code>movies.txt</code>, you can type the name of a performer to see the list of the movies in the database in which that performer appeared, or you can type the name of a movie to see the list of performers that appear in that movie. Typing a movie name and getting its cast is not much more than regurgitating the corresponding line in the input file, but typing the name of a performer and getting the list of movies in which that performer has appeared is inverting the index. Even though the database is built around connecting movies to performers, the bipartite graph model embraces the idea that it also connects performers to movies. The bipartite graph model automatically serves as an inverted index and also provides the basis for more sophisticated processing, as we will see.</p>
<p class="image"><img alt="image" src="graphics/p0550-02.jpg"/></p>
<p class="image"><img alt="image" src="graphics/p0550-03.jpg"/></p>
<p><a id="page_551"/><small>THIS APPROACH IS CLEARLY EFFECTIVE</small> for any of the graph-processing methods that we consider: any client can use <code>index()</code> when it wants to convert a vertex name to an index for use in graph processing and <code>name()</code> when it wants to convert an index from graph processing into a name for use in the context of the application.</p>
<p><a id="ch04sec3lev16"/></p>
<h5><em>Implementation</em></h5>
<p>A full <code>SymbolGraph</code> implementation is given on page <a href="#ch04sb15">552</a>. It builds three data structures:</p>
<p class="indenthangingB">• A symbol table <code>st</code> with <code>String</code> keys (vertex names) and <code>int</code> values (indices)</p>
<p class="indenthangingB">• An array <code>keys[]</code> that serves as an inverted index, giving the vertex name associated with each integer index</p>
<p class="indenthangingB">• A <code>Graph G</code> built using the indices to refer to vertices</p>
<p><code>SymbolGraph</code> uses two passes through the data to build these data structures, primarily because the number of vertices <em>V</em> is needed to build the <code>Graph</code>. In typical real-world applications, keeping the value of <em>V</em> and <em>E</em> in the graph definition file (as in our <code>Graph</code> constructor at the beginning of this section) is somewhat inconvenient—with <code>SymbolGraph</code>, we can maintain files such as <code>routes.txt</code> or <code>movies.txt</code> by adding or deleting entries without regard to the number of different names involved.</p>
<p class="image"><img alt="image" src="graphics/04_27-sgexample.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb15"/></p>
<h3><a id="page_552"/>Symbol graph data type</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0552-01.jpg"/></p>
<p>This <code>Graph</code> client allows clients to define graphs with <code>String</code> vertex names instead of integer indices. It maintains instance variables <code>st</code> (a symbol table that maps names to indices), <code>keys</code> (an array that maps indices to names), and <code>G</code> (a graph, with integer vertex names). To build these data structures, it makes two passes through the graph definition (each line has a string and a list of adjacent strings, separated by the delimiter <code>sp</code>).</p>
<hr/>
</div>
<p><a id="ch04sec3lev17"/></p>
<h5><a id="page_553"/><em>Degrees of separation</em></h5>
<p>One of the classic applications of graph processing is to find the degree of separation between two individuals in a social network. To fix ideas, we discuss this application in terms of a recently popularized pastime known as the <em>Kevin Bacon game</em>, which uses the movie-performer graph that we just considered. Kevin Bacon is a prolific actor who has appeared in many movies. We assign every performer a <em>Kevin Bacon number</em> as follows: Bacon himself is 0, any performer who has been in the same cast as Bacon has a Kevin Bacon number of 1, any other performer (except Bacon) who has been in the same cast as a performer whose number is 1 has a Kevin Bacon number of 2, and so forth. For example, Meryl Streep has a Kevin Bacon number of 1 because she appeared in <em>The River Wild</em> with Kevin Bacon. Nicole Kidman’s number is 2: although she did not appear in any movie with Kevin Bacon, she was in <em>Days of Thunder</em> with Tom Cruise, and Cruise appeared in <em>A Few Good Men</em> with Kevin Bacon. Given the name of a performer, the simplest version of the game is to find some alternating sequence of movies and performers that leads back to Kevin Bacon. For example, a movie buff might know that Tom Hanks was in <em>Joe Versus the Volcano</em> with Lloyd Bridges, who was in <em>High Noon</em> with Grace Kelly, who was in <em>Dial M for Murder</em> with Patrick Allen, who was in <em>The Eagle Has Landed</em> with Donald Sutherland, who was in <em>Animal House</em> with Kevin Bacon. But this knowledge does not suffice to establish Tom Hanks’s Bacon number (it is actually 1 because he was in <em>Apollo 13</em> with Kevin Bacon). You can see that the Kevin Bacon number has to be defined by counting the movies in the <em>shortest</em> such sequence, so it is hard to be sure whether someone wins the game without using a computer. Of course, as illustrated in the <code>SymbolGraph</code> client <code>DegreesOfSeparation</code> on page <a href="#ch04sb16">555</a>, <code>BreadthFirstPaths</code> is the program we need to find a shortest path that establishes the Kevin Bacon number of any performer in <code>movies.txt</code>. This program takes a source vertex from the command line, then takes queries from standard input and prints a shortest path from the source to the query vertex. Since the graph associated with <code>movies.txt</code> is bipartite, all paths alternate between movies and performers, and the printed path is a “proof” that the path is valid (but not a proof that it is the shortest such path—you need to educate your <a id="page_554"/>friends about <a href="#ch04sb11"><small>PROPOSITION B</small></a> for that). <code>DegreesOfSeparation</code> also finds shortest paths in graphs that are not bipartite: for example, it finds a way to get from one airport to another in <code>routes.txt</code> using the fewest connections.</p>
<p class="image"><img alt="image" src="graphics/p0553-01.jpg"/></p>
<p><small>YOU MIGHT ENJOY USING</small> <code>DegreesOfSeparation</code> to answer some entertaining questions about the movie business. For example, you can find separations between movies, not just performers. More important, the concept of separation has been widely studied in many other contexts. For example, mathematicians play this same game with the graph defined by paper co-authorship and their connection to P. Erdös, a prolific 20th-century mathematician. Similarly, everyone in New Jersey seems to have a Bruce Springsteen number of 2, because everyone in the state seems to know someone who claims to know Bruce. To play the Erdös game, you would need a database of all mathematical papers; playing the Springsteen game is a bit more challenging. On a more serious note, degrees of separation play a crucial role in the design of computer and communications networks, and in our understanding of natural networks in all fields of science.</p>
<p class="image"><img alt="image" src="graphics/p0554-01.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb16"/></p>
<h3><a id="page_555"/>Degrees of separation</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0555-01.jpg"/></p>
<p>This <code>SymbolGraph</code> and <code>BreadthFirstPaths</code> client finds shortest paths in graphs. For <code>movies.txt</code>, it plays the Kevin Bacon game.</p>
<p class="image"><img alt="image" src="graphics/p0555-02.jpg"/></p>
<hr/>
</div>
<p><a id="ch04sec2lev9"/></p>
<h4><a id="page_556"/>Summary</h4>
<p>In this section, we have introduced several basic concepts that we will expand upon and further develop throughout the rest of this chapter:</p>
<p class="indenthangingB">• Graph nomenclature</p>
<p class="indenthangingB">• A graph representation that enables processing of huge sparse graphs</p>
<p class="indenthangingB">• A design pattern for graph processing, where we implement algorithms by developing clients that preprocess the graph in the constructor, building data structures that can efficiently support client queries about the graph</p>
<p class="indenthangingB">• Depth-first search and breadth-first search</p>
<p class="indenthangingB">• A class providing the capability to use symbolic vertex names</p>
<p>The table below summarizes the implementations of graph algorithms that we have considered. These algorithms are a proper introduction to graph processing, since variants on their code will resurface as we consider more complicated types of graphs and applications, and (consequently) more difficult graph-processing problems. The same questions involving connections and paths among vertices become much more difficult when we add direction and then weights to graph edges, but the same approaches are effective in addressing them and serve as a starting point for addressing more difficult problems.</p>
<p class="image"><img alt="image" src="graphics/t0556-01.jpg"/></p>
<p><a id="ch04sec2lev10"/></p>
<h4><a id="page_557"/>Q&amp;A</h4>
<p><strong>Q.</strong> Why not jam all of the algorithms into <code>Graph.java</code>?</p>
<p><strong>A.</strong> Yes, we might just add query methods (and whatever private fields and methods each might need) to the basic <code>Graph</code> ADT definition. While this approach has some of the virtues of data abstraction that we have embraced, it also has some serious drawbacks, because the world of graph processing is significantly more expansive than the kinds of basic data structures treated in <a href="ch01a.html#ch01sec1lev5"><small>SECTION 1.3</small></a>. Chief among these drawbacks are the following:</p>
<p class="indenthangingB">• There are many more graph-processing operations to implement than we can accurately define in a single API.</p>
<p class="indenthangingB">• Simple graph-processing tasks have to use the same API needed by complicated tasks.</p>
<p class="indenthangingB">• One method can access a field intended for use by another method, contrary to encapsulation principles that we would like to follow.</p>
<p>This situation is not unusual: APIs of this kind have come to be known as <em>wide</em> interfaces (see page <a href="ch01.html#page_97">97</a>). In a chapter filled with graph-processing algorithms, an API of this sort would be wide indeed.</p>
<p><strong>Q.</strong> Does <code>SymbolGraph</code> really need two passes?</p>
<p><strong>A.</strong> No. You could pay an extra lg <em>N</em> factor and support <code>adj()</code> directly as an <code>ST</code> instead of a <code>Bag</code>. We have an implementation along these lines in our book <em>An Introduction to Programming in Java: An Interdisciplinary Approach</em>.</p>
<p><a id="ch04sec2lev11"/></p>
<h4><a id="page_558"/>Exercises</h4>
<p><a id="ch04qa1q1"/><strong>4.1.1</strong> What is the maximum number of edges in a graph with <em>V</em> vertices and no parallel edges? What is the minimum number of edges in a graph with <em>V</em> vertices, none of which are isolated?</p>
<p><a id="ch04qa1q2"/><strong>4.1.2</strong> Draw, in the style of the figure in the text (page <a href="#page_524">524</a>), the adjacency lists built by <code>Graph</code>’s input stream constructor for the file <code>tinyGex2.txt</code> depicted at left.</p>
<p class="image"><img alt="image" src="graphics/04_28-tinydgex2.jpg"/></p>
<p><a id="ch04qa1q3"/><strong>4.1.3</strong> Create a copy constructor for <code>Graph</code> that takes as input a graph <code>G</code> and creates and initializes a new copy of the graph. Any changes a client makes to <code>G</code> should not affect the newly created graph.</p>
<p><a id="ch04qa1q4"/><strong>4.1.4</strong> Add a method <code>hasEdge()</code> to <code>Graph</code> which takes two <code>int</code> arguments <code>v</code> and <code>w</code> and returns <code>true</code> if the graph has an edge <code>v-w</code>, <code>false</code> otherwise.</p>
<p><a id="ch04qa1q5"/><strong>4.1.5</strong> Modify <code>Graph</code> to disallow parallel edges and self-loops.</p>
<p><a id="ch04qa1q6"/><strong>4.1.6</strong> Consider the four-vertex graph with edges <code>0-1</code>, <code>1-2</code>, <code>2-3</code>, and <code>3-0</code>. Draw an array of adjacency-lists that could <em>not</em> have been built calling <code>addEdge()</code> for these edges <em>no matter what order</em>.</p>
<p><a id="ch04qa1q7"/><strong>4.1.7</strong> Develop a test client for <code>Graph</code> that reads a graph from the input stream named as command-line argument and then prints it, relying on <code>toString()</code>.</p>
<p><a id="ch04qa1q8"/><strong>4.1.8</strong> Develop an implementation for the <code>Search</code> API on page <a href="#page_528">528</a> that uses <code>UF</code>, as described in the text.</p>
<p><a id="ch04qa1q9"/><strong>4.1.9</strong> Show, in the style of the figure on page <a href="#page_533">533</a>, a detailed trace of the call <code>dfs(0)</code> for the graph built by <code>Graph</code>’s input stream constructor for the file <code>tinyGex2.txt</code> (see <a href="#ch04qa1q2"><small>EXERCISE 4.1.2</small></a>). Also, draw the tree represented by <code>edgeTo[].</code></p>
<p><a id="ch04qa1q10"/><strong>4.1.10</strong> Prove that every connected graph has a vertex whose removal (including all adjacent edges) will not disconnect the graph, and write a DFS method that finds such a vertex. <em>Hint</em>: Consider a vertex whose adjacent vertices are all marked.</p>
<p><a id="ch04qa1q11"/><strong>4.1.11</strong> Draw the tree represented by <code>edgeTo[]</code> after the call <code>bfs(G, 0)</code> in <a href="#ch04sb10"><small>ALGORITHM 4.2</small></a> for the graph built by <code>Graph</code>’s input stream constructor for the file <code>tinyGex2.txt</code> (see <a href="#ch04qa1q2"><small>EXERCISE 4.1.2</small></a>).</p>
<p><a id="page_559"/><a id="ch04qa1q12"/><strong>4.1.12</strong> What does the BFS tree tell us about the distance from <code>v</code> to <code>w</code> when neither is at the root?</p>
<p class="image"><img alt="image" src="graphics/04_29-outformatal.jpg"/></p>
<p><a id="ch04qa1q13"/><strong>4.1.13</strong> Add a <code>distTo()</code> method to the <code>BreadthFirstPaths</code> API and implementation, which returns the number of edges on the shortest path from the source to a given vertex. A <code>distTo()</code> query should run in constant time.</p>
<p><a id="ch04qa1q14"/><strong>4.1.14</strong> Suppose you use a stack instead of a queue when running breadth-first search. Does it still compute shortest paths?</p>
<p><a id="ch04qa1q15"/><strong>4.1.15</strong> Modify the input stream constructor for <code>Graph</code> to also allow adjacency lists from standard input (in a manner similar to <code>SymbolGraph</code>), as in the example <code>tinyGadj.txt</code> shown at right. After the number of vertices and edges, each line contains a vertex and its list of adjacent vertices.</p>
<p><a id="ch04qa1q16"/><strong>4.1.16</strong> The <em>eccentricity</em> of a vertex <code>v</code> is the the length of the shortest path from that vertex to the furthest vertex from <code>v</code>. The <em>diameter</em> of a graph is the maximum eccentricity of any vertex. The <em>radius</em> of a graph is the smallest eccentricity of any vertex. A <em>center</em> is a vertex whose eccentricity is the radius. Implement the following API:</p>
<p class="image"><img alt="image" src="graphics/t0559-01.jpg"/></p>
<p><a id="ch04qa1q18"/><strong>4.1.18</strong> The <em>girth</em> of a graph is the length of its shortest cycle. If a graph is acyclic, then its girth is infinite. Add a method <code>girth()</code> to <code>GraphProperties</code> that returns the girth of the graph. <em>Hint</em>: Run BFS from each vertex. The shortest cycle containing <code>s</code> is a shortest path from <code>s</code> to some vertex <code>v</code>, plus the edge from <code>v</code> back to <code>s</code>.</p>
<p><a id="page_560"/><a id="ch04qa1q19"/><strong>4.1.19</strong> Show, in the style of the figure on page <a href="#page_545">545</a>, a detailed trace of <code>CC</code> for finding the connected components in the graph built by <code>Graph</code>’s input stream constructor for the file <code>tinyGex2.txt</code> (see <a href="#ch04qa1q2"><small>EXERCISE 4.1.2</small></a>).</p>
<p><a id="ch04qa1q20"/><strong>4.1.20</strong> Show, in the style of the figures in this section, a detailed trace of <code>Cycle</code> for finding a cycle in the graph built by <code>Graph</code>’s input stream constructor for the file <code>tinyGex2.txt</code> (see <a href="#ch04qa1q2"><small>EXERCISE 4.1.2</small></a>). What is the order of growth of the running time of the <code>Cycle</code> constructor, in the worst case?</p>
<p><a id="ch04qa1q21"/><strong>4.1.21</strong> Show, in the style of the figures in this section, a detailed trace of <code>TwoColor</code> for finding a two-coloring of the graph built by <code>Graph</code>’s input stream constructor for the file <code>tinyGex2.txt</code> (see <a href="#ch04qa1q2"><small>EXERCISE 4.1.2</small></a>). What is the order of growth of the running time of the <code>TwoColor</code> constructor, in the worst case?</p>
<p><a id="ch04qa1q22"/><strong>4.1.22</strong> Run <code>SymbolGraph</code> with <code>movies.txt</code> to find the Kevin Bacon number of this year’s Oscar nominees.</p>
<p><a id="ch04qa1q23"/><strong>4.1.23</strong> Write a program <code>BaconHistogram</code> that prints a histogram of Kevin Bacon numbers, indicating how many performers from <code>movies.txt</code> have a Bacon number of 0, 1, 2, 3, .... Include a category for those who have an infinite number (not connected to Kevin Bacon).</p>
<p><a id="ch04qa1q24"/><strong>4.1.24</strong> Compute the number of connected components in <code>movies.txt</code>, the size of the largest component, and the number of components of size less than 10. Find the eccentricity, diameter, radius, a center, and the girth of the largest component in the graph. Does it contain Kevin Bacon?</p>
<p><a id="ch04qa1q25"/><strong>4.1.25</strong> Modify <code>DegreesOfSeparation</code> to take an <code>int</code> value <code>y</code> as a command-line argument and ignore movies that are more than <code>y</code> years old.</p>
<p><a id="ch04qa1q26"/><strong>4.1.26</strong> Write a <code>SymbolGraph</code> client like <code>DegreesOfSeparation</code> that uses <em>depth-first</em> search instead of breadth-first search to find paths connecting two performers, producing output like that shown on the facing page.</p>
<p><a id="page_561"/><a id="ch04qa1q27"/><strong>4.1.27</strong> Determine the amount of memory used by <code>Graph</code> to represent a graph with <em>V</em> vertices and <em>E</em> edges, using the memory-cost model of <a href="ch01a.html#ch01sec1lev6"><small>SECTION 1.4</small></a>.</p>
<p><a id="ch04qa1q28"/><strong>4.1.28</strong> Two graphs are <em>isomorphic</em> if there is a way to rename the vertices of one to make it identical to the other. Draw all the nonisomorphic graphs with two, three, four, and five vertices.</p>
<p><a id="ch04qa1q29"/><strong>4.1.29</strong> Modify <code>Cycle</code> so that it works even if the graph contains self-loops and parallel edges.</p>
<p class="image"><img alt="image" src="graphics/p0561-01.jpg"/></p>
<p><a id="ch04sec2lev12"/></p>
<h4><a id="page_562"/>Creative Problems</h4>
<p><a id="ch04qa1q30"/><strong>4.1.30</strong> <em>Eulerian and Hamiltonian cycles.</em> Consider the graphs defined by the following four sets of edges:</p>
<p class="programlisting"><img alt="image" src="graphics/t0562-01.jpg"/></p>
<p>Which of these graphs have Euler cycles (cycles that visit each edge exactly once)? Which of them have Hamilton cycles (cycles that visit each vertex exactly once)?</p>
<p><a id="ch04qa1q31"/><strong>4.1.31</strong> <em>Graph enumeration.</em> How many different undirected graphs are there with <em>V</em> vertices and <em>E</em> edges (and no parallel edges)?</p>
<p><a id="ch04qa1q32"/><strong>4.1.32</strong> <em>Parallel edge detection.</em> Devise a linear-time algorithm to count the parallel edges in a graph.</p>
<p><a id="ch04qa1q33"/><strong>4.1.33</strong> <em>Odd cycles.</em> Prove that a graph is two-colorable (bipartite) if and only if it contains no odd-length cycle.</p>
<p><a id="ch04qa1q34"/><strong>4.1.34</strong> <em>Symbol graph.</em> Implement a one-pass <code>SymbolGraph</code> (it need not be a <code>Graph</code> client). Your implementation may pay an extra log <em>V</em> factor for graph operations, for symbol-table lookups.</p>
<p><a id="ch04qa1q35"/><strong>4.1.35</strong> <em>Biconnectedness.</em> A graph is <em>biconnected</em> if every pair of vertices is connected by two disjoint paths. An <em>articulation point</em> in a connected graph is a vertex that would disconnect the graph if it (and its adjacent edges) were removed. Prove that any graph with no articulation points is biconnected. <em>Hint</em>: Given a pair of vertices <code>s</code> and <code>t</code> and a path connecting them, use the fact that none of the vertices on the path are articulation points to construct two disjoint paths connecting <code>s</code> and <code>t</code>.</p>
<p><a id="ch04qa1q36"/><strong>4.1.36</strong> <em>Two-edge connectivity.</em> A <em>bridge</em> in a graph is an edge that, if removed, would increase the number of connected components. A graph that has no bridges is said to be <em>two-edge connected</em>. Develop a DFS-based data type for determining whether a given graph is edge connected.</p>
<p><a id="ch04qa1q37"/><strong>4.1.37</strong> <em>Euclidean graphs.</em> Design and implement an API <code>EuclideanGraph</code> for graphs whose vertices are points in the plane that include coordinates. Include a method <code>show()</code> that uses <code>StdDraw</code> to draw the graph.</p>
<p><a id="page_563"/><a id="ch04qa1q38"/><strong>4.1.38</strong> <em>Image processing.</em> Implement the <em>flood fill</em> operation on the implicit graph defined by connecting adjacent points that have the same color in an image.</p>
<p><a id="ch04sec2lev13"/></p>
<h4><a id="page_564"/>Experiments</h4>
<p><a id="ch04qa1q39"/><strong>4.1.39</strong> <em>Random graphs.</em> Write a program <code>ErdosRenyiGraph</code> that takes integer values <em>V</em> and <em>E</em> from the command line and builds a graph by generating <em>E</em> random pairs of integers between 0 and <em>V</em>−1. <em>Note</em>: This generator produces self-loops and parallel edges.</p>
<p><a id="ch04qa1q40"/><strong>4.1.40</strong> <em>Random simple graphs.</em> Write a program <code>RandomSimpleGraph</code> that takes integer values <em>V</em> and <em>E</em> from the command line and produces, with equal likelihood, each of the possible <em>simple</em> graphs with <em>V</em> vertices and <em>E</em> edges.</p>
<p><a id="ch04qa1q41"/><strong>4.1.41</strong> <em>Random sparse graphs.</em> Write a program <code>RandomSparseGraph</code> to generate random sparse graphs for a well-chosen set of values of <em>V</em> and <em>E</em> such that you can use it to run meaningful empirical tests on graphs drawn from the Erdös-Renyi model.</p>
<p><a id="ch04qa1q42"/><strong>4.1.42</strong> <em>Random Euclidean graphs.</em> Write a <code>EuclideanGraph</code> client (see <a href="#ch04qa1q37"><small>EXERCISE 4.1.37</small></a>) <code>RandomEuclideanGraph</code> that produces random graphs by generating <em>V</em> random points in the plane, then connecting each point with all points that are within a circle of radius <em>d</em> centered at that point. <em>Note</em>: The graph will almost certainly be connected if <em>d</em> is larger than the threshold value <img alt="image" src="graphics/564fig01.jpg"/> and almost certainly disconnected if <em>d</em> is smaller than that value.</p>
<p><a id="ch04qa1q43"/><strong>4.1.43</strong> <em>Random grid graphs.</em> Write a <code>EuclideanGraph</code> client <code>RandomGridGraph</code> that generates random graphs by connecting vertices arranged in a <img alt="image" src="graphics/root-v.jpg"/>-by-<img alt="image" src="graphics/root-v.jpg"/> grid to their neighbors (see <a href="ch01a.html#ch01qa5q15"><small>EXERCISE 1.5.15</small></a>). Augment your program to add <em>R</em> extra random edges. For large <em>R</em>, shrink the grid so that the total number of edges remains about <em>V</em>. Add an option such that an extra edge goes from a vertex <code>s</code> to a vertex <code>t</code> with probability inversely proportional to the Euclidean distance between <code>s</code> and <code>t</code>.</p>
<p><a id="ch04qa1q44"/><strong>4.1.44</strong> <em>Real-world graphs.</em> Find a large weighted graph on the web—perhaps a map with distances, telephone connections with costs, or an airline rate schedule. Write a program <code>RandomRealGraph</code> that builds a graph by choosing <em>V</em> vertices at random and <em>E</em> edges at random from the subgraph induced by those vertices.</p>
<p><a id="ch04qa1q45"/><strong>4.1.45</strong> <em>Random interval graphs.</em> Consider a collection of <em>V</em> intervals on the real line (pairs of real numbers). Such a collection defines an <em>interval graph</em> with one vertex corresponding to each interval, with edges between vertices if the corresponding intervals intersect (have any points in common). Write a program that generates <em>V</em> random intervals in the unit interval, all of length <em>d</em>, then builds the corresponding interval graph. <em>Hint</em>: Use a BST.</p>
<p><a id="page_565"/><a id="ch04qa1q46"/><strong>4.1.46</strong> <em>Random transportation graphs.</em> One way to define a transportation system is with a set of sequences of vertices, each sequence defining a path connecting the vertices. For example, the sequence <code>0-9-3-2</code> defines the edges <code>0-9</code>, <code>9-3</code>, and <code>3-2</code>. Write a <code>EuclideanGraph</code> client <code>RandomTransportation</code> that builds a graph from an input file consisting of one sequence per line, using symbolic names. Develop input suitable to allow you to use your program to build a graph corresponding to the Paris Métro system.</p>
<p><em>Testing all algorithms and studying all parameters against all graph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input graph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</em></p>
<p><a id="ch04qa1q47"/><strong>4.1.47</strong> <em>Path lengths in DFS.</em> Run experiments to determine empirically the probability that <code>DepthFirstPaths</code> finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various graph models.</p>
<p><a id="ch04qa1q48"/><strong>4.1.48</strong> <em>Path lengths in BFS.</em> Run experiments to determine empirically the probability that <code>BreadthFirstPaths</code> finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various graph models.</p>
<p><a id="ch04qa1q49"/><strong>4.1.49</strong> <em>Connected components.</em> Run experiments to determine empirically the distribution of the number of components in random graphs of various types, by generating large numbers of graphs and drawing a histogram.</p>
<p><a id="ch04qa1q50"/><strong>4.1.50</strong> <em>Two-colorable.</em> Most graphs are not two-colorable, and DFS tends to discover that fact quickly. Run empirical tests to study the number of edges examined by <code>TwoColor</code>, for various graph models.</p>
<p><a id="ch04sec1lev11"/></p>
<h3><a id="page_566"/>4.2 Directed Graphs</h3>
<p>In <em>directed graphs</em>, edges are one-way: the pair of vertices that defines each edge is an ordered pair that specifies a one-way adjacency. Many applications (for example, graphs that represent the web, scheduling constraints, or telephone calls) are naturally expressed in terms of directed graphs. The one-way restriction is natural, easy to enforce in our implementations, and seems innocuous; but it implies added combinatorial structure that has profound implications for our algorithms and makes working with directed graphs quite different from working with undirected graphs. In this section, we consider classic algorithms for exploring and processing directed graphs.</p>
<p class="image"><img alt="image" src="graphics/t0566-01.jpg"/></p>
<p><a id="ch04sec2lev14"/></p>
<h4>Glossary</h4>
<p>Our definitions for directed graphs are nearly identical to those for undirected graphs (as are some of the algorithms and programs that we use), but they are worth restating. The slight differences in the wording to account for edge directions imply structural properties that will be the focus of this section.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb17"/></p>
<p><strong>Definition.</strong> A <em>directed graph</em> (or <em>digraph</em>) is a set of <em>vertices</em> and a collection of <em>directed edges</em>. Each directed edge connects an ordered pair of vertices.</p>
<hr/>
</div>
<p>We say that a directed edge <em>points from</em> the first vertex in the pair and <em>points to</em> the second vertex in the pair. The <em>outdegree</em> of a vertex in a digraph is the number of edges going <em>points from</em> it; the <em>indegree</em> of a vertex is the number of edges pointing <em>to</em> it. We drop the modifier <em>directed</em> when referring to edges in digraphs when the distinction is obvious in context. The first vertex in a directed edge is called its <em>head</em>; the second vertex is called its <em>tail</em>. We draw directed edges as arrows pointing from head to tail. We use the notation <code>v-&gt;w</code> to refer to an edge that points from <code>v</code> to <code>w</code> in a digraph. As with undirected graphs, our code handles parallel edges and self-loops, but they are not present in examples and we generally ignore them in the text. Ignoring anomalies, there are four <a id="page_567"/>different ways in which two vertices might be related in a digraph: no edge; an edge <code>v-&gt;w</code> from <code>v</code> to <code>w</code>; an edge <code>w-&gt;v</code> from <code>w</code> to <code>v</code>; or two edges <code>v-&gt;w</code> and <code>w-&gt;v</code>, which indicate connections in both directions.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb18"/></p>
<p><strong>Definition.</strong> A <em>directed path</em> in a digraph is a sequence of vertices in which there is a (directed) edge pointing from each vertex in the sequence to its successor in the sequence. A <em>directed cycle</em> is a directed path with at least one edge whose first and last vertices are the same. A <em>simple cycle</em> is a cycle with no repeated edges or vertices (except the requisite repetition of the first and last vertices). The <em>length</em> of a path or a cycle is its number of edges.</p>
<hr/>
</div>
<p>As for undirected graphs, we assume that directed paths are simple unless we specifically relax this assumption by referring to specific repeated vertices (as in our definition of directed cycle) or to <em>general</em> directed paths. We say that a vertex <code>w</code> is <em>reachable</em> from a vertex <code>v</code> if there is a directed path from <code>v</code> to w. Also, we adopt the convention that each vertex is reachable from itself. Except for this case, the fact that <code>w</code> is reachable from <code>v</code> in a digraph indicates nothing about whether <code>v</code> is reachable from <code>w</code>. This distinction is obvious, but critical, as we shall see.</p>
<p class="image"><img alt="image" src="graphics/04_30-anatomyd.jpg"/></p>
<p><small>UNDERSTANDING THE ALGORITHMS</small> in this section requires an appreciation of the distinction between reachability in digraphs and connectivity in undirected graphs. Developing such an appreciation is more complicated than you might think. For example, although you are likely to be able to tell at a glance whether two vertices in a small undirected graph are connected, a directed path in a digraph is not so easy to spot, as indicated in the example at left. Processing digraphs is akin to traveling around in a city where all the streets are one-way, with the directions not necessarily assigned in any uniform pattern. Getting from one point to another in such a situation could be a challenge indeed. Counter to this intuition is the fact that the standard data structure that we use for representing digraphs is <em>simpler</em> than the corresponding representation for undirected graphs!</p>
<p class="image"><img alt="image" src="graphics/04_31-griddg.jpg"/></p>
<p><a id="ch04sec2lev15"/></p>
<h4><a id="page_568"/>Digraph data type</h4>
<p>The API below and the class <code>Digraph</code> shown on the facing page are virtually identical to those for <code>Graph</code> (page <a href="#ch04sb06">526</a>).</p>
<p class="image"><img alt="image" src="graphics/p0568-01.jpg"/></p>
<p><a id="ch04sec3lev18"/></p>
<h5><em>Representation</em></h5>
<p>We use the adjacency-lists representation, where an edge <code>v-&gt;w</code> is represented as a list node containing <code>w</code> in the linked list corresponding to <code>v</code>. This representation is essentially the same as for undirected graphs but is even more straightforward because each edge occurs just once, as shown on the facing page.</p>
<p><a id="ch04sec3lev19"/></p>
<h5><em>Input format</em></h5>
<p>The code for the constructor that takes a digraph from an input stream is identical to the corresponding constructor in <code>Graph</code>—the input format is the same, but all edges are interpreted to be directed edges. In the list-of-edges format, a pair <code>v w</code> is interpreted as an edge <code>v-&gt;w</code>.</p>
<p><a id="ch04sec3lev20"/></p>
<h5><em>Reversing a digraph</em></h5>
<p><code>Digraph</code> also adds to the API a method <code>reverse()</code> which returns a copy of the digraph, with all edges reversed. This method is sometimes needed in digraph processing because it allows clients to find the edges that point <em>to</em> each vertex, while <code>adj()</code> gives just vertices connected by edges that point <em>from</em> each vertex.</p>
<p><a id="ch04sec3lev21"/></p>
<h5><em>Symbolic names</em></h5>
<p>It is also a simple matter to allow clients to use symbolic names in digraph applications. To implement a class <code>SymbolDigraph</code> like <code>SymbolGraph</code> on page <a href="#ch04sb15">552</a>, replace <code>Graph</code> by <code>Digraph</code> everywhere.</p>
<p><small>IT IS WORTHWHILE</small> to take the time to consider carefully the difference, by comparing code and the figure at right with their counterparts for undirected graphs on page <a href="#page_524">524</a> and page <a href="#ch04sb06">526</a>. In the adjacency-lists representation of an undirected graph, we know that if <code>v</code> is on <code>w</code>’s list, then <code>w</code> will be on <code>v</code>’s list; the adjacency-lists representation of a digraph has no such symmetry. This difference has profound implications in processing digraphs.</p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb19"/></p>
<h3><a id="page_569"/>Directed graph (digraph) data type</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0569-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_32-digraphrepex.jpg"/></p>
<p>This <code>Digraph</code> data type is identical to <code>Graph</code> (page <a href="#ch04sb06">526</a>) except that <code>addEdge()</code> only calls <code>add()</code> once, and it has an instance method <code>reverse()</code> that returns a copy with all its edges reversed. Since the code is easily derived from the corresponding code for <code>Graph</code>, we omit the <code>toString()</code> method (see the table on page <a href="#page_523">523</a>) and the input stream constructor from (see page <a href="#ch04sb06">526</a>).</p>
<hr/>
</div>
<p><a id="ch04sec2lev16"/></p>
<h4><a id="page_570"/>Reachability in digraphs</h4>
<p>Our first graph-processing algorithm for undirected graphs was <code>DepthFirstSearch</code> on page <a href="#page_531">531</a>, which solves the single-source connectivity problem, allowing clients to determine which vertices are connected to a given source. The <em>identical code</em> with <code>Graph</code> changed to <code>Digraph</code> solves the analogous problem for digraphs:</p>
<p class="indenthanging"><strong><em>Single-source reachability</em></strong>. Given a digraph and a source vertex <code>s</code>, support queries of the form <em>Is there a directed path from</em> <code>s</code> <em>to a given target vertex</em> <code>v</code>?</p>
<p><code>DirectedDFS</code> on the facing page is a slight embellishment of <code>DepthFirstSearch</code> that implements the following API:</p>
<p class="image"><img alt="image" src="graphics/t0570-01.jpg"/></p>
<p>By adding a second constructor that takes a list of vertices, this API supports for clients the following generalization of the problem:</p>
<p class="indenthanging"><strong><em>Multiple-source reachability.</em></strong> Given a digraph and a <em>set</em> of source vertices, support queries of the form <em>Is there a directed path from</em> any <em>vertex in the set to a given target vertex</em> <code>v</code>?</p>
<p>This problem arises in the solution of a classic string-processing problem that we consider in <a href="ch05.html#ch05sec1lev10"><small>SECTION 5.4</small></a>.</p>
<p><code>DirectedDFS</code> uses our standard graph-processing paradigm and a standard recursive depth-first search to solve these problems. It calls the recursive <code>dfs()</code> for each source, which marks every vertex encountered.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb20"/></p>
<p><strong>Proposition D.</strong> DFS marks all the vertices in a digraph reachable from a given set of sources in time proportional to the sum of the outdegrees of the vertices marked.</p>
<p><strong>Proof:</strong> Same as <a href="#ch04sb07"><small>PROPOSITION A</small></a> on page <a href="#ch04sb07">531</a>.</p>
<hr/>
</div>
<p>A trace of the operation of this algorithm for our sample digraph appears on page <a href="#page_527">572</a>. This trace is somewhat simpler than the corresponding trace for undirected graphs, <a id="page_573"/>because DFS is fundamentally a digraph-processing algorithm, with one representation of each edge. Following this trace is a worthwhile way to help cement your understanding of depth-first search in digraphs.</p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb21"/></p>
<h3><a id="page_571"/>Algorithm 4.4 Reachability in digraphs</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0571-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/p0571-02.jpg"/></p>
<p>This implementation of depth-first search provides clients the ability to test which vertices are reachable from a given vertex or a given set of vertices.</p>
<hr/>
</div>
<p class="image"><a id="page_572"/><img alt="image" src="graphics/04_33-dfstrace13.jpg"/></p>
<p><a id="ch04sec3lev22"/></p>
<h5><em>Mark-and-sweep garbage collection</em></h5>
<p>An important application of multiple-source reachability is found in typical memory-management systems, including many implementations of Java. A digraph where each vertex represents an object and each edge represents a reference to an object is an appropriate model for the memory usage of a running Java program. At any point in the execution of a program, certain objects are known to be directly accessible, and any object not reachable from that set of objects can be returned to available memory. A mark-and-sweep garbage collection strategy reserves one bit per object for the purpose of garbage collection, then periodically <em>marks</em> the set of potentially accessible objects by running a digraph reachability algorithm like <code>DirectedDFS</code> and <em>sweeps</em> through all objects, collecting the unmarked ones for use for new objects.</p>
<p class="image"><img alt="image" src="graphics/04_34-marksweep.jpg"/></p>
<p><a id="ch04sec3lev23"/></p>
<h5><em>Finding paths in digraphs</em></h5>
<p><code>DepthFirstPaths</code> (<a href="#ch04sb08"><small>ALGORITHM 4.1</small></a> on page <a href="#ch04sb08">536</a>) and <code>BreadthFirstPaths</code> (<a href="#ch04sb10"><small>ALGORITHM 4.2</small></a> on page <a href="#ch04sb10">540</a>) are also fundamentally digraph-processing algorithms. Again, the identical APIs and code (with <code>Graph</code> changed to <code>Digraph</code>) effectively solve the following problems:</p>
<p class="indenthanging"><strong><em>Single-source directed paths.</em></strong> Given a digraph and a source vertex <code>s</code>, support queries of the form <em>Is there a directed path from</em> <code>s</code> <em>to a given target vertex</em> <code>v</code>? If so, find such a path.</p>
<p class="indenthanging"><strong><em>Single-source shortest directed paths.</em></strong> Given a digraph and a source vertex <code>s</code>, support queries of the form <em>Is there a directed path from</em> <code>s</code> <em>to a given target vertex</em> <code>v</code>? If so, find a <em>shortest</em> such path (one with a minimal number of edges).</p>
<p>On the booksite and in the exercises at the end of this section, we refer to these solutions as <code>DepthFirstDirectedPaths</code> and <code>BreadthFirstDirectedPaths</code>, respectively.</p>
<p><a id="ch04sec2lev17"/></p>
<h4><a id="page_574"/>Cycles and DAGs</h4>
<p>Directed cycles are of particular importance in applications that involve processing digraphs. Identifying directed cycles in a typical digraph can be a challenge without the help of a computer, as shown at right. In principle, a digraph might have a huge number of cycles; in practice, we typically focus on a small number of them, or simply are interested in knowing that none are present.</p>
<p class="image"><img alt="image" src="graphics/04_35-griddgtwo.jpg"/></p>
<p>To motivate the study of the role of directed cycles in digraph processing we consider, as a running example, the following prototypical application where digraph models arise directly:</p>
<p><a id="ch04sec3lev24"/></p>
<h5><em>Scheduling problems</em></h5>
<p>A widely applicable problem-solving model has to do with arranging for the completion of a set of jobs, under a set of constraints, by specifying when and how the jobs are to be performed. Constraints might involve functions of the time taken or other resources consumed by the jobs. The most important type of constraints is <em>precedence constraints</em>, which specify that certain tasks must be performed before certain others. Different types of additional constraints lead to many different types of scheduling problems, of varying difficulty. Literally thousands of different problems have been studied, and researchers still seek better algorithms for many of them. As an example, consider a college student planning a course schedule, under the constraint that certain courses are prerequisite for certain other courses, as in the example below.</p>
<p class="image"><img alt="image" src="graphics/04_36-courses.jpg"/></p>
<p><a id="page_575"/>If we further assume that the student can take only one course at a time, we have an instance of the following problem:</p>
<p class="indenthanging"><strong><em>Precedence-constrained scheduling.</em></strong> Given a set of jobs to be completed, with precedence constraints that specify that certain jobs have to be completed before certain other jobs are begun, how can we schedule the jobs such that they are all completed while still respecting the constraints?</p>
<p>For any such problem, a digraph model is immediate, with vertices corresponding to jobs and directed edges corresponding to precedence constraints. For economy, we switch the example to our standard model with vertices labeled as integers, as shown at left. In digraphs, precedence-constrained scheduling amounts to the following fundamental problem:</p>
<p class="indenthanging"><strong><em>Topological sort.</em></strong> Given a digraph, put the vertices in order such that all its directed edges point from a vertex earlier in the order to a vertex later in the order (or report that doing so is not possible).</p>
<p class="image"><img alt="image" src="graphics/04_37-tinydag.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_38-dagtopsort.jpg"/></p>
<p>A topological order for our example model is shown at right. All edges point down, so it clearly represents a solution to the precedence-constrained scheduling problem that this digraph models: the student can satisfy all course prerequisites by taking the courses in this order. This application is typical—some other representative applications are listed in the table below.</p>
<p class="image"><img alt="image" src="graphics/t0575-01.jpg"/></p>
<p><a id="ch04sec3lev25"/></p>
<h5><a id="page_576"/><em>Cycles in digraphs</em></h5>
<p>If job <code>x</code> must be completed before job <code>y</code>, job <code>y</code> before job <code>z</code>, and job <code>z</code> before job <code>x</code>, then someone has made a mistake, because those three constraints cannot all be satisfied. In general, if a precedence-constrained scheduling problem has a directed cycle, then there is no feasible solution. To check for such errors, we need to be able to solve the following problem:</p>
<p class="indenthanging"><strong><em>Directed cycle detection.</em></strong> Does a given digraph have a directed cycle? If so, find the vertices on some such cycle, in order from some vertex back to itself.</p>
<p>A graph may have an exponential number of cycles (see <a href="#ch04qa2q11"><small>EXERCISE 4.2.11</small></a>) so we only ask for one cycle, not all of them. For job scheduling and many other applications it is <em>required</em> that no directed cycle exists, so digraphs where they are absent play a special role:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb22"/></p>
<p><strong>Definition.</strong> A <em>directed acyclic graph</em> (DAG) is a digraph with no directed cycles.</p>
<hr/>
</div>
<p>Solving the directed cycle detection problem thus answers the following question: <em>Is a given digraph a DAG</em>? Developing a depth-first-search-based solution to this problem is not difficult, based on the fact that the recursive call stack maintained by the system represents the “current” directed path under consideration (like the string back to the entrance in Tremaux maze exporation). If we ever find a directed edge <code>v-&gt;w</code> to a vertex <code>w</code> that is on that stack, we have found a cycle, since the stack is evidence of a directed path from <code>w</code> to <code>v</code>, and the edge <code>v-&gt;w</code> completes the cycle. Moreover, the absence of any such <em>back edges</em> implies that the graph is acyclic. <code>DirectedCycle</code> on the facing page uses this idea to implement the following API:</p>
<p class="image"><img alt="image" src="graphics/t0576-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_39-dfscycle.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb23"/></p>
<h3><a id="page_577"/>Finding a directed cycle</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0577-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_40-dfstinycycle.jpg"/></p>
<p>This class adds to our standard recursive <code>dfs()</code> a boolean array <code>onStack[]</code> to keep track of the vertices for which the recursive call has not completed. When it finds an edge <code>v-&gt;w</code> to a vertex <code>w</code> that is on the stack, it has discovered a directed cycle, which it can recover by following <code>edgeTo[]</code> links.</p>
<hr/>
</div>
<p><a id="page_578"/>When executing <code>dfs(G, v)</code>, we have followed a directed path from the source to <code>v</code>. To keep track of this path, <code>DirectedCycle</code> maintains a vertex-indexed array <code>onStack[]</code> that marks the vertices on the recursive call stack (by setting <code>onStack[v]</code> to <code>true</code> on entry to <code>dfs(G, v)</code> and to <code>false</code> on exit). <code>DirectedCycle</code> also maintains an <code>edgeTo[]</code> array so that it can return the cycle when it is detected, in the same way as <code>DepthFirstPaths</code> (page <a href="#ch04sb08">536</a>) and <code>BreadthFirstPaths</code> (page <a href="#ch04sb10">540</a>) return paths.</p>
<p><a id="ch04sec3lev26"/></p>
<h5><em>Depth-first orders and topological sort</em></h5>
<p>Precedence-constrained scheduling amounts to computing a topological order for the vertices of a DAG, as in this API:</p>
<p class="image"><img alt="image" src="graphics/t0578-01.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb24"/></p>
<p><strong>Proposition E.</strong> A digraph has a topological order if and only if it is a DAG.</p>
<p><strong>Proof:</strong> If the digraph has a directed cycle, it has no topological order. Conversely, the algorithm that we are about to examine computes a topological order for any given DAG.</p>
<hr/>
</div>
<p>Remarkably, it turns out that we have already seen an algorithm for topological sort: a one-line addition to our standard recursive DFS does the job! To convince you of this fact, we begin with the class <code>DepthFirstOrder</code> on page <a href="#ch04sb25">580</a>. It is based on the idea that depth-first search visits each vertex exactly once. If we save the vertex given as argument to the recursive <code>dfs()</code> in a data structure, then iterate through that data structure, we see all the graph vertices, in order determined by the nature of the data structure and by whether we do the save before or after the recursive calls. Three vertex orderings are of interest in typical applications:</p>
<p class="indenthangingB">• <em>Preorder</em>: Put the vertex on a queue before the recursive calls.</p>
<p class="indenthangingB">• <em>Postorder</em>: Put the vertex on a queue after the recursive calls.</p>
<p class="indenthangingB">• <em>Reverse postorder</em>: Put the vertex on a stack after the recursive calls.</p>
<p>A trace of <code>DepthFirstOrder</code> for our sample DAG is given on the facing page. It is simple to implement and supports <code>pre()</code>, <code>post()</code>, and <code>reversePost()</code> methods that are useful for advanced graph-processing algorithms. For example, <code>order()</code> in <code>Topological</code> consists of a call on <code>reversePost()</code>.</p>
<p class="image"><a id="page_579"/><img alt="image" src="graphics/04_41-dfo.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb25"/></p>
<h3><a id="page_580"/>Depth-first search vertex ordering in a digraph</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0580-01.jpg"/></p>
<p>This class enables clients to iterate through the vertices in various orders defined by depth-first search. This ability is very useful in the development of advanced digraph-processing algorithms, because the recursive nature of the search enables us to prove properties of the computation (see, for example, <a href="#ch04sb27"><small>PROPOSITION F</small></a>).</p>
<hr/>
</div>
<div class="sidebar">
<hr/>
<p><a id="ch04sb26"/></p>
<h3><a id="page_581"/>Algorithm 4.5 Topological sort</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0581-01.jpg"/></p>
<p>This <code>DepthFirstOrder</code> and <code>DirectedCycle</code> client returns a topological order for a DAG. The test client solves the precedence-constrained scheduling problem for a <code>SymbolDigraph</code>. The instance method <code>order()</code> returns <code>null</code> if the given digraph is not a DAG and an iterator giving the vertices in topological order otherwise. The code for <code>SymbolDigraph</code> is omitted because it is precisely the same as for <code>SymbolGraph</code> (page <a href="#ch04sb15">552</a>), with <code>Digraph</code> replacing <code>Graph</code> everywhere.</p>
<hr/>
</div>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb27"/></p>
<p><a id="page_582"/><strong>Proposition F.</strong> Reverse postorder in a DAG is a topological sort.</p>
<p><strong>Proof:</strong> Consider any edge <code>v-&gt;w</code>. One of the following three cases must hold when <code>dfs(v)</code> is called (see the diagram on page <a href="#page_583">583</a>):</p>
<p class="indenthangingB">• <code>dfs(w)</code> has already been called and has returned (<code>w</code> is marked).</p>
<p class="indenthangingB">• <code>dfs(w)</code> has not yet been called (<code>w</code> is unmarked), so <code>v-&gt;w</code> will cause <code>dfs(w)</code> to be called (and return), either directly or indirectly, before <code>dfs(v)</code> returns.</p>
<p class="indenthangingB">• <code>dfs(w)</code> has been called and has not yet returned when <code>dfs(v)</code> is called. The key to the proof is that this case is impossible in a DAG, because the recursive call chain implies a path from <code>w</code> to <code>v</code> and <code>v-&gt;w</code> would complete a directed cycle.</p>
<p>In the two possible cases, <code>dfs(w)</code> is done before <code>dfs(v)</code>, so <code>w</code> appears <em>before</em> <code>v</code> in postorder and <em>after</em> <code>v</code> in reverse postorder. Thus, each edge <code>v-&gt;w</code> points from a vertex earlier in the order to a vertex later in the order, as desired.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/p0582-01.jpg"/></p>
<p><a id="page_583"/><code>Topological</code> (<a href="#ch04sb26"><small>ALGORITHM 4.5</small></a> on page <a href="#ch04sb26">581</a>) is an implementation that uses depth-first search to topologically sort a DAG. A trace is given at right.</p>
<p class="image"><img alt="image" src="graphics/04_42-dfodag.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb28"/></p>
<p><strong>Proposition G.</strong> With DFS, we can topologically sort a DAG in time proportional to <em>V</em>+<em>E</em>.</p>
<p><strong>Proof:</strong> Immediate from the code. It uses one depth-first search to ensure that the graph has no directed cycles, and another to do the reverse postorder ordering. Both involve examining all the edges and all the vertices, and thus take time proportional to <em>V</em>+<em>E.</em></p>
<hr/>
</div>
<p>Despite the simplicity of this algorithm, it escaped attention for many years, in favor of a more intuitive algorithm based on maintaining a queue of sources (see <a href="#ch04qa2q30"><small>EXERCISE 4.2.30</small></a>).</p>
<p><small>IN PRACTICE</small>, topological sorting and cycle detection go hand in hand, with cycle detection playing the role of a debugging tool. For example, in a job-scheduling application, a directed cycle in the underlying digraph represents a mistake that must be corrected, no matter how the schedule was formulated. Thus, a job-scheduling application is typically a three-step process:</p>
<p class="indenthangingB">• Specify the tasks and precedence constraints.</p>
<p class="indenthangingB">• Make sure that a feasible solution exists, by detecting and removing cycles in the underlying digraph until none exist.</p>
<p class="indenthangingB">• Solve the scheduling problem, using topological sort.</p>
<p>Similarly, any changes in the schedule can be checked for cycles (using <code>DirectedCycle</code>), then a new schedule computed (using <code>Topological</code>).</p>
<p><a id="ch04sec2lev18"/></p>
<h4><a id="page_584"/>Strong connectivity in digraphs</h4>
<p>We have been careful to maintain a distinction between reachability in digraphs and connectivity in undirected graphs. In an undirected graph, two vertices <code>v</code> and <code>w</code> are connected if there is a path connecting them—we can use that path to get from <code>v</code> to <code>w</code> or to get from <code>w</code> to <code>v</code>. In a digraph, by contrast, a vertex <code>w</code> is reachable from a vertex <code>v</code> if there is a directed path from <code>v</code> to <code>w</code>, but there may or may not be a directed path back to <code>v</code> from <code>w</code>. To complete our study of digraphs, we consider the natural analog of connectivity in undirected graphs.</p>
<p class="image"><img alt="image" src="graphics/04_43-scgexamples.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb29"/></p>
<p><strong>Definition.</strong> Two vertices <code>v</code> and <code>w</code> are <em>strongly connected</em> if they are mutually reachable: that is, if there is a directed path from <code>v</code> to <code>w</code> and a directed path from <code>w</code> to <code>v</code>. A digraph is <em>strongly connected</em> if all its vertices are strongly connected to one another.</p>
<hr/>
</div>
<p>Several examples of strongly connected graphs are given in the figure at left. As you can see from the examples, cycles play an important role in understanding strong connectivity. Indeed, recalling that a general directed cycle is a directed cycle that may have repeated vertices, it is easy to see that <em>two vertices are strongly connected if and only if there exists a general directed cycle that contains them both.</em> (<em>Proof</em>: compose the paths from <code>v</code> to <code>w</code> and from <code>w</code> to <code>v</code>.)</p>
<p><a id="ch04sec3lev27"/></p>
<h5><em>Strong components</em></h5>
<p>Like connectivity in undirected graphs, strong connectivity in digraphs is an equivalence relation on the set of vertices, as it has the following properties:</p>
<p class="indenthangingB">• <em>Reflexive</em>: Every vertex <code>v</code> is strongly connected to itself.</p>
<p class="indenthangingB">• <em>Symmetric</em>: If <code>v</code> is strongly connected to <code>w</code>, then <code>w</code> is strongly connected to <code>v</code>.</p>
<p class="indenthangingB">• <em>Transitive</em>: If <code>v</code> is strongly connected to <code>w</code> and <code>w</code> is strongly connected to <code>x</code>, then <code>v</code> is also strongly connected to <code>x</code>.</p>
<p>As an equivalence relation, strong connectivity partitions the vertices into equivalence classes. The equivalence classes are maximal subsets of vertices that are strongly connected to one another, with each vertex in exactly one subset. We refer to these subsets as <em>strongly connected components</em>, or <em>strong components</em> for short. Our sample digraph <code>tinyDG.txt</code> has five strong components, as shown in the diagram at right. A digraph with <em>V</em> vertices has between 1 and <em>V</em> strong components—a strongly <a id="page_585"/>connected digraph has 1 strong component and a DAG has <em>V</em> strong components. Note that the strong components are defined in terms of the vertices, not the edges. Some edges connect two vertices in the same strong component; some other edges connect vertices in different strong components. The latter are not found on any directed cycle. Just as identifying connected components is typically important in processing undirected graphs, identifying strong components is typically important in processing digraphs.</p>
<p class="image"><img alt="image" src="graphics/04_44-sccexample.jpg"/></p>
<p><a id="ch04sec3lev28"/></p>
<h5><em>Examples of applications</em></h5>
<p>Strong connectivity is a useful abstraction in understanding the structure of a digraph, highlighting interrelated sets of vertices (strong components). For example, strong components can help textbook authors decide which topics should be grouped together and software developers decide how to organize program modules. The figure below shows an example from ecology. It illustrates a digraph that models the food web connecting living organisms, where vertices represent species and an edge from one vertex to another indicates that an organism of the species indicated by the <em>point from</em> vertex consumes organisms of the species indicated by the <em>point to</em> vertex for food. Scientific studies on such digraphs (with carefully chosen sets of species and carefully documented relationships) play an important role in helping ecologists answer basic questions about ecological systems. Strong components in such digraphs can help ecologists understand energy flow in the food web. The figure on page <a href="#page_591">591</a> shows a digraph model of web content, where vertices represent pages and edges represent hyperlinks from one page to another. Strong components in such a digraph can help network engineers partition the huge number of pages on the web into more manageable sizes for processing. Further properties of these applications and other examples are addressed in the exercises and on the booksite.</p>
<p class="image"><img alt="image" src="graphics/t0585-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_45-predator.jpg"/></p>
<p><a id="page_586"/>Accordingly, we need the following API, the analog for digraphs of <code>CC</code> (page <a href="#page_543">543</a>):</p>
<p class="image"><img alt="image" src="graphics/t0586-01.jpg"/></p>
<p>A quadratic algorithm to compute strong components is not difficult to develop (see <a href="#ch04qa2q31"><small>EXERCISE 4.2.31</small></a>), but (as usual) quadratic time and space requirements are prohibitive for huge digraphs that arise in practical applications like the ones just described.</p>
<p><a id="ch04sec3lev29"/></p>
<h5><em>Kosaraju–Sharir algorithm.</em></h5>
<p>We saw in <code>CC</code> (<a href="#ch04sb13"><small>ALGORITHM 4.3</small></a> on page <a href="#ch04sb13">544</a>) that computing connected components in undirected graphs is a simple application of depth-first search. How can we efficiently compute strong components in digraphs? Remarkably, the implementation <code>KosarajuSharirSCC</code> on the facing page does the job with just a few lines of code added to <code>CC</code>, as follows:</p>
<p class="indenthangingB">• Given a digraph <em>G</em>, use <code>DepthFirstOrder</code> to compute the reverse postorder of its reverse digraph, <em>G<sup>R</sup></em>.</p>
<p class="indenthangingB">• Run standard DFS on <em>G</em>, but consider the unmarked vertices in the order just computed instead of the standard numerical order.</p>
<p class="indenthangingB">• All vertices visited on a call to the recursive <code>dfs()</code> from the constructor are <em>a strong component</em> (!), so identify them as such, in the same manner as in <code>CC</code>.</p>
<p>The Kosaraju–Sharir algorithm is an extreme example of a method that is easy to code but difficult to understand. To persuade yourself that the algorithm is correct, start by considering the <em>kernel DAG</em> (or <em>condensation digraph</em>) associated with each digraph, formed by collapsing all the vertices in each strong component to a single vertex (and removing any self-loops). The result must be a DAG because any directed cycle would imply a larger strong component. The kernel DAG for the digraph on page 584 has fi ve vertices and seven edges, as shown at right (note the possibility of parallel edges). Since the kernel DAG is a DAG, its vertices can be placed in (reverse) topological order, as shown in the diagram at the top of page 588. This ordering is the key to understanding the Kosaraju–Sharir algorithm.</p>
<p class="image"><img alt="image" src="graphics/04_46-kosarajuproof.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb30"/></p>
<h3><a id="page_587"/>Algorithm 4.6 Kosaraju—Sharir algorithm for computing strong components</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0587-02.jpg"/></p>
<p>This implementation differs from <code>CC</code> (<a href="#ch04sb13"><small>ALGORITHM 4.3</small></a>) only in the highlighted code (and in the implementation of <code>main()</code> where we use the code on page <a href="#page_543">543</a>, with <code>Graph</code> changed to <code>Digraph</code>, <code>CC</code> changed to <code>KosarajuSharirSCC</code>, and “components” changed to “strong components”). To find strong components, it does a depth-first search in the reverse digraph to produce a vertex order (reverse postorder of that search) for use in a depth-first search of the given digraph.</p>
<hr/>
</div>
<p><a id="page_588"/>The Kosaraju-Sharir algorithm identifies the strong components in reverse topological order of the kernel DAG. It begins by finding a vertex that is in a sink component of the kernel DAG. When it runs DFS from that vertex, it visits precisely the vertices in that component. The DFS marks those vertices, effectively removing them from the digraph. Next, it finds a vertex that is in a sink component in the remaining kernel DAG, visits precisely the vertices in that component, and so forth.</p>
<p class="image"><img alt="image" src="graphics/04_46-kosarajuproofa.jpg"/></p>
<p>The postorder of <em>G<sup>R</sup></em> enables us to examine the strong components in the desired order. The first vertex in a reverse postorder of <em>G</em> is in a <em>source</em> component of the kernel DAG; the first vertex in a reverse postorder of the <em>reverse</em> digraph <em>G<sup>R</sup></em> is in a <em>sink</em> component of the kernel DAG (see <small>EXERCISE 4.2.16</small>). More generally, the following lemma relates the reverse postorder of <em>G<sup>R</sup></em> to the strong components, based on edges in the kernel DAG: it is the key to establishing the correctness of the Kosaraju—Sharir algorithm.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb31"/></p>
<p><strong>Postorder lemma.</strong> Let <em>C</em> be a strong component in a digraph <em>G</em> and let <code>v</code> be any vertex not in <em>C</em>. If there is an edge <em>e</em> pointing from any vertex in <em>C</em> to <code>v</code>, then vertex <code>v</code> appears before <em>every</em> vertex in <em>C</em> in the reverse postorder of <em>G<sup>R</sup></em>.</p>
<p><strong>Proof:</strong> See <small>EXERCISE 4.2.15</small>.</p>
<p><strong>Proposition H.</strong> The Kosaraju—Sharir algorithm identifies the strong components of a digraph <em>G</em>.</p>
<p><strong>Proof:</strong> By induction on the number of strong components identified in the DFS of <em>G</em>. After the algorithm has identified the first <em>i</em> components, we assume (by our inductive hypothesis) that the vertices in the first <em>i</em> components are marked and the vertices in the remaining components are unmarked. Let <code>s</code> be the unmarked vertex that appears first in the reverse postorder of <em>G<sup>R</sup></em>. Then, the constructor call <code>dfs(G, s)</code> will visit every vertex in the strong component containing <code>s</code> (which we refer to as component <em>i</em>+1) and only those vertices because:</p>
<p class="indenthangingB">• Vertices in the first <em>i</em> components will not be visited (because they are already marked).</p>
<p class="indenthangingB">• Vertices in component <em>i</em>+1 are not yet marked and are reachable from <em>s</em> using only other vertices in component <em>i</em>+1 (so will be visited and marked).</p>
<p class="indenthangingB">• Vertices in components after <em>i</em>+1 will not be visited (or marked): Consider (for the sake of contradiction) the first such vertex <code>v</code> that is visited. Let <em>e</em> be an edge that goes from a vertex in component <em>i</em>+1 to <code>v</code>. By the postorder lemma, <code>v</code> appears in the reverse postorder before every vertex in component <em>i</em>+1 (including s). This contradicts the definition of <code>s</code>.</p>
<hr/>
</div>
<p class="image"><a id="page_589"/><img alt="image" src="graphics/04_47-kosarajudg.jpg"/></p>
<p><a id="page_590"/>A trace of the algorithm for <code>tinyDG.txt</code> is shown on the preceding page. To the right of each DFS trace is a drawing of the digraph, with vertices appearing in the order they are done. Thus, reading up the reverse digraph drawing on the left gives the reverse postorder in <em>G<sup>R</sup></em>, the order in which unmarked vertices are checked in the DFS of <em>G</em>. As you can see from the diagram, the second DFS calls <code>dfs(1)</code> (which marks vertex <code>1</code>) then calls <code>dfs(0)</code> (which marks <code>5, 4, 3</code>, and <code>2</code>), then checks <code>2, 4, 5</code>, and <code>3</code>, then calls <code>dfs(11)</code> (which marks <code>11, 12, 9</code>, and <code>10</code>), then checks <code>9, 12</code>, and <code>10</code>, then calls <code>dfs(6)</code> (which marks <code>6</code> and <code>8</code>), and finally <code>dfs(7)</code>, which marks <code>7</code>.</p>

<p>A larger example, a very small subset of a digraph model of the web, is shown on the facing page.</p>
<p><small>THE KOSARAJU–SHARIR ALGORITHM</small> solves the following analog of the connectivity problem for undirected graphs that we first posed in <small>CHAPTER 1</small> and reintroduced in <small>SECTION 4.1</small> (page 534):</p>
<p class="indenthanging"><strong><em>Strong connectivity.</em></strong> Given a digraph, support queries of the form: <em>Are two given vertices strongly connected? and How many strong components does the digraph have?</em></p>

<p>That we can solve this problem in digraphs as efficiently as the corresponding connectivity problem in undirected graphs was an open research problem for some time (resolved by R. E. Tarjan in the early 1970s). That such a simple solution is now available is quite surprising.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb32"/></p>
<p><strong>Proposition I.</strong> The Kosaraju–Sharir algorithm uses preprocessing time and space proportional to <em>V+E</em> to support constant-time strong connectivity queries in a digraph.</p>
<p><strong>Proof:</strong> The algorithm computes the reverse of the digraph and does two depth-first searches. Each of these three steps takes time proportional to <em>V+E</em>. The reverse copy of the digraph uses space proportional to <em>V+E</em>.</p>
<hr/>
</div>
<p class="image"><a id="page_591"/><img alt="image" src="graphics/04_48-scclarge.jpg"/></p>
<p><a id="ch04sec3lev30"/></p>
<h5><em>Reachability revisited</em></h5>
<p>With <code>CC</code> for undirected graphs, we can infer from the fact that two vertices <code>v</code> and <code>w</code> are connected that there is a path from <code>v</code> to <code>w</code> and a path (the same one) from <code>w</code> to <code>v</code>. With <code>KosarajuSharirCC</code>, we can infer from the fact that <code>v</code> and <code>w</code> are strongly connected that there is a path from <code>v</code> to <code>w</code> and a path (a different one) from <code>w</code> to <code>v</code>. But what about pairs of vertices that are not strongly connected? There may be a path from <code>v</code> to <code>w</code> or a path from <code>w</code> to <code>v</code> or neither, but not both.</p>
<p class="indenthanging"><strong><em>All-pairs reachability.</em></strong> Given a digraph, support queries of the form <em>Is there a directed path from a given vertex</em> <code>v</code> <em>to another given vertex</em> <code>w</code>?</p>
<p>For undirected graphs, the corresponding problem is equivalent to the connectivity problem; for digraphs, it is quite different from the strong connectivity problem. Our <code>CC</code> implementation uses linear preprocessing time to support constant-time answers to such queries for undirected graphs. Can we achieve this performance for digraphs? This seemingly innocuous question has confounded experts for decades. To better <a id="page_592"/>understand the challenge, consider the diagram at left, which illustrates the following fundamental concept:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb33"/></p>
<p><strong>Definition.</strong> The <em>transitive closure</em> of a digraph <em>G</em> is another digraph with the same set of vertices, but with an edge from <code>v</code> to <code>w</code> in the transitive closure if and only if <code>w</code> is reachable from <code>v</code> in <em>G</em>.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_49-tcex.jpg"/></p>
<p>By convention, every vertex is reachable from itself, so the transitive closure has <em>V</em> self-loops. Our sample digraph has just 13 directed edges, but its transitive closure has 108 out of a possible 169 directed edges. Generally, the transitive closure of a digraph has many more edges than the digraph itself, and it is not at all unusual for a sparse graph to have a dense transitive closure. For example, the transitive closure of a <em>V</em>-vertex directed cycle, which has <em>V</em> directed edges, is a complete digraph with <em>V</em><sup>2</sup> directed edges. Since transitive closures are typically dense, we normally represent them with a matrix of boolean values, where the entry in row <code>v</code> and column <code>w</code> is <code>true</code> if and only if <code>w</code> is reachable from <code>v</code>. Instead of explicitly computing the transitive closure, we use depth-first search to implement the following API:</p>
<p class="image"><img alt="image" src="graphics/t0592-01.jpg"/></p>
<p>The code below is a straightforward implementation that uses <code>DirectedDFS</code> (<a href="#ch04sb21"><small>ALGORITHM 4.4</small></a>). This solution is ideal for small or dense digraphs, but it is not a solution for the large digraphs we might encounter in practice because <em>the constructor uses space proportional to V</em><sup>2</sup> <em>and time proportional to V</em> (<em>V</em>+<em>E</em>): each of the <em>V</em> <code>DirectedDFS</code> objects takes space proportional to <em>V</em> (they all have <code>marked[]</code> arrays of size <em>V</em> and examine <em>E</em> edges to compute the marks). Essentially, <code>TransitiveClosure</code> <a id="page_593"/>computes and stores the transitive closure of <em>G</em>, to support constant-time queries—row <code>v</code> in the transitive closure matrix is the <code>marked[]</code> array for the <code>v</code>th entry in the <code>DirectedDFS[]</code> in <code>TransitiveClosure</code>. Can we support constant-time queries with substantially less preprocessing time and substantially less space? A general solution that achieves constant-time queries with substantially less than quadratic space is an unsolved research problem, with important practical implications: for example, until it is solved, we cannot hope to have a practical solution to the all-pairs reachability problem for a giant digraph such as the web graph.</p>
<p class="image"><img alt="image" src="graphics/p0593-01.jpg"/></p>
<p><a id="ch04sec2lev19"/></p>
<h4><a id="page_594"/>Summary</h4>
<p>In this section, we have introduced directed edges and digraphs, emphasizing the relationship between digraph processing and corresponding problems for undirected graphs, as summarized in the following list of topics:</p>
<p class="indenthangingB">• Digraph nomenclature</p>
<p class="indenthangingB">• The idea that the representation and approach are essentially the same as for undirected graphs, but some digraph problems are more complicated</p>
<p class="indenthangingB">• Cycles, DAGs, topological sort, and precedence-constrainted scheduling</p>
<p class="indenthangingB">• Reachability, paths, and strong connectivity in digraphs</p>
<p>The table below summarizes the implementations of digraph algorithms that we have considered (all but one of the algorithms are based on depth-first search). The problems addressed are all simply stated, but the solutions that we have considered range from easy adaptations of corresponding algorithms for undirected graphs to an ingenious and surprising solution. These algorithms are a starting point for several of the more complicated algorithms that we consider in <a href="ch04a.html#ch04sec1lev13"><small>SECTION 4.4</small></a>, when we consider <em>edge-weighted</em> digraphs.</p>
<p class="image"><img alt="image" src="graphics/t0594-01.jpg"/></p>
<p><a id="ch04sec2lev20"/></p>
<h4><a id="page_595"/>Q&amp;A</h4>
<p><strong>Q.</strong> Is a self-loop a cycle?</p>
<p><strong>A.</strong> Yes, but no self-loop is needed for a vertex to be reachable from itself.</p>
<p><a id="ch04sec2lev21"/></p>
<h4><a id="page_596"/>Exercises</h4>
<p><a id="ch04qa2q1"/><strong>4.2.1</strong> What is the maximum number of edges in a digraph with <em>V</em> vertices and no parallel edges? What is the minimum number of edges in a digraph with <em>V</em> vertices, none of which are isolated?</p>
<p class="image"><img alt="image" src="graphics/04_50-tinygex2.jpg"/></p>
<p><a id="ch04qa2q2"/><strong>4.2.2</strong> Draw, in the style of the figure in the text (page <a href="#page_524">524</a>), the adjacency lists built by <code>Digraph</code>’s input stream constructor for the file <code>tinyDGex2.txt</code> depicted at left.</p>
<p><a id="ch04qa2q3"/><strong>4.2.3</strong> Create a copy constructor for <code>Digraph</code> that takes as input a digraph <code>G</code> and creates and initializes a new copy of the digraph. Any changes a client makes to <code>G</code> should not affect the newly created digraph.</p>
<p><a id="ch04qa2q4"/><strong>4.2.4</strong> Add a method <code>hasEdge()</code> to <code>Digraph</code> which takes two <code>int</code> arguments <code>v</code> and <code>w</code> and returns <code>true</code> if the graph has an edge <code>v-&gt;w</code>, <code>false</code> otherwise.</p>
<p><a id="ch04qa2q5"/><strong>4.2.5</strong> Modify <code>Digraph</code> to disallow parallel edges and self-loops.</p>
<p><a id="ch04qa2q6"/><strong>4.2.6</strong> Develop a test client for <code>Digraph</code>.</p>
<p><a id="ch04qa2q7"/><strong>4.2.7</strong> The <em>indegree</em> of a vertex in a digraph is the number of directed edges that point to that vertex. The <em>outdegree</em> of a vertex in a digraph is the number of directed edges that emanate from that vertex. No vertex is reachable from a vertex of outdegree 0, which is called a <em>sink</em>; a vertex of indegree 0, which is called a <em>source</em>, is not reachable from any other vertex. A digraph where self-loops are allowed <em>and</em> every vertex has outdegree 1 is called a <em>map</em> (a function from the set of integers from 0 to <em>V</em>–1 onto itself). Write a program <code>Degrees.java</code> that implements the following API:</p>
<p class="image"><img alt="image" src="graphics/t0596-01.jpg"/></p>
<p><a id="page_597"/><a id="ch04qa2q8"/><strong>4.2.8</strong> Draw all the nonisomorphic DAGs with two, three, four, and five vertices (see <a href="#ch04qa1q28"><small>EXERCISE 4.1.28</small></a>).</p>
<p><a id="ch04qa2q9"/><strong>4.2.9</strong> Write a method that checks whether a given permutation of a DAG’s vertices is a topological order of that DAG.</p>
<p><a id="ch04qa2q10"/><strong>4.2.10</strong> Given a DAG, does there exist a topological order that cannot result from applying a DFS-based algorithm, no matter in what order the vertices adjacent to each vertex are chosen? Prove your answer.</p>
<p><a id="ch04qa2q11"/><strong>4.2.11</strong> Describe a family of sparse digraphs whose number of directed cycles grows exponentially in the number of vertices.</p>
<p><a id="ch04qa2q12"/><strong>4.2.12</strong> Prove that the strong components in <em>G<sup>R</sup></em> are the same as in <em>G</em>.</p>
<p><a id="ch04qa2q13"/><strong>4.2.13</strong> Prove that two vertices in a digraph G are in the same strong component if and only if there is a directed cycle (not necessarily simple) containing both of them.</p>
<p><a id="ch04qa2q14"/><strong>4.2.14</strong> Let <em>C</em> be a strong component in a digraph <em>G</em> and let <em>v</em> be any vertex not in <em>C</em>. Prove that if there is an edge <em>e</em> pointing from <em>v</em> to any vertex in <em>C</em>, then vertex <em>v</em> appears before <em>every</em> vertex in <em>C</em> in the reverse postorder of <em>G</em>.</p>
<p><em>Solution</em>: If <code>v</code> is visited before every vertex in <em>C</em>, then every vertex in <em>C</em> will be visited and finished before <code>v</code> finishes (because every vertex in <em>C</em> is reachable from <em>v</em> via edge <em>e</em>). If some vertex in <em>C</em> is visited before <code>v</code>, then all vertices in <em>C</em> will be visited and finished before <code>v</code> is visited (because <code>v</code> is not reachable from any vertex in <em>C</em>—if it were, such a path when combined with edge <em>e</em> would be part of a directed cycle, implying that <code>v</code> is in <em>C</em>).</p>
<p><a id="ch04qa2q15"/><strong>4.2.15</strong> Let <em>C</em> be a strong component in a digraph <em>G</em> and let <code>v</code> be any vertex not in <em>C</em>. Prove that if there is an edge <em>e</em> pointing from any vertex in <em>C</em> to <code>v</code>, then vertex <code>v</code> appears before <em>every</em> vertex in <em>C</em> in the reverse postorder of <em>G<sup>R</sup></em>.</p>
<p><em>Solution</em>: Apply <small>EXERCISE 4.2.14</small> to <em>G<sup>R</sup></em>.</p>
<p><a id="ch04qa2q16"/><strong>4.2.16</strong> Given a digraph <em>G</em>, prove that the first vertex in the reverse postorder of <em>G</em> is in a strong component that is a <em>source</em> of <em>G’s</em> kernel DAG. Then, prove that the first vertex in the reverse postorder of <em>G<sup>R</sup></em> is in a strong component that is a sink of <em>G’s</em> kernel DAG.</p>
<p><em>Hint</em>: Apply <small>EXERCISES 4.2.14</small> and <small>4.2.15</small>.</p>
<p><a id="ch04qa2q17"/><strong>4.2.17</strong> How many strong components are there in the digraph on page 591?</p>
<p><a id="ch04qa2q18"/><strong>4.2.18</strong> What are the strong components of a DAG?.</p>
<p><a id="ch04sec2lev22"/></p>
<h4><a id="page_598"/>Creative Problems</h4>
<p><a id="ch04qa2q19"/><strong>4.2.19</strong> What happens if you run the Kosaraju–Sharir algorithm on a DAG?</p>
<p><a id="ch04qa2q20"/><strong>4.2.20</strong> True or false: The reverse postorder of a digraph's reverse is the same as the postorder of the digraph.</p>
<p><a id="ch04qa2q21"/><strong>4.2.21</strong> True or false: If we consider the vertices of a digraph <em>G</em> (or its reverse <em>G<sup>R</sup></em>) in postorder, then vertices in the same strong component will be consecutive in that order.</p>

<p><a id="ch04qa2q22"/><strong>4.2.22</strong> True or false: If we modify the Kosaraju–Sharir algorithm to run first depth-first search in the digraph <em>G</em> (instead of the reverse digraph <em>G<sup>R</sup></em>) and the second depth-first search in <em>G<sup>R</sup></em> (instead of <em>G</em>), then it will still find the strong components.</p>
<p><a id="ch04qa2q23"/><strong>4.2.23</strong> True or false: If we modify the Kosaraju–Sharir algorithm to replace the second depth-first search with breadth-first search, then it will still find the strong components.</p>
<p><a id="ch04qa2q24"/><strong>4.2.24</strong> Compute the memory usage of a <code>Digraph</code> with <em>V</em> vertices and <em>E</em> edges, under the memory cost model of <small>SECTION 1.4</small>.</p>
<p><a id="ch04qa2q25"/><strong>4.2.25</strong> How many edges are there in the transitive closure of a digraph that is a simple directed path with <em>V</em> vertices and <em>V–1</em> edges?</p>
<p><a id="ch04qa2q26"/><strong>4.2.26</strong> Give the transitive closure of the digraph with ten vertices and these edges:</p>
<p>3-&gt;7 1-&gt;4 7-&gt;8 0-&gt;5 5-&gt;2 3-&gt;8 2-&gt;9 0-&gt;6 4-&gt;9 2-&gt;6 6-&gt;4</p>
<p><a id="ch04qa2q27"/><strong>4.2.27</strong> <em>Topological sort and BFS</em>. Explain why the following algorithm does not necessarily produce a topological order: Run BFS, and label the vertices by increasing distance to their respective source.</p>
<p><a id="ch04qa2q28"/><strong>4.2.28</strong> <em>Directed Eulerian cycle</em>. An directed Eulerian cycle is a directed cycle that contains each edge exactly once. Write a digraph client <code>Euler</code> that finds a directed Eulerian cycle or reports that no such cycle exists. <em>Hint</em>: Prove that a digraph <em>G</em> has a directed Eulerian cycle if and only if <em>G</em> is connected and each vertex has its indegree equal to its outdegree.</p>
<p><a id="ch04qa2q29"/><strong>4.2.29</strong> <em>LCA of a DAG</em>. Given a DAG and two vertices <code>v</code> and <code>w</code>, find the <em>lowest common ancestor</em> (LCA) of <code>v</code> and <code>w</code>. The LCA of <code>v</code> and <code>w</code> is an ancestor of <code>v</code> and <code>w</code> that has no descendants that are also ancestors of <code>v</code> and <code>w</code>. Computing the LCA is useful in multiple inheritance in programming languages, analysis of genealogical data (find degree of inbreeding in a pedigree graph), and other applications. <em>Hint</em>: Define the height of a vertex <code>v</code> in a DAG to be the length of the longest path from a root to <code>v</code>. Among vertices that are ancestors of both <code>v</code> and <code>w</code>, the one with the greatest height is an LCA of <code>v</code> and <code>w</code>.</p>
<p><a id="ch04qa2q30"/><strong>4.2.30</strong> <em>Shortest ancestral path</em>. Given a DAG and two vertices <code>v</code> and <code>w</code>, find the shortest ancestral path between <code>v</code> and <code>w</code>. An ancestral path between <code>v</code> and <code>w</code> is a common ancestor <code>x</code> along with a shortest path from <code>v</code> to <code>x</code> and a shortest path from <code>w</code> to <code>x</code>. The shortest ancestral path is the ancestral path whose total length is minimized. <em>Warmup</em>: Find a DAG where the shortest ancestral path goes to a common ancestor <code>x</code> that is not an LCA. <em>Hint</em>: Run BFS twice, once from v and once from <code>w</code>.</p>
<p><a id="ch04qa2q31"/><strong>4.2.31</strong> <em>Strong component</em>. Describe a linear-time algorithm for computing the strong component containing a given vertex <code>v</code>. On the basis of that algorithm, describe a simple quadratic-time algorithm for computing the strong components of a digraph.</p>
<p><a id="ch04qa2q32"/><strong>4.2.32</strong> <em>Hamiltonian path in DAGs</em>. Given a DAG, design a linear-time algorithm to determine whether there is a directed path that visits each vertex exactly once.</p>
<p><em>Solution</em>: Compute a topological sort and check if there is an edge between each consecutive pair of vertices in the topological order.</p>
<p><a id="ch04qa2q33"/><strong>4.2.33</strong> <em>Unique topological ordering</em>. Design an algorithm to determine whether a digraph has a unique topological ordering. <em>Hint</em>: A digraph has a unique topological ordering if and only if there is a directed edge between each pair of consecutive vertices in the topological order (i.e., the digraph has a Hamiltonian path). If the digraph has multiple topological orderings, then a second topological order can be obtained by swapping a pair of consecutive vertices.</p>
<p><a id="page_599"/><a id="ch04qa2q34"/><strong>4.2.34</strong> <em>2-satisfiability</em>. Given a boolean formula in conjunctive normal form with M clauses and <em>N</em> literals such that each clause has exactly two literals, find a satisfying assignment (if one exists). <em>Hint</em>: Form the <em>implication digraph</em> with 2<em>N</em> vertices (one per literal and its negation). For each clause <em>x</em> + <em>y</em>, include edges from <em>y′</em> to <em>x</em> and from <em>x′</em> to <em>y</em>. <em>Claim</em>: The formula is satisfiable if and only if no variable <em>x</em> is in the same strong component as its negation <em>x′</em>. Moreover, a topological sort of the <em>kernel DAG</em> (contract each strong component to a single vertex) yields a satisfying assignment.</p>
<p><a id="ch04qa2q35"/><strong>4.2.35</strong> <em>Digraph enumeration</em>. Show that the number of different <em>V</em>-vertex digraphs with no parallel edges is 2<sup><em>V</em><sup>2</sup></sup> . (How many digraphs are there that contain <em>V</em> vertices and <em>E</em> edges?) Then compute an upper bound on the percentage of 20-vertex digraphs that could ever be examined by any computer, under the assumptions that every electron in the universe examines a digraph every nanosecond, that the universe has fewer than 10<sup>80</sup> electrons, and that the age of the universe will be less than 10<sup>20</sup> years.</p>
<p><a id="ch04qa2q36"/><strong>4.2.36</strong> <em>DAG enumeration</em>. Give a formula for the number of <em>V</em>-vertex DAGs with <em>E</em> edges.</p>
<p><a id="ch04qa2q37"/><strong>4.2.37</strong> <em>Arithmetic expressions</em>. Write a class that evaluates DAGs that represent arithmetic expressions. Use a vertex-indexed array to hold values corresponding to each vertex. Assume that values corresponding to leaves have been established. Describe a family of arithmetic expressions with the property that the size of the expression tree is exponentially larger than the size of the corresponding DAG (so the running time of your program for the DAG is proportional to the logarithm of the running time for the tree).</p>
<p><a id="page_602"/><a id="ch04qa2q38"/><strong>4.2.38</strong> <em>Euclidean digraphs</em>. Modify your solution to <small>EXERCISE 4.1.37</small> to create an API <code>EuclideanDigraph</code> for graphs whose vertices are points in the plane, so that you can work with graphical representations.</p>
<p><a id="ch04qa2q39"/><strong>4.2.39</strong> <em>Queue-based topological sort</em>. Develop a topological sort implementation that maintains a vertex-indexed array that keeps track of the indegree of each vertex. Initialize the array and a queue of sources in a single pass through all the edges, as in <small>EXERCISE 4.2.7</small>. Then, perform the following operations until the source queue is empty:</p>
<p class="indenthangingB">• Remove a source from the queue and label it.</p>
<p class="indenthangingB">• Decrement the entries in the indegree array corresponding to the destination vertex of each of the removed vertex’s edges.</p>
<p class="indenthangingB">• If decrementing any entry causes it to become 0, insert the corresponding vertex onto the source queue.</p>
<p><a id="ch04qa2q40"/><strong>4.2.40</strong> <em>Shortest directed cycle</em>. Given a digraph, design an algorithm to find a directed cycle with the minimum number of edges (or report that the graph is acyclic). The running time of your algorithm should be proportional to <em>E V</em> in the worst case.</p>
<p><a id="ch04qa2q41"/><strong>4.2.41</strong> <em>Odd-length directed cycle.</em> Design a linear-time algorithm to determine whether a digraph has an odd-length directed cycle.</p>
<p><a id="ch04qa2q42"/><strong>4.2.42</strong> <em>Reachable vertex in a DAG</em>. Design a linear-time algorithm to determine whether a DAG has a vertex that is reachable from every other vertex.</p>
<p><strong>4.2.43</strong> <em>Reachable vertex in a digraph</em>. Design a linear-time algorithm to determine whether a digraph has a vertex that is reachable from every other vertex.</p>
<p><strong>4.2.44</strong> <em>Web crawler</em>. Write a program that uses breadth-first search to crawl the web digraph, starting from a given web page. Do not explicitly build the web digraph.</p>
<p><a id="ch04sec2lev23"/></p>
<h4><a id="page_603"/>Experiments</h4>
<p><strong>4.2.45</strong> <em>Random digraphs</em>. Write a program <code>ErdosRenyiDigraph</code> that takes integer values <em>V</em> and <em>E</em> from the command line and builds a digraph by generating <em>E</em> random pairs of integers between 0 and <em>V</em>—1. <em>Note</em>: This generator produces self-loops and parallel edges.</p>
<p><strong>4.2.46</strong> <em>Random simple digraphs</em>. Write a program <code>RandomDigraph</code> that takes integer values <em>V</em> and <em>E</em> from the command line and produces, with equal likelihood, each of the possible <em>simple</em> digraphs with <em>V</em> vertices and <em>E</em> edges.</p>
<p><strong>4.2.47</strong> <em>Random sparse digraphs</em>. Modify your solution to <small>EXERCISE 4.1.41</small> to create a program <code>RandomSparseDigraph</code> that generates random sparse digraphs for a well-chosen set of values of <em>V</em> and <em>E</em> that you can use it to run meaningful empirical tests.</p>
<p><strong>4.2.48</strong> <em>Random Euclidean digraphs</em>. Modify your solution to <small>EXERCISE 4.1.42</small> to create a <code>EuclideanDigraph</code> client <code>RandomEuclideanDigraph</code> that assigns a random direction to each edge.</p>
<p><strong>4.2.49</strong> <em>Random grid digraphs</em>. Modify your solution to <small>EXERCISE 4.1.43</small> to create a <code>EuclideanDiGraph</code> client <code>RandomGridDigraph</code> that assigns a random direction to each edge.</p>
<p><strong>4.2.50</strong> <em>Real-world digraphs</em>. Find a large digraph somewhere online—perhaps a transaction graph in some online system, or a digraph defined by links on web pages. Write a program <code>RandomRealDigraph</code> that builds a graph by choosing <em>V</em> vertices at random and <em>E</em> directed edges at random from the subgraph induced by those vertices.</p>
<p><strong>4.2.51</strong> <em>Real-world DAG</em>. Find a large DAG somewhere online—perhaps one defined by class-definition dependencies in a large software system, or by directory links in a large file system. Write a program <code>RandomRealDAG</code> that builds a graph by choosing <em>V</em> vertices at random and <em>E</em> directed edges at random from the subgraph induced by those vertices.</p>
<p><em>Testing all algorithms and studying all parameters against all graph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input graph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</em></p>
<p><strong>4.2.52</strong> <em>Reachability</em>. Run experiments to determine empirically the average number of vertices that are reachable from a randomly chosen vertex, for various digraph models.</p>
<p><strong>4.2.53</strong> <em>Path lengths in DFS</em>. Run experiments to determine empirically the probability that <code>DepthFirstDirectedPaths</code> finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various random digraph models.</p>
<p><strong>4.2.54</strong> <em>Path lengths in BFS</em>. Run experiments to determine empirically the probability that <code>BreadthFirstDirectedPaths</code> finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various random digraph models.</p>
<p><strong>4.2.55</strong> <em>Strong components</em>. Run experiments to determine empirically the distribution of the number of strong components in random digraphs of various types, by generating large numbers of digraphs and drawing a histogram.</p>
<p><a id="ch04sec1lev12"/></p>
<h3><a id="page_604"/>4.3 Minimum Spanning Trees</h3>
<p>AN <em>edge-weighted graph</em> is a graph model where we associate <em>weights</em> or <em>costs</em> with each edge. Such graphs are natural models for many applications. In an airline map where edges represent flight routes, these weights might represent distances or fares. In an electric circuit where edges represent wires, the weights might represent the length of the wire, its cost, or the time that it takes a signal to propagate through it. Minimizing cost is naturally of interest in such situations. In this section, we consider <em>undirected</em> edge-weighted graph models and examine algorithms for one such problem:</p>
<p class="indenthanging"><strong><em>Minimum spanning tree.</em></strong> Given an undirected edge-weighted graph, find an MST.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb34"/></p>
<p><strong>Definition.</strong> Recall that a <em>spanning tree</em> of a graph is a connected subgraph with no cycles that includes all the vertices. A <em>minimum spanning tree</em> (MST) of an edge-weighted graph is a spanning tree whose weight (the sum of the weights of its edges) is no larger than the weight of any other spanning tree.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_51-tinymst.jpg"/></p>
<p>In this section, we examine two classical algorithms for computing MSTs: <em>Prim’s algorithm</em> and <em>Kruskal’s algorithm</em>. These algorithms are easy to understand and not difficult to implement. They are among the oldest and most well-known algorithms in this book, and they also take good advantage of modern data structures. Since MSTs have numerous important applications, algorithms to solve the problem have been studied at least since the 1920s, at first in the context of power distribution networks, later in the context of telephone networks. MST algorithms are now important in the design of many types of networks (communication, electrical, hydraulic, computer, road, rail, air, and many others) and also in the study of biological, chemical, and physical networks that are found in nature.</p>
<p class="image"><img alt="image" src="graphics/t0604-01.jpg"/></p>
<p><a id="ch04sec2lev24"/></p>
<h4><a id="page_605"/><em>Assumptions</em></h4>
<p>Various anomalous situations, which are generally easy to handle, can arise when computing minimum spanning trees. To streamline the presentation, we adopt the following conventions:</p>
<p class="indenthangingB">• <em>The graph is connected</em>. The spanning-tree condition in our definition implies that the graph must be connected for an MST to exist. Another way to pose the problem, recalling basic properties of trees from <a href="#ch04sec1lev10"><small>SECTION 4.1</small></a>, is to find a minimal-weight set of <em>V</em>−1 edges that connect the graph. If a graph is not connected, we can adapt our algorithms to compute the MSTs of each of its connected components, collectively known as a <em>minimum spanning forest</em> (see <a href="#ch04qa3q22"><small>EXERCISE 4.3.22</small></a>).</p>
<p class="image"><img alt="image" src="graphics/04_52-tinyconventions.jpg"/></p>
<p class="indenthangingB">• <em>The edge weights are not necessarily distances.</em> Geometric intuition is sometimes beneficial in understanding algorithms, so we use examples where vertices are points in the plane and weights are distances, such as the graph on the facing page. But it is important to remember that the weights might represent time or cost or an entirely different variable and do not need to be proportional to a distance at all.</p>
<p class="indenthangingB">• <em>The edge weights may be zero or negative.</em> If the edge weights are all positive, it suffices to define the MST as the subgraph with minimal total weight that connects all the vertices, as such a subgraph must form a spanning tree. The spanning-tree condition in the definition is included so that it applies for graphs that may have zero negative edge weights.</p>
<p class="indenthangingB">• <em>The edge weights are all different.</em> If edges can have equal weights, the minimum spanning tree may not be unique (see <a href="#ch04qa3q2"><small>EXERCISE 4.3.2</small></a>). The possibility of multiple MSTs complicates the correctness proofs of some of our algorithms, so we rule out that possibility in the presentation. It turns out that this assumption is not restrictive because our algorithms work without modification in the presence of equal weights.</p>
<p>In summary, we assume throughout the presentation that our job is to find the MST of a connected edge-weighted graph with arbitrary (but distinct) weights.</p>
<p><a id="ch04sec2lev25"/></p>
<h4><a id="page_606"/>Underlying principles</h4>
<p>To begin, we recall from <a href="#ch04sec1lev10"><small>SECTION 4.1</small></a> two of the defining properties of a tree:</p>
<p class="indenthangingB">• Adding an edge that connects two vertices in a tree creates a unique cycle.</p>
<p class="indenthangingB">• Removing an edge from a tree breaks it into two separate subtrees.</p>
<p class="image"><img alt="image" src="graphics/04_53-basictree.jpg"/></p>
<p>These properties are the basis for proving a fundamental property of MSTs that leads to the MST algorithms that we consider in this section.</p>
<p><a id="ch04sec3lev31"/></p>
<h5><em>Cut property</em></h5>
<p>This property, which we refer to as the <em>cut property</em>, has to do with identifying edges that must be in the MST of a given edge-weighted graph, by dividing vertices into two sets and examining edges that cross the division.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb35"/></p>
<p><strong>Definition.</strong> A <em>cut</em> of a graph is a partition of its vertices into two nonempty disjoint sets. A <em>crossing edge</em> of a cut is an edge that connects a vertex in one set with a vertex in the other.</p>
<hr/>
</div>
<p>Typically, we specify a cut by specifying a set of vertices, leaving implicit the assumption that the cut comprises the given vertex set and its complement, so that a crossing edge is an edge from a vertex in the set to a vertex not in the set. In figures, we draw vertices on one side of the cut in gray and vertices on the other side in white.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb36"/></p>
<p><strong>Proposition J. (Cut property)</strong> Given any cut in an edge-weighted graph, the crossing edge of minimum weight is in the MST of the graph.</p>
<p><strong>Proof:</strong> Let <em>e</em> be the crossing edge of minimum weight and let <em>T</em> be the MST. The proof is by contradiction: Suppose that <em>T</em> does not contain <em>e</em>. Now consider the graph formed by adding <em>e</em> to <em>T</em>. This graph has a cycle that contains <em>e</em>, and that cycle must contain at least one other crossing edge—say, <em>f</em>, which has higher weight than <em>e</em> (since <em>e</em> is minimal and all edge weights are different). We can get a spanning tree of strictly lower weight by deleting <em>f</em> and adding <em>e,</em> contradicting the assumed minimality of <em>T</em>.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_54-cut.jpg"/></p>
<p><a id="page_607"/>Under our assumption that edge weights are distinct, every connected graph has a unique MST (see <a href="#ch04qa3q3"><small>EXERCISE 4.3.3</small></a>); and the cut property says that the shortest crossing edge for every cut must be in the MST.</p>
<p class="image"><img alt="image" src="graphics/04_55-cuttwo.jpg"/></p>
<p>The figure to the left of <a href="#ch04sb36"><small>PROPOSITION J</small></a> illustrates the cut property. Note that there is no requirement that the minimal edge be the <em>only</em> MST edge connecting the two sets; indeed, for typical cuts there are several MST edges that connect a vertex in one set with a vertex in the other, as illustrated in the figure above.</p>
<p class="image"><img alt="image" src="graphics/04_56-greedy.jpg"/></p>
<p><a id="ch04sec3lev32"/></p>
<h5><em>Greedy algorithm</em></h5>
<p>The cut property is the basis for the algorithms that we consider for the MST problem. Specifically, they are special cases of a general paradigm known as the <em>greedy algorithm</em>: apply the cut property to accept an edge as an MST edge, continuing until finding all of the MST edges. Our algorithms differ in their approaches to maintaining cuts and identifying the crossing edge of minimum weight, but are special cases of the following:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb37"/></p>
<p><strong>Proposition K. (Greedy MST algorithm)</strong> The following method colors black all edges in the the MST of any connected edge-weighted graph with <em>V</em> vertices: starting with all edges colored gray, find a cut with no black edges, color its minimum-weight edge black, and continue until <em>V</em>−1 edges have been colored black.</p>
<p><strong>Proof:</strong> For simplicity, we assume in the discussion that the edge weights are all different, though the proposition is still true when that is not the case (see <a href="#ch04qa3q5"><small>EXERCISE 4.3.5</small></a>). By the cut property, any edge that is colored black is in the MST. If fewer than <em>V</em>−1 edges are black, a cut with no black edges exists (recall that we assume the graph to be connected). Once <em>V</em>−1 edges are black, the black edges form a spanning tree.</p>
<hr/>
</div>
<p>The diagram at right is a typical trace of the greedy algorithm. Each drawing depicts a cut and identifies the minimum-weight edge in the cut (thick red) that is added to the MST by the algorithm.</p>
<p><a id="ch04sec2lev26"/></p>
<h4><a id="page_608"/>Edge-weighted graph data type</h4>
<p>How should we represent edge-weighted graphs? Perhaps the simplest way to proceed is to extend the basic graph representations from <a href="#ch04sec1lev10"><small>SECTION 4.1</small></a>: in the adjacency-matrix representation, the matrix can contain edge weights rather than boolean values; in the adjacency-lists representation, we can define a node that contains both a vertex and a weight field to put in the adjacency lists. (As usual, we focus on sparse graphs and leave the adjacency-matrix representation for exercises.) This classic approach is appealing, but we will use a different method that is not much more complicated, will make our programs useful in more general settings, and needs a slightly more general API, which allows us to process <code>Edge</code> objects:</p>
<p class="image"><img alt="image" src="graphics/t0608-01.jpg"/></p>
<p>The <code>either()</code> and <code>other()</code> methods for accessing the edge’s vertices may be a bit puzzling at first—the need for them will become plain when we examine client code. You can find an implementation of <code>Edge</code> on page <a href="#ch04sb38">610</a>. It is the basis for this <code>EdgeWeightedGraph</code> API, which refers to <code>Edge</code> objects in a natural manner:</p>
<p class="image"><img alt="image" src="graphics/t0608-02.jpg"/></p>
<p><a id="page_609"/>This API is very similar to the API for <code>Graph</code> (page <a href="#page_522">522</a>). The two important differences are that it is based on <code>Edge</code> and that it adds the <code>edges()</code> method at right, which provides clients with the ability to iterate through to all the graph’s edges (ignoring any self-loops). The rest of the implementation of <code>EdgeWeightedGraph</code> on page <a href="#ch04sb39">611</a> is quite similar to the unweighted undirected graph implementation of <a href="#ch04sec1lev10"><small>SECTION 4.1</small></a>, but instead of the adjacency lists of integers used in <code>Graph</code>, it uses adjacency lists of <code>Edge</code> objects.</p>
<p class="image"><img alt="image" src="graphics/p0609-01.jpg"/></p>
<p>The figure at the bottom of this page shows the edge-weighted graph representation that <code>EdgeWeightedGraph</code> builds from the sample file <code>tinyEWG.txt</code>, showing the contents of each <code>Bag</code> as a linked list to reflect the standard implementation of <a href="ch01a.html#ch01sec1lev5"><small>SECTION 1.3</small></a>. To reduce clutter in the figure, we show each <code>Edge</code> as a pair of <code>int</code> values and a <code>double</code> value. The actual data structure is a linked list of links to objects containing those values. In particular, although there are two <em>references</em> to each <code>Edge</code> (one in the list for each vertex), there is only one <code>Edge</code> object corresponding to each graph edge. In the figure, the edges appear in each list in reverse order of the order they are processed, because of the stack-like nature of the standard linked-list implementation. As in <code>Graph</code>, by using a <code>Bag</code> we are making clear that our client code makes no assumptions about the order of objects in the lists.</p>
<p class="image"><img alt="image" src="graphics/04_57-weightedgraphrep.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb38"/></p>
<h3><a id="page_610"/>Weighted edge data type</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0610-01.jpg"/></p>
<p>This data type provides the methods <code>either()</code> and <code>other()</code> so that such clients can use <code>other(v)</code> to find the other vertex when it knows <code>v</code>. When neither vertex is known, our clients use the idiomatic code <code>int v = e.either(), w = e.other(v);</code> to access an <code>Edge e</code>’s two vertices.</p>
<hr/>
</div>
<div class="sidebar">
<hr/>
<p><a id="ch04sb39"/></p>
<h3><a id="page_611"/>Edge-weighted graph data type</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0611-01.jpg"/></p>
<p>This implementation maintains a vertex-indexed array of lists of edges. As with <code>Graph</code> (see page <a href="#ch04sb06">526</a>), every edge appears twice: if an edge connects <code>v</code> and <code>w</code>, it appears both in <code>v</code>’s list and in <code>w</code>’s list. The <code>edges()</code> method puts all the edges in a <code>Bag</code> (see page <a href="#page_609">609</a>). The <code>toString()</code> implementation is left as an exercise.</p>
<hr/>
</div>
<p><a id="ch04sec3lev33"/></p>
<h5><a id="page_612"/><em>Comparing edges by weight</em></h5>
<p>The API specifies that the <code>Edge</code> class must implement the <code>Comparable</code> interface and include a <code>compareTo()</code> implementation. The natural ordering for edges in an edge-weighted graph is by weight. Accordingly, the implementation of <code>compareTo()</code> is straightforward.</p>
<p><a id="ch04sec3lev34"/></p>
<h5><em>Parallel edges</em></h5>
<p>As with our undirected-graph implementations, we allow parallel edges. Alternatively, we could develop a more complicated implementation of <code>EdgeWeightedGraph</code> that disallows them, perhaps keeping the minimum-weight edge from a set of parallel edges.</p>
<p><a id="ch04sec3lev35"/></p>
<h5><em>Self-loops</em></h5>
<p>We allow self-loops. However, our <code>edges()</code> implementation in <code>EdgeWeightedGraph</code> does not include self-loops even though they might be present in the input or in the data structure. This omission has no effect on our MST algorithms because no MST contains a self-loop. When working with an application where self-loops are significant, you may need to modify our code as appropriate for the application.</p>
<p><small>OUR CHOICE</small> TO USE explicit <code>Edge</code> objects leads to clear and compact client code, as you will see. It carries a small price: each adjacency-list node has a <em>reference</em> to an <code>Edge</code> object, with redundant information (all the nodes on <code>v</code>’s adjacency list have a <code>v</code>). We also pay object overhead cost. Although we have only one copy of each <code>Edge</code>, we do have two references to each <code>Edge</code> object. An alternative and widely used approach is to keep two list nodes corresponding to each edge, just as in <code>Graph</code>, each with a vertex and the edge weight in each list node. This alternative also carries a price—two nodes, including two copies of the weight for each edge.</p>
<p><a id="ch04sec2lev27"/></p>
<h4><a id="page_613"/>MST API and test client</h4>
<p>As usual, for graph processing, we define an API where the constructor takes an edge-weighted graph as argument and supports client query methods that return the MST and its weight. How should we represent the MST itself? The MST of a graph <em>G</em> is a subgraph of <em>G</em> that is also a tree, so we have numerous options. Chief among them are</p>
<p class="indenthangingB">• A list of edges</p>
<p class="indenthangingB">• An edge-weighted graph</p>
<p class="indenthangingB">• A vertex-indexed array with parent links</p>
<p>To give clients and our implementations as much flexibility as possible in choosing among these alternatives for various applications, we adopt the following API:</p>
<p class="image"><img alt="image" src="graphics/t0613-01.jpg"/></p>
<p><a id="ch04sec3lev36"/></p>
<h5><em>Test client</em></h5>
<p>As usual, we create sample graphs and develop a test client for use in testing our implementations. A sample client is shown below. It reads edges from the input stream, builds an edge-weighted graph, computes the MST of that graph, prints the MST edges, and prints the total weight of the MST.</p>
<p class="image"><img alt="image" src="graphics/p0613-01.jpg"/></p>
<p><a id="ch04sec3lev37"/></p>
<h5><a id="page_614"/><em>Test data</em></h5>
<p>You can find the file <code>tinyEWG.txt</code> on the booksite, which defines the small sample graph on page <a href="#page_604">604</a> that we use for detailed traces of MST algorithms. You can also find on the booksite the file <code>mediumEWG.txt</code>, which defines the weighted graph with 250 vertices that is drawn on bottom of the the facing page. It is an example of a <em>Euclidean graph,</em> whose vertices are points in the plane and whose edges are lines connecting them with weights equal to their Euclidean distances. Such graphs are useful for gaining insight into the behavior of MST algorithms, and they also model many of the typical practical problems we have mentioned, such as road maps or electric circuits. You can also find on the booksite is a larger example <code>largeEWG.txt</code> that defines a Euclidean graph with 1 million vertices. Our goal is to be able to find the MST of such a graph in a reasonable amount of time.</p>
<p class="image"><img alt="image" src="graphics/p0614-01.jpg"/></p>
<p class="image"><a id="page_615"/><img alt="image" src="graphics/p0615-01.jpg"/></p>
<p class="image"><img alt="image" src="graphics/04_58-medium.jpg"/></p>
<p><a id="ch04sec2lev28"/></p>
<h4><a id="page_616"/>Prim’s algorithm</h4>
<p>Our first MST method, known as <em>Prim’s algorithm</em>, is to attach a new edge to a single growing tree at each step. Start with any vertex as a single-vertex tree; then add <em>V</em>−1 edges to it, always taking next (coloring black) the minimum-weight edge that connects a vertex on the tree to a vertex not yet on the tree (a crossing edge for the cut defined by tree vertices).</p>
<p class="image"><img alt="image" src="graphics/04_59-primproof.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb40"/></p>
<p><strong>Proposition L.</strong> Prim’s algorithm computes the MST of any connected edge-weighted graph.</p>
<p><strong>Proof:</strong> Immediate from <a href="#ch04sb37"><small>PROPOSITION K</small></a>. The growing tree defines a cut with no black edges; the algorithm takes the crossing edge of minimal weight, so it is successively coloring edges black in accordance with the greedy algorithm.</p>
<hr/>
</div>
<p>The one-sentence description of Prim’s algorithm just given leaves unanswered a key question: How do we (efficiently) find the crossing edge of minimal weight? Several methods have been proposed—we will discuss some of them after we have developed a full solution based on a particularly simple approach.</p>
<p><a id="ch04sec3lev38"/></p>
<h5><em>Data structures</em></h5>
<p>We implement Prim’s algorithm with the aid of a few simple and familiar data structures. In particular, we represent the vertices on the tree, the edges on the tree, and the crossing edges, as follows:</p>
<p class="indenthangingB">• <em>Vertices on the tree</em>: We use a vertex-indexed boolean array <code>marked[]</code>, where <code>marked[v]</code> is <code>true</code> if <code>v</code> is on the tree.</p>
<p class="indenthangingB">• <em>Edges on the tree</em>: We use one of two data structures: a queue <code>mst</code> to collect MST edges or a vertex-indexed array <code>edgeTo[]</code> of <code>Edge</code> objects, where <code>edgeTo[v]</code> is the <code>Edge</code> that connects <code>v</code> to the tree.</p>
<p class="indenthangingB">• <em>Crossing edges</em>: We use a <code>MinPQ&lt;Edge&gt;</code> priority queue that compares edges by weight (see page <a href="#ch04sb38">610</a>).</p>
<p>These data structures allow us to directly answer the basic question “Which is the minimal-weight crossing edge?”</p>
<p><a id="ch04sec3lev39"/></p>
<h5><em>Maintaining the set of crossing edges</em></h5>
<p>Each time that we add an edge to the tree, we also add a vertex to the tree. To maintain the set of crossing edges, we need to add to the priority queue all edges from that vertex to any non-tree vertex (using <code>marked[]</code> to identify such edges). But we must do more: any edge connecting the vertex just added to a tree vertex that is already on the priority queue now becomes <em>ineligible</em> (it is no longer a crossing edge because it connects two tree vertices). An <em>eager</em> implementation <a id="page_617"/>of Prim’s algorithm would remove such edges from the priority queue; we first consider a simpler <em>lazy</em> implementation of the algorithm where we leave such edges on the priority queue, deferring the eligibility test to when we remove them.</p>
<p class="image"><img alt="image" src="graphics/04_60-primtrace8x.jpg"/></p>
<p>The figure at right is a trace for our small sample graph <code>tinyEWG.txt</code>. Each drawing depicts the graph and the priority queue just after a vertex is visited (added to the tree and the edges in its adjacency list processed). The contents of the priority queue are shown in order on the side, with new edges marked with asterisks. The algorithm builds the MST as follows:</p>
<p class="indenthangingB">• Adds <code>0</code> to the MST and all edges in its adjacency list to the priority queue.</p>
<p class="indenthangingB">• Adds <code>7</code> and <code>0-7</code> to the MST and all edges in its adjacency list to the priority queue.</p>
<p class="indenthangingB">• Adds <code>1</code> and <code>1-7</code> to the MST and all edges in its adjacency list to the priority queue.</p>
<p class="indenthangingB">• Adds <code>2</code> and <code>0-2</code> to the MST and edges <code>2-3</code> and <code>6-2</code> to the priority queue. Edges <code>2-7</code> and <code>1-2</code> become ineligible.</p>
<p class="indenthangingB">• Adds <code>3</code> and <code>2-3</code> to the MST and edge <code>3-6</code> to the priority queue. Edge <code>1-3</code> becomes ineligible.</p>
<p class="indenthangingB">• Adds <code>5</code> and <code>5-7</code> to the MST and edge <code>4-5</code> to the priority queue. Edge <code>1-5</code> becomes ineligible.</p>
<p class="indenthangingB">• Removes ineligible edges <code>1-3</code>, <code>1-5</code>, and <code>2-7</code> from the priority queue.</p>
<p class="indenthangingB">• Adds <code>4</code> and <code>4-5</code> to the MST and edge <code>6-4</code> to the priority queue. Edges <code>4-7</code> and <code>0-4</code> become ineligible.</p>
<p class="indenthangingB">• Removes ineligible edges <code>1-2</code>, <code>4-7</code>, and <code>0-4</code> from the priority queue.</p>
<p class="indenthangingB">• Adds <code>6</code> and <code>6-2</code> to the MST. The other edges incident to <code>6</code> become ineligible.</p>
<p><a id="page_618"/>After having added <em>V</em> vertices (and <em>V</em>−1 edges), the MST is complete. The remaining edges on the priority queue are ineligible, so we need not examine them again.</p>
<p><a id="ch04sec3lev40"/></p>
<h5><em>Implementation</em></h5>
<p>With these preparations, implementing Prim’s algorithm is straightforward, as shown in the implementation <code>LazyPrimMST</code> on the facing page. As with our depth-first search and breadth-first search implementations in the previous two sections, it computes the MST in the constructor so that client methods can learn properties of the MST with query methods. We use a private method <code>visit()</code> that puts a vertex on the tree, by marking it as visited and then putting all of its incident edges that are not ineligible onto the priority queue, thus ensuring that the priority queue contains the crossing edges from tree vertices to non-tree vertices (perhaps also some ineligible edges). The inner loop is a rendition in code of the one-sentence description of the algorithm: we take an edge from the priority queue and (if it is not ineligible) add it to the tree, and also add to the tree the new vertex that it leads to, updating the set of crossing edges by calling <code>visit()</code> with that vertex as argument. The <code>weight()</code> method requires iterating through the tree edges to add up the edge weights (lazy approach) or keeping a running total in an instance variable (eager approach) and is left as <a href="#ch04qa3q31"><small>EXERCISE 4.3.31</small></a>.</p>
<p><a id="ch04sec3lev41"/></p>
<h5><em>Running time</em></h5>
<p>How fast is Prim’s algorithm? This question is not difficult to answer, given our knowledge of the behavior characteristics of priority queues:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb41"/></p>
<p><strong>Proposition M.</strong> The lazy version of Prim’s algorithm uses space proportional to <em>E</em> and time proportional to <em>E</em> log <em>E</em> (in the worst case) to compute the MST of a connected edge-weighted graph with <em>E</em> edges and <em>V</em> vertices.</p>
<p><strong>Proof:</strong> The bottleneck in the algorithm is the number of edge-weight comparisons in the priority-queue methods <code>insert()</code> and <code>delMin()</code>. The number of edges on the priority queue is at most <em>E</em>, which gives the space bound. In the worst case, the cost of an insertion is ~lg <em>E</em> and the cost to delete the minimum is ~2 lg <em>E</em> (see <a href="ch02.html#ch02sb30"><small>PROPOSITION O</small></a> in <a href="ch02.html#ch02"><small>CHAPTER 2</small></a>). Since at most <em>E</em> edges are inserted and at most <em>E</em> are deleted, the time bound follows.</p>
<hr/>
</div>
<p>In practice, the upper bound on the running time is a bit conservative because the number of edges on the priority queue is typically much less than <em>E</em>. The existence of such a simple, efficient, and useful algorithm for such a challenging task is quite remarkable. Next, we briefly discuss some improvements. As usual, detailed evaluation of such improvements in performance-critical applications is a job for experts.</p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb42"/></p>
<h3><a id="page_619"/>Lazy version of Prim’s MST algorithm</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0619-01.jpg"/></p>
<p>This implementation of Prim’s algorithm uses a priority queue to hold crossing edges, a vertex-indexed arrays to mark tree vertices, and a queue to hold MST edges. This implementation is a lazy approach where we leave ineligible edges in the priority queue.</p>
<hr/>
</div>
<p><a id="ch04sec2lev29"/></p>
<h4><a id="page_620"/>Eager version of Prim’s algorithm</h4>
<p>To improve the <code>LazyPrimMST</code>, we might try to delete ineligible edges from the priority queue, so that the priority queue contains <em>only</em> the crossing edges between tree vertices and non-tree vertices. But we can eliminate even more edges. The key is to note that our only interest is in the <em>minimal</em> edge from each non-tree vertex to a tree vertex. When we add a vertex <code>v</code> to the tree, the only possible change with respect to each non-tree vertex <code>w</code> is that adding <code>v</code> brings <code>w</code> closer than before to the tree. In short, we do not need to keep on the priority queue <em>all</em> of the edges from <code>w</code> to tree vertices—we just need to keep track of the minimum-weight edge and check whether the addition of <code>v</code> to the tree necessitates that we update that minimum (because of an edge <code>v-w</code> that has lower weight), which we can do as we process each edge in <code>v</code>’s adjacency list. In other words, we maintain on the priority queue just <em>one</em> edge for each non-tree vertex <code>w</code>: the shortest edge that connects it to the tree. Any longer edge connecting <code>w</code> to the tree will become ineligible at some point, so there is no need to keep it on the priority queue.</p>
<p class="image"><img alt="image" src="graphics/04_61-primeager.jpg"/></p>
<p><code>PrimMST</code> (<a href="#ch04sb43"><small>ALGORITHM 4.7</small></a> on page <a href="#ch04sb43">622</a>) implements Prim’s algorithm using our index priority queue data type from <a href="ch02.html#ch02sec1lev4"><small>SECTION 2.4</small></a> (see page <a href="ch02.html#page_320">320</a>). It replaces the data structures <code>marked[]</code> and <code>mst[]</code> in <code>LazyPrimMST</code> by two vertex-indexed arrays <code>edgeTo[]</code> and <code>distTo[]</code>, which have the following properties:</p>
<p class="indenthangingB">• If <code>v</code> is not on the tree but has at least one edge connecting it to the tree, then <code>edgeTo[v]</code> is the shortest edge connecting <code>v</code> to the tree, and <code>distTo[v]</code> is the weight of that edge.</p>
<p class="indenthangingB">• All such vertices <code>v</code> are maintained on the index priority queue, as an index <code>v</code> associated with the weight of <code>edgeTo[v]</code>.</p>
<p>The key implications of these properties is that <em>the minimum key on the priority queue is the weight of the minimal-weight crossing edge, and its associated vertex</em> <code>v</code> is <em>the next to add to the tree</em>. The <code>marked[]</code> array is not needed, since the condition <code>!marked[w]</code> is equivalent to the condition that <code>distTo[w]</code> is infinite (and that <code>edgeTo[w]</code> is <code>null</code>). To maintain the data structures, <code>PrimMST</code> takes an edge <code>v</code> from the priority queue, then checks each edge <code>v-w</code> on its adjacency list. If <code>w</code> is marked, the edge is ineligible; if it is not on the priority queue or its weight is lower than the current best-known <code>edgeTo[w]</code>, the code updates the data structures to establish <code>v-w</code> as the best-known way to connect <code>v</code> to the tree.</p>
<p>The figure on the facing page is a trace of <code>PrimMST</code> for our small sample graph <code>tinyEWG.txt</code>. The contents of the <code>edgeTo[]</code> and <code>distTo[]</code> arrays are depicted after each vertex is added to the MST, color-coded to depict the MST vertices (index in black), the non-MST vertices (index in gray), the MST edges (in black), and the priority-queue <a id="page_621"/>index/value pairs (in red). In the drawings, the shortest edge connecting each non-MST vertex to an MST vertex is drawn in red. The algorithm adds edges to the MST in the same order as the lazy version; the difference is in the priority-queue operations. It builds the MST as follows:</p>
<p class="indenthangingB">• Adds <code>0</code> to the MST and all edges in its adjacency list to the priority queue, since each such edge is the best (only) known connection between a tree vertex and a non-tree vertex.</p>
<p class="indenthangingB">• Adds <code>7</code> and <code>0-7</code> to the MST and <code>1-7</code> and <code>5-7</code> to the priority queue. Edges <code>4-7</code> and <code>2-7</code> do not affect the priority queue because their weights are not less than the weights of the known connections from the MST to <code>4</code> and <code>2</code>, respectively.</p>
<p class="indenthangingB">• Adds <code>1</code> and <code>1-7</code> to the MST and <code>1-3</code> to the priority queue.</p>
<p class="indenthangingB">• Adds <code>2</code> and <code>0-2</code> to the MST, replaces <code>0-6</code> with <code>2-6</code> as the shortest edge from a tree vertex to <code>6</code>, and replaces <code>1-3</code> with <code>2-3</code> as the shortest edge from a tree vertex to <code>3</code>.</p>
<p class="indenthangingB">• Adds <code>3</code> and <code>2-3</code> to the MST.</p>
<p class="indenthangingB">• Adds <code>5</code> and <code>5-7</code> to the MST and replaces <code>0-4</code> with <code>4-5</code> as the shortest edge from a tree vertex to <code>4</code>.</p>
<p class="indenthangingB">• Adds <code>4</code> and <code>4-5</code> to the MST.</p>
<p class="indenthangingB">• Adds <code>6</code> and <code>6-2</code> to the MST.</p>
<p class="image"><img alt="image" src="graphics/04_62-primtrace8xeager.jpg"/></p>
<p>After having added <em>V</em>−1 edges, the MST is complete and the priority queue is empty.</p>
<p><small>AN ESSENTIALLY IDENTICAL ARGUMENT</small> as in the proof of <a href="#ch04sb41"><small>PROPOSITION M</small></a> proves that the eager version of Prim’s algorithm finds the <a id="page_623"/>MST of a connected edge-weighted graph in time proportional to <em>E</em> log <em>V</em> and extra space proportional to <em>V</em> (see page <a href="#page_623">623</a>). For the huge sparse graphs that are typical in practice, there is no asymptotic difference in the time bound (because lg <em>E</em> ~ lg <em>V</em> for sparse graphs); the space bound is a constant-factor (but significant) improvement. Further analysis and experimentation are best left for experts facing performance-critical applications, where many factors come into play, including the implementations of <code>MinPQ</code> and <code>IndexMinPQ</code>, the graph representation, properties of the application’s graph model, and so forth. As usual, such improvements need to be carefully considered, as the increased code complexity is only justified for applications where constant-factor performance gains are important, and might even be counterproductive on complex modern systems.</p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb43"/></p>
<h3><a id="page_622"/>Algorithm 4.7 Prim’s MST algorithm (eager version)</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0622-01.jpg"/></p>
<p>This implementation of Prim’s algorithm keeps eligible crossing edges on an index priority queue.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_63-primtrace250.jpg"/></p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb44"/></p>
<p><strong>Proposition N.</strong> The eager version of Prim’s algorithm uses extra space proportional to <em>V</em> and time proportional to <em>E</em> log <em>V</em> (in the worst case) to compute the MST of a connected edge-weighted graph with <em>E</em> edges and <em>V</em> vertices.</p>
<p><strong>Proof:</strong> The number of edges on the priority queue is at most <em>V</em>, and there are three vertex-indexed arrays, which implies the space bound. The algorithm uses <em>V insert</em> operations, <em>V delete the minimum</em> operations, and (in the worst case) <em>E change priority</em> operations. These counts, coupled with the fact that our heap-based implementation of the index priority queue implements all these operations in time proportional to log <em>V</em> (see page <a href="ch02.html#page_321">321</a>), imply the time bound.</p>
<hr/>
</div>
<p>The diagram at right shows Prim’s algorithm in operation on our 250-vertex Euclidean graph <code>mediumEWG.txt</code>. It is a fascinating dynamic process (see also <a href="#ch04qa3q27"><small>EXERCISE 4.3.27</small></a>). Most often the tree grows by connecting a new vertex to the vertex just added. When reaching an area with no nearby non-tree vertices, the growth starts from another part of the tree.</p>
<p><a id="ch04sec2lev30"/></p>
<h4><a id="page_624"/>Kruskal’s algorithm</h4>
<p>The second MST algorithm that we consider in detail is to process the edges in order of their weight values (smallest to largest), taking for the MST (coloring black) each edge that does not form a cycle with edges previously added, stopping after adding <em>V</em>−1 edges. The black edges form a forest of trees that evolves gradually into a single tree, the MST. This method is known as <em>Kruskal’s algorithm</em>:</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb45"/></p>
<p><strong>Proposition O.</strong> Kruskal’s algorithm computes the MST of any connected edge-weighted graph.</p>
<p><strong>Proof:</strong> Immediate from <a href="#ch04sb37"><small>PROPOSITION K</small></a>. If the next edge to be considered does not form a cycle with black edges, it crosses a cut defined by the set of vertices connected to one of the edge’s vertices by tree edges (and its complement). Since the edge does not create a cycle, it is the only crossing edge seen so far, and since we consider the edges in sorted order, it is a crossing edge of minimum weight. Thus, the algorithm is successively taking a minimal-weight crossing edge, in accordance with the greedy algorithm.</p>
<hr/>
</div>
<p class="image"><img alt="image" src="graphics/04_64-kruskaltrace8.jpg"/></p>
<p>Prim’s algorithm builds the MST one edge at a time, finding a new edge to attach to a single growing tree at each step. Kruskal’s algorithm also builds the MST one edge at a time; but, by contrast, it finds an edge that connects two trees in a forest of growing trees. We start with a degenerate forest of <em>V</em> single-vertex trees and perform the operation of combining two trees (using the shortest edge possible) until there is just one tree left: the MST.</p>
<p>The figure at left shows a step-by-step example of the operation of Kruskal’s algorithm on <code>tinyEWG.txt</code>. The five lowest-weight edges in the graph are taken for the MST, then <code>1-3</code>, <code>1-5</code>, and <code>2-7</code> are determined to be ineligible before <code>4-5</code> is taken for the MST, and finally <code>1-2</code>, <code>4-7</code>, and <code>0-4</code> are determined to be ineligible and <code>6-2</code> is taken for the MST.</p>
<p><a id="page_625"/>Kruskal’s algorithm is also not difficult to implement, given the basic algorithmic tools that we have considered in this book: we use a priority queue (<a href="ch02.html#ch02sec1lev4"><small>SECTION 2.4</small></a>) to consider the edges in order by weight, a union-find data structure (<a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a>) to identify those that cause cycles, and a queue (<a href="ch01a.html#ch01sec1lev5"><small>SECTION 1.3</small></a>) to collect the MST edges. <a href="#ch04sb47"><small>ALGORITHM 4.8</small></a> is an implementation along these lines. Note that collecting the MST edges in a <code>Queue</code> means that when a client iterates through the edges it gets them in increasing order of their weight. The <code>weight()</code> method requires iterating through the queue to add the edge weights (or keeping a running total in an instance variable) and is left as an exercise (see <a href="#ch04qa3q31"><small>EXERCISE 4.3.31</small></a>).</p>
<p>Analyzing the running time of Kruskal’s algorithm is a simple matter because we know the running times of its basic operations.</p>
<div class="sidebar1">
<hr/>
<p><a id="ch04sb46"/></p>
<p><strong>Proposition N (continued).</strong> Kruskal’s algorithm uses space proportional to <em>E</em> and time proportional to <em>E</em> log <em>E</em> (in the worst case) to compute the MST of an edge-weighted connected graph with <em>E</em> edges and <em>V</em> vertices.</p>
<p><strong>Proof:</strong> The implementation uses the priority-queue constructor that initializes the priority queue with all the edges, at a cost of at most <em>E</em> compares (see <a href="ch02.html#ch02sec1lev4"><small>SECTION 2.4</small></a>). After the priority queue is built, the argument is the same as for Prim’s algorithm. The number of edges on the priority queue is at most <em>E</em>, which gives the space bound, and the cost per operation is at most 2 lg <em>E</em> compares, which gives the time bound. Kruskal’s algorithm also performs up to <em>E</em> <code>find()</code> and <em>V</em> <code>union()</code> operations, but that cost does not contribute to the <em>E</em> log <em>E</em> order of growth of the total running time (see <a href="ch01a.html#ch01sec1lev7"><small>SECTION 1.5</small></a>).</p>
<hr/>
</div>
<p>As with Prim’s algorithm the cost bound is conservative, since the algorithm terminates after finding the <em>V</em>−1 MST edges. The order of growth of the actual cost is <em>E</em> + <em>E</em><sub>0</sub> log <em>E</em>, where <em>E</em><sub>0</sub> is the number of edges whose weight is less than the weight of the MST edge with the highest weight. Despite this advantage, Kruskal’s algorithm is generally slower than Prim’s algorithm because it has to do a <code>connected()</code> operation for each edge, in addition to the priority-queue operations that both algorithms do for each edge processed (see <a href="#ch04qa3q39"><small>EXERCISE 4.3.39</small></a>).</p>
<p><a id="page_626"/>The figure at left illustrates the algorithm’s dynamic characteristics on the larger example <code>mediumEWG.txt</code>. The fact that the edges are added to the forest in order of their length is quite apparent.</p>
<p class="image"><img alt="image" src="graphics/04_65-kruskaltrace250.jpg"/></p>
<div class="sidebar">
<hr/>
<p><a id="ch04sb47"/></p>
<h3><a id="page_627"/>Algorithm 4.8 Kruskal’s MST algorithm</h3>
<p class="programlisting2"><img alt="image" src="graphics/p0627-01.jpg"/></p>
<p>This implementation of Kruskal’s algorithm uses a queue to hold MST edges, a priority queue to hold edges not yet examined, and a union-find data structure for identifying ineligible edges. The MST edges are returned to the client in increasing order of their weights. The <code>weight()</code> method is left as an exercise.</p>
<p class="image"><img alt="image" src="graphics/p0627-02.jpg"/></p>
<hr/>
</div>
<p><a id="ch04sec2lev31"/></p>
<h4><a id="page_628"/>Perspective</h4>
<p>The MST problem is one of the most heavily studied problems that we encounter in this book. Basic approaches to solving it were invented long before the development of modern data structures and modern techniques for analyzing the performance of algorithms, at a time when finding the MST of a graph that contained, say, thousands of edges was a daunting task. The MST algorithms that we have considered differ from these old ones essentially in their use and implementation of modern algorithms and data structures for basic tasks, which (coupled with modern computing power) makes it possible for us to compute MSTs with millions or even billions of edges.</p>
<p><a id="ch04sec3lev42"/></p>
<h5><em>Historical notes</em></h5>
<p>An MST implementation for dense graphs (see <a href="#ch04qa3q29"><small>EXERCISE 4.3.29</small></a>) was first presented by R. Prim in 1961 and, independently, by E. W. Dijkstra soon thereafter. It is usually referred to as <em>Prim’s algorithm</em>, although Dijkstra’s presentation was more general. But the basic idea was also presented by V. Jarnik in 1939, so some authors refer to the method as <em>Jarnik’s algorithm</em>, thus characterizing Prim’s (or Dijkstra’s) role as finding an efficient implementation of the algorithm for dense graphs. As the priority-queue ADT came into use in the early 1970s, its application to finding MSTs of sparse graphs was straightforward; the fact that MSTs of sparse graphs could be computed in time proportional to <em>E</em> log <em>E</em> became widely known without attribution to any particular researcher. In 1984, M. L. Fredman and R. E. Tarjan developed the <em>Fibonacci heap</em> data structure, which improves the theoretical bound on the order of growth of the running time of Prim’s algorithm to <em>E</em> + <em>V</em> log <em>V</em>. J. Kruskal presented his algorithm in 1956, but, again, the relevant ADT implementations were not carefully studied for many years. Other interesting historical notes are that Kruskal’s paper mentioned a version of Prim’s algorithm and that a 1926 (!) paper by O. Boruvka mentioned both approaches. Boruvka’s paper addressed a power-distribution application and introduced yet another method that is easily implemented with modern data structures (see <a href="#ch04qa3q43"><small>EXERCISE 4.3.43</small></a> and <a href="#ch04qa3q44"><small>EXERCISE 4.3.44</small></a>). The method was rediscovered by M. Sollin in 1961; <a id="page_629"/>it later attracted attention as the basis for MST algorithms with efficient asymptotic performance and as the basis for parallel MST algorithms.</p>
<p class="image"><img alt="image" src="graphics/t0628-01.jpg"/></p>
<p><a id="ch04sec3lev43"/></p>
<h5><em>A linear-time algorithm?</em></h5>
<p>On the one hand, no theoretical results have been developed that deny the existence of an MST algorithm that is guaranteed to run in linear time for all graphs. On the other hand, the goal of developing algorithms for computing the MST of sparse graphs in linear time remains elusive. Since the 1970s the applicability of the union-find abstraction to Kruskal’s algorithm and the applicability of the priority-queue abstraction to Prim’s algorithm have been prime motivations for many researchers to seek better implementations of those ADTs. Many researchers have concentrated on finding efficient priority-queue implementations as the key to finding efficient MST algorithms for sparse graphs; many other researchers have studied variations of Boruvka’s algorithm as the basis for nearly linear-time MST algorithms for sparse graphs. Such research still holds the potential to lead us eventually to a practical linear-time MST algorithm and has even shown the existence of a randomized linear-time algorithm. Also, researchers are getting quite close to the linear-time goal: B. Chazelle exhibited an algorithm in 1997 that certainly could never be distinguished from a linear-time algorithm in any conceivable practical situation (even though it is provably nonlinear), but is so complicated that no one would use it in practice. While the algorithms that have emerged from such research are generally quite complicated, simplified versions of some of them may yet be shown to be useful in practice. In the meantime, we can use the basic algorithms that we have considered here to compute the MST in linear time in most practical situations, perhaps paying an extra factor of log <em>V</em> for some sparse graphs.</p>
<p><small>IN SUMMARY</small>, we can consider the MST problem to be “solved” for practical purposes. For most graphs, the cost of finding the MST is only slightly higher than the cost of extracting the graph’s edges. This rule holds except for huge graphs that are extremely sparse, but the available performance improvement over the best-known algorithms even in this case is a small constant factor, perhaps a factor of 10 at best. These conclusions are borne out for many graph models, and practitioners have been using Prim’s and Kruskal’s algorithms to find MSTs in huge graphs for decades.</p>
<p><a id="ch04sec2lev32"/></p>
<h4><a id="page_630"/>Q&amp;A</h4>
<p><strong>Q.</strong> Do Prim’s and Kruskal’s algorithms work for <em>directed</em> graphs?</p>
<p><strong>A.</strong> No, not at all. That is a more difficult graph-processing problem known as the <em>minimum cost arborescence</em> problem.</p>
<p><a id="ch04sec2lev33"/></p>
<h4><a id="page_631"/>Exercises</h4>
<p><a id="ch04qa3q1"/><strong>4.3.1</strong> Prove that you can rescale the weights by adding a positive constant to all of them or by multiplying them all by a positive constant without affecting the MST.</p>
<p class="image"><img alt="image" src="graphics/04_66-ex432.jpg"/></p>
<p><a id="ch04qa3q2"/><strong>4.3.2</strong> Draw all of the MSTs of the graph depicted at right (all edge weights are equal).</p>
<p><a id="ch04qa3q3"/><strong>4.3.3</strong> Show that if a graph’s edges all have distinct weights, the MST is unique.</p>
<p><a id="ch04qa3q4"/><strong>4.3.4</strong> Consider the assertion that an edge-weighted graph has a unique MST <em>only</em> if its edge weights are distinct. Give a proof or a counterexample.</p>
<p><a id="ch04qa3q5"/><strong>4.3.5</strong> Show that the greedy algorithm is valid even when edge weights are not distinct.</p>
<p><a id="ch04qa3q6"/><strong>4.3.6</strong> Give the MST of the weighted graph obtained by deleting vertex <code>7</code> from <code>tinyEWG.txt</code> (see page <a href="#page_604">604</a>).</p>
<p><a id="ch04qa3q7"/><strong>4.3.7</strong> How would you find a <em>maximum</em> spanning tree of an edge-weighted graph?</p>
<p><a id="ch04qa3q8"/><strong>4.3.8</strong> Prove the following, known as the <em>cycle property</em>: Given any cycle in an edge-weighted graph (all edge weights distinct), the edge of maximum weight in the cycle does not belong to the MST of the graph.</p>
<p><a id="ch04qa3q9"/><strong>4.3.9</strong> Implement the constructor for <code>EdgeWeightedGraph</code> that reads an edge-weighted graph from the input stream, by suitably modifying the constructor from <code>Graph</code> (see page <a href="#ch04sb06">526</a>).</p>
<p><a id="ch04qa3q10"/><strong>4.3.10</strong> Develop an <code>EdgeWeightedGraph</code> implementation for dense graphs that uses an adjacency-matrix (two-dimensional array of weights) representation. Disallow parallel edges.</p>
<p><a id="ch04qa3q11"/><strong>4.3.11</strong> Determine the amount of memory used by <code>EdgeWeightedGraph</code> to represent a graph with <em>V</em> vertices and <em>E</em> edges, using the memory-cost model of <a href="ch01a.html#ch01sec1lev6"><small>SECTION 1.4</small></a>.</p>
<p><a id="ch04qa3q12"/><strong>4.3.12</strong> Suppose that a graph has distinct edge weights. Does its shortest edge have to belong to the MST? Can its longest edge belong to the MST? Does a min-weight edge on every cycle have to belong to the MST? Prove your answer to each question or give a counterexample.</p>
<p><a id="ch04qa3q13"/><strong>4.3.13</strong> Give a counterexample that shows why the following strategy does not necessarily find the MST: ‘Start with any vertex as a single-vertex MST, then add <code>V-1</code> edges to it, always taking next a min-weight edge incident to the vertex most recently added <a id="page_632"/>to the MST.’</p>
<p><a id="ch04qa3q14"/><strong>4.3.14</strong> Given an MST for an edge-weighted graph <em>G</em>, suppose that an edge in <em>G</em> that does not disconnect <em>G</em> is deleted. Describe how to find an MST of the new graph in time proportional to <em>E</em>.</p>
<p><a id="ch04qa3q15"/><strong>4.3.15</strong> Given an MST for an edge-weighted graph <em>G</em> and a new edge <em>e</em>, describe how to find an MST of the new graph in time proportional to <em>V</em>.</p>
<p><a id="ch04qa3q16"/><strong>4.3.16</strong> Given an MST for an edge-weighted graph <em>G</em> and a new edge <em>e</em>, write a program that determines the range of weights for which <em>e</em> is in an MST.</p>
<p><a id="ch04qa3q17"/><strong>4.3.17</strong> Implement <code>toString()</code> for <code>EdgeWeightedGraph</code>.</p>
<p><a id="ch04qa3q18"/><strong>4.3.18</strong> Give traces that show the process of computing the MST of the graph defined in <a href="#ch04qa3q6"><small>EXERCISE 4.3.6</small></a> with the lazy version of Prim’s algorithm, the eager version of Prim’s algorithm, and Kruskal’s algorithm.</p>
<p><a id="ch04qa3q19"/><strong>4.3.19</strong> Suppose that you use a priority-queue implementation that maintains a sorted list. What would be the order of growth of the worst-case running time for Prim’s algorithm and for Kruskal’s algorithm for graphs with <em>V</em> vertices and <em>E</em> edges? When would this method be appropriate, if ever? Defend your answer.</p>
<p><a id="ch04qa3q20"/><strong>4.3.20</strong> True or false: At any point during the execution of Kruskal’s algorithm, each vertex is closer to some vertex in its subtree than to any vertex not in its subtree. Prove your answer.</p>
<p><a id="ch04qa3q21"/><strong>4.3.21</strong> Provide an implementation of <code>edges()</code> for <code>PrimMST</code> (page <a href="#ch04sb43">622</a>).</p>
<p><em>Solution</em>:</p>
<p class="programlisting"><img alt="image" src="graphics/p0632-01.jpg"/></p>
<p><a id="ch04sec2lev34"/></p>
<h4><a id="page_633"/>Creative Problems</h4>
<p><a id="ch04qa3q22"/><strong>4.3.22</strong> <em>Minimum spanning forest</em>. Develop versions of Prim’s and Kruskal’s algorithms that compute the minimum spanning <em>forest</em> of an edge-weighted graph that is not necessarily connected. Use the connected-components API of <a href="#ch04sec1lev10"><small>SECTION 4.1</small></a> and find MSTs in each component.</p>
<p><a id="ch04qa3q23"/><strong>4.3.23</strong> <em>Vyssotsky’s algorithm</em>. Develop an implementation that computes the MST by applying the cycle property (see <a href="#ch04qa3q8"><small>EXERCISE 4.3.8</small></a>) repeatedly: Add edges one at a time to a putative tree, deleting a maximum-weight edge on the cycle if one is formed. <em>Note</em>: This method has received less attention than the others that we consider because of the comparative difficulty of maintaining a data structure that supports efficient implementation of the “delete the maximum-weight edge on the cycle” operation.</p>
<p><a id="ch04qa3q24"/><strong>4.3.24</strong> <em>Reverse-delete algorithm</em>. Develop an implementation that computes the MST as follows: Start with a graph containing all of the edges. Then repeatedly go through the edges in decreasing order of weight. For each edge, check if deleting that edge will disconnect the graph; if not, delete it. Prove that this algorithm computes the MST. What is the order of growth of the number of edge-weight compares performed by your implementation?</p>
<p><a id="ch04qa3q25"/><strong>4.3.25</strong> <em>Worst-case generator</em>. Develop a reasonable generator for edge-weighted graphs with <em>V</em> vertices and <em>E</em> edges such that the running time of the lazy version of Prim’s algorithm is nonlinear. Answer the same question for the eager version.</p>
<p><a id="ch04qa3q26"/><strong>4.3.26</strong> <em>Critical edges.</em> An MST edge whose deletion from the graph would cause the MST weight to increase is called a <em>critical edge</em>. Show how to find all critical edges in a graph in time proportional to <em>E</em> log <em>E</em>. <em>Note</em>: This question assumes that edge weights are not necessarily distinct (otherwise all edges in the MST are critical).</p>
<p><a id="ch04qa3q27"/><strong>4.3.27</strong> <em>Animations.</em> Write a client program that does dynamic graphical animations of MST algorithms. Run your program for <code>mediumEWG.txt</code> to produce images like the figures on page <a href="#page_621">621</a> and page <a href="#page_624">624</a>.</p>
<p><a id="ch04qa3q28"/><strong>4.3.28</strong> <em>Space-efficient data structures.</em> Develop an implementation of the lazy version of Prim’s algorithm that saves space by using lower-level data structures for <code>EdgeWeightedGraph</code> and for <code>MinPQ</code> instead of <code>Bag</code> and <code>Edge</code>. Estimate the amount of memory saved as a function of <em>V</em> and <em>E,</em> using the memory-cost model of <a href="ch01a.html#ch01sec1lev6"><small>SECTION 1.4</small></a> (see <a href="#ch04qa3q11"><small>EXERCISE 4.3.11</small></a>).</p>
<p><a id="page_634"/><a id="ch04qa3q29"/><strong>4.3.29</strong> <em>Dense graphs.</em> Develop an implementation of Prim’s algorithm that uses an eager approach (but not a priority queue) and computes the MST using <em>V</em><sup>2</sup> edge-weight comparisons.</p>
<p><a id="ch04qa3q30"/><strong>4.3.30</strong> <em>Euclidean weighted graphs.</em> Modify your solution to <a href="#ch04qa1q37"><small>EXERCISE 4.1.37</small></a> to create an API <code>EuclideanEdgeWeightedGraph</code> for graphs whose vertices are points in the plane, so that you can work with graphical representations.</p>
<p><a id="ch04qa3q31"/><strong>4.3.31</strong> <em>MST weights.</em> Develop implementations of <code>weight()</code> for <code>LazyPrimMST</code>, <code>PrimMST</code>, and <code>KruskalMST</code>, using a <em>lazy</em> strategy that iterates through the MST edges when the client calls <code>weight()</code>. Then develop alternate implementations that use an <em>eager</em> strategy that maintains a running total as the MST is computed.</p>
<p><a id="ch04qa3q32"/><strong>4.3.32</strong> <em>Specified set.</em> Given a connected edge-weighted graph <em>G</em> and a specified set of edges <em>S</em> (having no cycles), describe a way to find a minimum-weight spanning tree of <em>G</em> that contains all the edges in <em>S</em>.</p>
<p><a id="ch04qa3q33"/><strong>4.3.33</strong> <em>Certification.</em> Write an <code>MST</code> and <code>EdgeWeightedGraph</code> client <code>check()</code> that uses the following <em>cut optimality conditions</em> implied by <a href="#ch04sb36"><small>PROPOSITION J</small></a> to verify that a proposed set of edges is in fact an MST: A set of edges is an MST if it is a spanning tree and every edge is a minimum-weight edge in the cut defined by removing that edge from the tree. What is the order of growth of the running time of your method?</p>
<p><a id="ch04sec2lev35"/></p>
<h4><a id="page_635"/>Experiments</h4>
<p><a id="ch04qa3q34"/><strong>4.3.34</strong> <em>Random sparse edge-weighted graphs.</em> Write a random-sparse-edge-weighted-graph generator based on your solution to <a href="#ch04qa1q41"><small>EXERCISE 4.1.41</small></a>. To assign edge weights, define a random-edge-weighted digraph ADT and write two implementations: one that generates uniformly distributed weights, another that generates weights according to a Gaussian distribution. Write client programs to generate sparse random edge-weighted graphs for both weight distributions with a well-chosen set of values of <em>V</em> and <em>E</em> so that you can use them to run empirical tests on graphs drawn from various distributions of edge weights.</p>
<p><a id="ch04qa3q35"/><strong>4.3.35</strong> <em>Random Euclidean edge-weighted graphs.</em> Modify your solution to <a href="#ch04qa1q42"><small>EXERCISE 4.1.42</small></a> to assign the distance between vertices as each edge’s weight.</p>
<p><a id="ch04qa3q36"/><strong>4.3.36</strong> <em>Random grid edge-weighted graphs.</em> Modify your your solution to <a href="#ch04qa1q43"><small>EXERCISE 4.1.43</small></a> to assign a random weight (between 0 and 1) to each edge.</p>
<p><a id="ch04qa3q37"/><strong>4.3.37</strong> <em>Real edge-weighted graphs.</em> Find a large weighted graph somewhere online—perhaps a map with distances, telephone connections with costs, or an airline rate schedule. Write a program <code>RandomRealEdgeWeightedGraph</code> that builds a weighted graph by choosing <em>V</em> vertices at random and <em>E</em> weighted edges at random from the subgraph induced by those vertices.</p>
<p><em>Testing all algorithms and studying all parameters against all graph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input graph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</em></p>
<p><a id="ch04qa3q38"/><strong>4.3.38</strong> <em>Cost of laziness.</em> Run empirical studies to compare the performance of the lazy version of Prim’s algorithm with the eager version, for various types of graphs.</p>
<p><a id="ch04qa3q39"/><strong>4.3.39</strong> <em>Prim versus Kruskal.</em> Run empirical studies to compare the performance of the lazy and eager versions of Prim’s algorithm with Kruskal’s algorithm.</p>
<p><a id="ch04qa3q40"/><strong>4.3.40</strong> <em>Reduced overhead.</em> Run empirical studies to determine the effect of using primitive types instead of <code>Edge</code> values in <code>EdgeWeightedGraph</code>, as described in <a href="#ch04qa3q28"><small>EXERCISE 4.3.28</small></a>.</p>
<p><a id="page_636"/><a id="ch04qa3q41"/><strong>4.3.41</strong> <em>Longest MST edge.</em> Run empirical studies to analyze the length of the longest edge in the MST and the number of graph edges that are not longer than that one.</p>
<p><a id="ch04qa3q42"/><strong>4.3.42</strong> <em>Partitioning.</em> Develop an implementation based on integrating Kruskal’s algorithm with quicksort partitioning (instead of using a priority queue) so as to check MST membership of each edge as soon as all smaller edges have been checked.</p>
<p><a id="ch04qa3q43"/><strong>4.3.43</strong> <em>Boruvka’s algorithm.</em> Develop an implementation of Boruvka’s algorithm: Build an MST by adding edges to a growing forest of trees, as in Kruskal’s algorithm, but in stages. At each stage, find the minimum-weight edge that connects each tree to a different one, then add all such edges to the MST. Assume that the edge weights are all different, to avoid cycles. <em>Hint</em>: Maintain in a vertex-indexed array to identify the edge that connects each component to its nearest neighbor, and use the union-find data structure.</p>
<p><a id="ch04qa3q44"/><strong>4.3.44</strong> <em>Improved Boruvka.</em> Develop an implementation of Boruvka’s algorithm that uses doubly-linked circular lists to represent MST subtrees so that subtrees can be merged and renamed in time proportional to <em>E</em> during each stage (and the union-find ADT is therefore not needed).</p>
<p><a id="ch04qa3q45"/><strong>4.3.45</strong> <em>External MST.</em> Describe how you would find the MST of a graph so large that only <em>V</em> edges can fit into main memory at once.</p>
<p><a id="ch04qa3q46"/><strong>4.3.46</strong> <em>Johnson’s algorithm.</em> Develop a priority-queue implementation that uses a <em>d</em>-way heap (see <a href="ch02.html#ch02qa4q41"><small>EXERCISE 2.4.41</small></a>). Find the best value of <em>d</em> for various weighted graph models.</p>
</body>
</html>