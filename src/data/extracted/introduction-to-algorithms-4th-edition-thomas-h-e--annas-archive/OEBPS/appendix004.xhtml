<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"/>
<title>Introduction to Algorithms</title>
<link href="css/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4a9ccac5-f2db-4081-af1f-a5a376b433e1" name="Adept.expected.resource"/>
</head>
<body>
<div class="body"><a id="p1214"/>
<p class="line-c"/>
<section epub:type="backmatter" title="D Matrices">
<p class="chapter-title"><a href="toc.xhtml#app-4"><strong><span class="blue1">D Matrices</span></strong></a></p>
<p class="noindent">Matrices arise in numerous applications, including, but by no means limited to, scientific computing. If you have seen matrices before, much of the material in this appendix will be familiar to you, but some of it might be new. <a href="appendix004.xhtml#Sec_D.1">Section D.1</a> covers basic matrix definitions and operations, and <a href="appendix004.xhtml#Sec_D.2">Section D.2</a> presents some basic matrix properties.</p>
<p class="line1"/>
<section title="D.1 Matrices and matrix operations">
<a id="Sec_D.1"/>
<p class="level1" id="h1-232"><a href="toc.xhtml#Rh1-232"><strong>D.1 Matrices and matrix operations</strong></a></p>
<p class="noindent">This section reviews some basic concepts of matrix theory and some fundamental properties of matrices.</p>
<p class="level4"><strong>Matrices and vectors</strong></p>
<p class="noindent">A <strong><em>matrix</em></strong> is a rectangular array of numbers. For example,</p>
<p class="eqr"><img alt="art" src="images/Art_P1768.jpg"/></p>
<p class="noindent">is a 2 × 3 matrix <em>A</em> = (<em>a<sub>ij</sub></em>), where for <em>i</em> = 1, 2 and <em>j</em> = 1, 2, 3, the element of the matrix in row <em>i</em> and column <em>j</em> is denoted by <em>a<sub>ij</sub></em>. By convention, uppercase letters denote matrices and corresponding subscripted lowercase letters denote their elements. We denote the set of all <em>m</em> × <em>n</em> matrices with real-valued entries by <span class="double"><span class="font1">ℝ</span></span><sup><em>m</em>×<em>n</em></sup> and, in general, the set of <em>m</em> × <em>n</em> matrices with entries drawn from a set <em>S</em> by <em>S</em><sup><em>m</em>×<em>n</em></sup>.</p>
<p>The <strong><em><span class="blue1">transpose</span></em></strong> of a matrix <em>A</em> is the matrix <em>A</em><sup>T</sup> obtained by exchanging the rows and columns of <em>A</em>. For the matrix <em>A</em> of equation (D.1),</p>
<a id="p1215"/>
<p class="eql"><img alt="art" src="images/Art_P1769.jpg"/></p>
<p>A <strong><em><span class="blue1">vector</span></em></strong> is a one-dimensional array of numbers. For example,</p>
<p class="eql"><img alt="art" src="images/Art_P1770.jpg"/></p>
<p class="noindent">is a vector of size 3. We sometimes call a vector of length <em>n</em> an <strong><em><span class="blue1">n-vector</span></em></strong>. By convention, lowercase letters denote vectors, and the <em>i</em>th element of a size-<em>n</em> vector <em>x</em> is denoted by <em>x<sub>i</sub></em>, for <em>i</em> = 1, 2, … , <em>n</em>. We take the standard form of a vector to be as a <strong><em><span class="blue1">column vector</span></em></strong> equivalent to an <em>n</em> × 1 matrix, whereas the corresponding <strong><em><span class="blue1">row vector</span></em></strong> is obtained by taking the transpose:</p>
<p class="eql"><em>x</em><sup>T</sup> = ( 2 3 5 ).</p>
<p class="noindent">The <strong><em><span class="blue1">unit vector</span></em></strong> <em>e<sub>i</sub></em> is the vector whose <em>i</em>th element is 1 and all of whose other elements are 0. Usually, the context makes the size of a unit vector clear.</p>
<p>A <strong><em><span class="blue1">zero matrix</span></em></strong> is a matrix all of whose entries are 0. Such a matrix is often denoted 0, since the ambiguity between the number 0 and a matrix of 0s can usually be resolved from context. If a matrix of 0s is intended, then the size of the matrix also needs to be derived from the context.</p>
<p class="level4"><strong>Square matrices</strong></p>
<p class="noindent"><strong><em><span class="blue1">Square</span></em></strong> <em>n</em> × <em>n</em> matrices arise frequently. Several special cases of square matrices are of particular interest:</p>
<p class="nl-1list-d">1. A <strong><em><span class="blue1">diagonal matrix</span></em></strong> has <em>a<sub>ij</sub></em> = 0 whenever <em>i</em> ≠ <em>j</em>. Because all of the off-diagonal elements are 0, a succinct way to specify the matrix lists only the elements along the diagonal:</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1771.jpg"/></p>
<p class="nl-1list-d">2. The <em>n</em> × <em>n</em> <strong><em><span class="blue1">identity matrix</span></em></strong> <em>I<sub>n</sub></em> is a diagonal matrix with 1s along the diagonal:</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1772.jpg"/></p>
<a id="p1216"/>
<p class="nl-1list-dp1">When <em>I</em> appears without a subscript, its size derives from the context. The <em>i</em>th column of an identity matrix is the unit vector <em>e<sub>i</sub></em>.</p>
<p class="nl-1list-d">3. A <strong><em><span class="blue1">tridiagonal matrix</span></em></strong> <em>T</em> is one for which <em>t<sub>ij</sub></em> = 0 if |<em>i</em> − <em>j</em> | &gt; 1. Nonzero entries appear only on the main diagonal, immediately above the main diagonal (<em>t</em><sub><em>i,i</em>+1</sub> for <em>i</em> = 1, 2, … , <em>n</em> − 1), or immediately below the main diagonal (<em>t</em><sub><em>i</em>+1,<em>i</em></sub> for <em>i</em> = 1, 2, … , <em>n</em> − 1):</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1773.jpg"/></p>
<p class="nl-1list-d">4. An <strong><em><span class="blue1">upper-triangular matrix</span></em></strong> <em>U</em> is one for which <em>u<sub>ij</sub></em> = 0 if <em>i</em> &gt; <em>j</em>. All entries below the diagonal are 0:</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1774.jpg"/></p>
<p class="nl-1list-dp1">An upper-triangular matrix is <strong><em><span class="blue1">unit upper-triangular</span></em></strong> if it has all 1s along the diagonal.</p>
<p class="nl-1list-d">5. A <strong><em><span class="blue1">lower-triangular matrix</span></em></strong> <em>L</em> is one for which <em>l<sub>ij</sub></em> = 0 if <em>i</em> &lt; <em>j</em>. All entries above the diagonal are 0:</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1775.jpg"/></p>
<p class="nl-1list-dp1">A lower-triangular matrix is <strong><em><span class="blue1">unit lower-triangular</span></em></strong> if it has all 1s along the diagonal.</p>
<a id="p1217"/>
<p class="nl-1list-d">6. A <strong><em><span class="blue1">permutation matrix</span></em></strong> <em>P</em> has exactly one 1 in each row or column, and 0s elsewhere. An example of a permutation matrix is</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1776.jpg"/></p>
<p class="nl-1list-dp1">Such a matrix is called a permutation matrix because multiplying a vector <em>x</em> by a permutation matrix has the effect of permuting (rearranging) the elements of <em>x</em>. Exercise D.1-4 explores additional properties of permutation matrices.</p>
<p class="nl-1list-d">7. A <strong><em><span class="blue1">symmetric matrix</span></em></strong> <em>A</em> satisfies the condition <em>A</em> = <em>A</em><sup>T</sup>. For example,</p>
<p class="nl-1list-dp1"><img alt="art" src="images/Art_P1777.jpg"/></p>
<p class="nl-1list-dp1">is a symmetric matrix.</p>
<p class="level4"><strong>Basic matrix operations</strong></p>
<p class="noindent">The elements of a matrix or vector are <strong><em><span class="blue1">scalar numbers</span></em></strong> from a number system, such as the real numbers, the complex numbers, or integers modulo a prime. The number system defines how to add and multiply scalars. These definitions extend to encompass addition and multiplication of matrices.</p>
<p>We define <strong><em><span class="blue1">matrix addition</span></em></strong> as follows. If <em>A</em> = (<em>a<sub>ij</sub></em>) and <em>B</em> = (<em>b<sub>ij</sub></em>) are <em>m</em> × <em>n</em> matrices, then their matrix sum <em>C</em> = (<em>c<sub>ij</sub></em>) = <em>A</em> + <em>B</em> is the <em>m</em> × <em>n</em> matrix defined by</p>
<p class="eql"><em>c<sub>ij</sub></em> = <em>a<sub>ij</sub></em> + <em>b<sub>ij</sub></em></p>
<p class="noindent">for <em>i</em> = 1, 2, … , <em>m</em> and <em>j</em> = 1, 2, … , <em>n</em>. That is, matrix addition is performed componentwise. A zero matrix is the identity for matrix addition:</p>
<p class="eql"><em>A</em> + 0 = <em>A</em> = 0 + <em>A</em>.</p>
<p>If is <em>λ</em> a scalar number and <em>A</em> = (<em>a<sub>ij</sub></em>) is a matrix, then <em>λA</em> = (<em>λa<sub>ij</sub></em>) is the <strong><em><span class="blue1">scalar multiple</span></em></strong> of <em>A</em> obtained by multiplying each of its elements by <em>λ</em>. As a special case, we define the <strong><em><span class="blue1">negative</span></em></strong> of a matrix <em>A</em> = (<em>a<sub>ij</sub></em>) to be −1 · <em>A</em> = −<em>A</em>, so that the <em>ij</em>th entry of −<em>A</em> is −<em>a<sub>ij</sub></em>. Thus,</p>
<p class="eql"><em>A</em> + (−<em>A</em>) = 0 = (−<em>A</em>) + <em>A</em>.</p>
<a id="p1218"/>
<p class="noindent">The negative of a matrix defines <strong><em><span class="blue1">matrix subtraction</span></em></strong>: <em>A</em> − <em>B</em> = <em>A</em> + (−<em>B</em>).</p>
<p>We define <strong><em><span class="blue1">matrix multiplication</span></em></strong> as follows. Start with two matrices <em>A</em> and <em>B</em> that are <strong><em><span class="blue1">compatible</span></em></strong> in the sense that the number of columns of <em>A</em> equals the number of rows of <em>B</em>. (In general, an expression containing a matrix product <em>AB</em> is always assumed to imply that matrices <em>A</em> and <em>B</em> are compatible.) If <em>A</em> = (<em>a<sub>ik</sub></em>) is a <em>p</em> × <em>q</em> matrix and <em>B</em> = (<em>b<sub>kj</sub></em>) is a <em>q</em> × <em>r</em> matrix, then their matrix product <em>C</em> = <em>AB</em> is the <em>p</em> × <em>r</em> matrix <em>C</em> = (<em>c<sub>ij</sub></em>), where</p>
<p class="eqr"><img alt="art" src="images/Art_P1778.jpg"/></p>
<p class="noindent">for <em>i</em> = 1, 2, … , <em>m</em> and <em>j</em> = 1, 2, … , <em>p</em>. The procedure R<small>ECTANGULAR</small>-M<small>ATRIX</small>-M<small>ULTIPLY</small> on page 374 implements matrix multiplication in the straightforward manner based on equation (D.2), assuming that <em>C</em> is initialized to 0, using <em>pqr</em> multiplications and <em>p</em>(<em>q</em> − 1)<em>r</em> additions for a running time of Θ(<em>pqr</em>). If the matrices are <em>n</em>×<em>n</em> square matrices, so that <em>n</em> = <em>p</em> = <em>q</em> = <em>r</em>, the pseudocode reduces to M<small>ATRIX</small>-M<small>ULTIPLY</small> on page 81, whose running time is Θ(<em>n</em><sup>3</sup>). (<a href="chapter004.xhtml#Sec_4.2">Section 4.2</a> describes an asymptotically faster Θ(<em>n</em><sup>lg7</sup>)-time algorithm due to V. Strassen.)</p>
<p>Matrices have many (but not all) of the algebraic properties typical of numbers. Identity matrices are identities for matrix multiplication:</p>
<p class="eql"><em>I<sub>m</sub>A</em> = <em>AI<sub>n</sub></em> = <em>A</em></p>
<p class="noindent">for any <em>m</em> × <em>n</em> matrix <em>A</em>. Multiplying by a zero matrix gives a zero matrix:</p>
<p class="eql"><em>A</em> · 0 = 0.</p>
<p class="noindent">Matrix multiplication is associative:</p>
<p class="eql"><em>A</em>(<em>BC</em>) = (<em>AB</em>)<em>C</em></p>
<p class="noindent">for compatible matrices <em>A</em>, <em>B</em>, and <em>C</em>. Matrix multiplication distributes over addition:</p>
<table class="table2b">
<tr>
<td class="td2"><em>A</em>(<em>B</em> + <em>C</em>)</td>
<td class="td2">=</td>
<td class="td2"><em>AB</em> + <em>AC</em>,</td>
</tr>
<tr>
<td class="td2">(<em>B</em> + <em>C</em>)<em>D</em></td>
<td class="td2">=</td>
<td class="td2"><em>BD</em> + <em>CD</em>.</td>
</tr>
</table>
<p class="noindent">For <em>n</em> &gt; 1, multiplication of <em>n</em> × <em>n</em> matrices is not commutative. For example, if <img alt="art" src="images/Art_P1779.jpg"/> and <img alt="art" src="images/Art_P1780.jpg"/>, then <img alt="art" src="images/Art_P1781.jpg"/> and <img alt="art" src="images/Art_P1782.jpg"/>.</p>
<p>We define matrix-vector products or vector-vector products as if the vector were the equivalent <em>n</em> × 1 matrix (or a 1 × <em>n</em> matrix, in the case of a row vector). Thus, if <em>A</em> is an <em>m</em> × <em>n</em> matrix and <em>x</em> is an <em>n</em>-vector, then <em>Ax</em> is an <em>m</em>-vector. If <em>x</em> and <em>y</em> are <em>n</em>-vectors, then</p>
<a id="p1219"/>
<p class="eql"><img alt="art" src="images/Art_P1783.jpg"/></p>
<p class="noindent">is a scalar number (actually a 1 × 1 matrix) called the <strong><em><span class="blue1">inner product</span></em></strong> of <em>x</em> and <em>y</em>. We also use the notation <span class="font1">〈</span><em>x</em>, <em>y</em><span class="font1">〉</span> to denote <em>x</em><sup>T</sup><em>y</em>. The inner-product operator is commutative: <span class="font1">〈</span><em>x</em>, <em>y</em><span class="font1">〉</span> = <span class="font1">〈</span><em>y</em>, <em>x</em><span class="font1">〉</span>. The matrix <em>xy</em><sup>T</sup> is an <em>n</em> × <em>n</em> matrix <em>Z</em> called the <strong><em><span class="blue1">outer product</span></em></strong> of <em>x</em> and <em>y</em>, where <em>z<sub>ij</sub></em> = <em>x<sub>i</sub>y<sub>j</sub></em>. The <strong><em><span class="blue1">(euclidean) norm</span></em></strong> <span class="font1">∥</span><em>x</em><span class="font1">∥</span> of an <em>n</em>-vector <em>x</em> is defined by</p>
<p class="eql"><img alt="art" src="images/Art_P1784.jpg"/></p>
<p class="noindent">Thus, the norm of <em>x</em> is its length in <em>n</em>-dimensional euclidean space. A useful fact, which follows from the equality</p>
<p class="eql"><img alt="art" src="images/Art_P1785.jpg"/></p>
<p class="noindent">is that for any real number <em>a</em> and <em>n</em>-vector <em>x</em>,</p>
<p class="eqr"><img alt="art" src="images/Art_P1786.jpg"/></p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level2"><strong><em>D.1-1</em></strong></p>
<p class="noindent">Show that if <em>A</em> and <em>B</em> are symmetric <em>n</em> × <em>n</em> matrices, then so are <em>A</em> + <em>B</em> and <em>A</em> − <em>B</em>.</p>
<p class="level2"><strong><em>D.1-2</em></strong></p>
<p class="noindent">Prove that (<em>AB</em>)<sup>T</sup> = <em>B</em><sup>T</sup><em>A</em><sup>T</sup> and that <em>A</em><sup>T</sup><em>A</em> is always a symmetric matrix.</p>
<p class="level2"><strong><em>D.1-3</em></strong></p>
<p class="noindent">Prove that the product of two lower-triangular matrices is lower-triangular.</p>
<p class="level2"><strong><em>D.1-4</em></strong></p>
<p class="noindent">Prove that if <em>P</em> is an <em>n</em> × <em>n</em> permutation matrix and <em>A</em> is an <em>n</em> × <em>n</em> matrix, then the matrix product <em>PA</em> is <em>A</em> with its rows permuted, and the matrix product <em>AP</em> is <em>A</em> with its columns permuted. Prove that the product of two permutation matrices is a permutation matrix.</p>
</section>
<p class="line1"/>
<section title="D.2 Basic matrix properties">
<a id="Sec_D.2"/>
<p class="level1" id="h1-233"><a href="toc.xhtml#Rh1-233"><strong>D.2 Basic matrix properties</strong></a></p>
<p class="noindent">We now define some basic properties pertaining to matrices: inverses, linear dependence and independence, rank, and determinants. We also define the class of positive-definite matrices.</p>
<a id="p1220"/>
<p class="level4"><strong>Matrix inverses, ranks, and determinants</strong></p>
<p class="noindent">The <strong><em><span class="blue1">inverse</span></em></strong> of an <em>n</em> × <em>n</em> matrix <em>A</em> is the <em>n</em> × <em>n</em> matrix, denoted <em>A</em><sup>−1</sup> (if it exists), such that <em>AA</em><sup>−1</sup> = <em>I<sub>n</sub></em> = <em>A</em><sup>−1</sup><em>A</em>. For example,</p>
<p class="eql"><img alt="art" src="images/Art_P1787.jpg"/></p>
<p class="noindent">Many nonzero <em>n</em> × <em>n</em> matrices do not have inverses. A matrix without an inverse is called <strong><em><span class="blue1">noninvertible</span></em></strong>, or <strong><em><span class="blue1">singular</span></em></strong>. An example of a nonzero singular matrix is</p>
<p class="eql"><img alt="art" src="images/Art_P1788.jpg"/></p>
<p class="noindent">If a matrix has an inverse, it is called <strong><em><span class="blue1">invertible</span></em></strong>, or <strong><em><span class="blue1">nonsingular</span></em></strong>. Matrix inverses, when they exist, are unique. (See Exercise D.2-1.) If <em>A</em> and <em>B</em> are nonsingular <em>n</em> × <em>n</em> matrices, then</p>
<p class="eql">(<em>BA</em>)<sup>−1</sup> = <em>A</em><sup>−1</sup><em>B</em><sup>−1</sup>.</p>
<p class="noindent">The inverse operation commutes with the transpose operation:</p>
<p class="eql">(<em>A</em><sup>−1</sup>)<sup>T</sup> = (<em>A</em><sup>T</sup>)<sup>−1</sup>.</p>
<p>The vectors <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, … , <em>x<sub>n</sub></em> are <strong><em><span class="blue1">linearly dependent</span></em></strong> if there exist coefficients <em>c</em><sub>1</sub>, <em>c</em><sub>2</sub>, … , <em>c<sub>n</sub></em>, not all of which are 0, such that <em>c</em><sub>1</sub><em>x</em><sub>1</sub> + <em>c</em><sub>2</sub><em>x</em><sub>2</sub> + <span class="font1">⋯</span> + <em>c<sub>n</sub>x<sub>n</sub></em> = 0. The row vectors <em>x</em><sub>1</sub> = ( 1 2 3 ), <em>x</em><sub>2</sub> = ( 2 6 4 ), and <em>x</em><sub>3</sub> = ( 4 11 9 ) are linearly dependent, for example, since 2<em>x</em><sub>1</sub>+3<em>x</em><sub>2</sub>−2<em>x</em><sub>3</sub> = 0. If vectors are not linearly dependent, they are <strong><em><span class="blue1">linearly independent</span></em></strong>. For example, the columns of an identity matrix are linearly independent.</p>
<p>The <strong><em><span class="blue1">column rank</span></em></strong> of a nonzero <em>m</em> × <em>n</em> matrix <em>A</em> is the size of the largest set of linearly independent columns of <em>A</em>. Similarly, the <strong><em><span class="blue1">row rank</span></em></strong> of <em>A</em> is the size of the largest set of linearly independent rows of <em>A</em>. A fundamental property of any matrix <em>A</em> is that its row rank always equals its column rank, so that we can simply refer to the <strong><em><span class="blue1">rank</span></em></strong> of <em>A</em>. The rank of an <em>m</em> × <em>n</em> matrix is an integer between 0 and min {<em>m</em>, <em>n</em>}, inclusive. (The rank of a zero matrix is 0, and the rank of an <em>n</em> × <em>n</em> identity matrix is <em>n</em>.) An alternate, but equivalent and often more useful, definition is that the rank of a nonzero <em>m</em>×<em>n</em> matrix <em>A</em> is the smallest number <em>r</em> such that there exist matrices <em>B</em> and <em>C</em> of respective sizes <em>m</em> × <em>r</em> and <em>r</em> × <em>n</em> such that <em>A</em> = <em>BC</em>. A square <em>n</em> × <em>n</em> matrix has <strong><em><span class="blue1">full rank</span></em></strong> if its rank is <em>n</em>. An <em>m</em> × <em>n</em> matrix has <strong><em><span class="blue1">full column rank</span></em></strong> if its rank is <em>n</em>. The following theorem gives a fundamental property of ranks.</p>
<p class="theo"><strong><em>Theorem D.1</em></strong></p>
<p class="noindent">A square matrix has full rank if and only if it is nonsingular.</p>
<p class="right"><span class="font1">▪</span></p>
<a id="p1221"/>
<p class="space-break">A <strong><em><span class="blue1">null vector</span></em></strong> for a matrix <em>A</em> is a nonzero vector <em>x</em> such that <em>Ax</em> = 0. The following theorem (whose proof is left as Exercise D.2-7) and its corollary relate the notions of column rank and singularity to null vectors.</p>
<p class="theo"><strong><em>Theorem D.2</em></strong></p>
<p class="noindent">A matrix has full column rank if and only if it does not have a null vector.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="cor"><strong><em>Corollary D.3</em></strong></p>
<p class="noindent">A square matrix is singular if and only if it has a null vector.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">The <em>ij</em>th <strong><em><span class="blue1">minor</span></em></strong> of an <em>n</em>×<em>n</em> matrix <em>A</em>, for <em>n</em> &gt; 1, is the (<em>n</em>−1)×(<em>n</em>−1) matrix <em>A</em><sub>[<em>ij</em>]</sub> obtained by deleting the <em>i</em>th row and <em>j</em>th column of <em>A</em>. The <strong><em><span class="blue1">determinant</span></em></strong> of an <em>n</em>×<em>n</em> matrix <em>A</em> is defined recursively in terms of its minors by</p>
<p class="eql"><img alt="art" src="images/Art_P1789.jpg"/></p>
<p class="noindent">The term (−1)<sup><em>i</em>+<em>j</em></sup> det(<em>A</em><sub>[<em>ij</em>]</sub>) is known as the <strong><em><span class="blue1">cofactor</span></em></strong> of the element <em>a<sub>ij</sub></em>.</p>
<p>The following theorems, whose proofs are omitted, express fundamental properties of the determinant.</p>
<p class="theo"><strong><em>Theorem D.4 (Determinant properties)</em></strong></p>
<p class="noindent">The determinant of a square matrix <em>A</em> has the following properties:</p>
<ul class="ulnoindent" epub:type="list">
<li>If any row or any column of <em>A</em> is zero, then det(<em>A</em>) = 0.</li>
<li class="litop">The determinant of <em>A</em> is multiplied by <em>λ</em> if the entries of any one row (or any one column) of <em>A</em> are all multiplied by <em>λ</em>.</li>
<li class="litop">The determinant of <em>A</em> is unchanged if the entries in one row (respectively, column) are added to those in another row (respectively, column).</li>
<li class="litop">The determinant of <em>A</em> equals the determinant of <em>A</em><sup>T</sup>.</li>
<li class="litop">The determinant of <em>A</em> is multiplied by −1 if any two rows (or any two columns) are exchanged.</li></ul>
<p class="noindent">Also, for any square matrices <em>A</em> and <em>B</em>, we have det(<em>AB</em>) = det(<em>A</em>) det(<em>B</em>).</p>
<p class="right"><span class="font1">▪</span></p>
<p class="theo"><strong><em>Theorem D.5</em></strong></p>
<p class="noindent">An <em>n</em> × <em>n</em> matrix <em>A</em> is singular if and only if det(<em>A</em>) = 0.</p>
<p class="right"><span class="font1">▪</span></p>
<a id="p1222"/>
<p class="level4"><strong>Positive-definite matrices</strong></p>
<p class="noindent">Positive-definite matrices play an important role in many applications. An <em>n</em> × <em>n</em> matrix <em>A</em> is <strong><em><span class="blue1">positive-definite</span></em></strong> if <em>x</em><sup>T</sup><em>Ax</em> &gt; 0 for all <em>n</em>-vectors <em>x</em> ≠ 0. For example, the identity matrix is positive-definite, since if <em>x</em> = ( <em>x</em><sub>1</sub> <em>x</em><sub>2</sub> <span class="font1">⋯</span> <em>x<sub>n</sub></em>)<sup>T</sup> is a nonzero vector, then</p>
<p class="eql"><img alt="art" src="images/Art_P1790.jpg"/></p>
<p>Matrices that arise in applications are often positive-definite due to the following theorem.</p>
<p class="theo"><strong><em>Theorem D.6</em></strong></p>
<p class="noindent">For any matrix <em>A</em> with full column rank, the matrix <em>A</em><sup>T</sup><em>A</em> is positive-definite.</p>
<p class="prof"><strong><em>Proof</em></strong>   We must show that <em>x</em><sup>T</sup>(<em>A</em><sup>T</sup><em>A</em>)<em>x</em> &gt; 0 for any nonzero vector <em>x</em>. For any vector <em>x</em>,</p>
<table class="table2b">
<tr>
<td class="td2"><em>x</em><sup>T</sup>(<em>A</em><sup>T</sup><em>A</em>)<em>x</em></td>
<td class="td2">=</td>
<td class="td2">(<em>Ax</em>)<sup>T</sup>(<em>Ax</em>)</td>
<td class="td2">(by Exercise D.1-2)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><span class="font1">∥</span><em>Ax</em><span class="font1">∥</span><sup>2</sup>.</td>
<td class="td2"/>
</tr>
</table>
<p class="noindent">The value <span class="font1">∥</span><em>Ax</em><span class="font1">∥</span><sup>2</sup> is just the sum of the squares of the elements of the vector <em>Ax</em>. Therefore, <span class="font1">∥</span><em>Ax</em><span class="font1">∥</span><sup>2</sup> ≥ 0. We’ll show by contradiction that <span class="font1">∥</span><em>Ax</em><span class="font1">∥</span><sup>2</sup> &gt; 0. Suppose that <span class="font1">∥</span><em>Ax</em><span class="font1">∥</span><sup>2</sup> = 0. Then, every element of <em>Ax</em> is 0, which is to say <em>Ax</em> = 0. Since <em>A</em> has full column rank, Theorem D.2 says that <em>x</em> = 0, which contradicts the requirement that <em>x</em> is nonzero. Hence, <em>A</em><sup>T</sup><em>A</em> is positive-definite.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break"><a href="chapter028.xhtml#Sec_28.3">Section 28.3</a> explores other properties of positive-definite matrices. <a href="chapter033.xhtml#Sec_33.3">Section 33.3</a> uses a similar condition, known as positive-semidefinite. An <em>n</em> × <em>n</em> matrix <em>A</em> is <strong><em><span class="blue1">positive-semidefinite</span></em></strong> if <em>x</em><sup>T</sup><em>Ax</em> ≥ 0 for all <em>n</em>-vectors <em>x</em> ≠ 0.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level2"><strong><em>D.2-1</em></strong></p>
<p class="noindent">Prove that matrix inverses are unique, that is, if <em>B</em> and <em>C</em> are inverses of <em>A</em>, then <em>B</em> = <em>C</em>.</p>
<a id="p1223"/>
<p class="level2"><strong><em>D.2-2</em></strong></p>
<p class="noindent">Prove that the determinant of a lower-triangular or upper-triangular matrix is equal to the product of its diagonal elements. Prove that the inverse of a lower-triangular matrix, if it exists, is lower-triangular.</p>
<p class="level2"><strong><em>D.2-3</em></strong></p>
<p class="noindent">Prove that if <em>P</em> is a permutation matrix, then <em>P</em> is invertible, its inverse is <em>P</em><sup>T</sup>, and <em>P</em><sup>T</sup> is a permutation matrix.</p>
<p class="level2"><strong><em>D.2-4</em></strong></p>
<p class="noindent">Let <em>A</em> and <em>B</em> be <em>n</em> × <em>n</em> matrices such that <em>AB</em> = <em>I</em>. Prove that if <em>A</em>′ is obtained from <em>A</em> by adding row <em>j</em> into row <em>i</em>, where <em>i</em> ≠ <em>j</em>, then subtracting column <em>i</em> from column <em>j</em> of <em>B</em> yields the inverse <em>B</em>′ of <em>A</em>′.</p>
<p class="level2"><strong><em>D.2-5</em></strong></p>
<p class="noindent">Let <em>A</em> be a nonsingular <em>n</em> × <em>n</em> matrix with complex entries. Show that every entry of <em>A</em><sup>−1</sup> is real if and only if every entry of <em>A</em> is real.</p>
<p class="level2"><strong><em>D.2-6</em></strong></p>
<p class="noindent">Show that if <em>A</em> is a nonsingular, symmetric, <em>n</em> × <em>n</em> matrix, then <em>A</em><sup>−1</sup> is symmetric. Show that if <em>B</em> is an arbitrary <em>m</em> × <em>n</em> matrix, then the <em>m</em> × <em>m</em> matrix given by the product <em>BAB</em><sup>T</sup> is symmetric.</p>
<p class="level2"><strong><em>D.2-7</em></strong></p>
<p class="noindent">Prove Theorem D.2. That is, show that a matrix <em>A</em> has full column rank if and only if <em>Ax</em> = 0 implies <em>x</em> = 0. (<em>Hint:</em> Express the linear dependence of one column on the others as a matrix-vector equation.)</p>
<p class="level2"><strong><em>D.2-8</em></strong></p>
<p class="noindent">Prove that for any two compatible matrices <em>A</em> and <em>B</em>,</p>
<p class="eql">rank(<em>AB</em>) ≤ min {rank(<em>A</em>), rank(<em>B</em>)},</p>
<p class="noindent">where equality holds if either <em>A</em> or <em>B</em> is a nonsingular square matrix. (<em>Hint:</em> Use the alternate definition of the rank of a matrix.)</p>
</section>
<p class="line1"/>
<section title="Problems">
<p class="level1" id="h1-234"><strong>Problems</strong></p>
<section title="D-1 Vandermonde matrix">
<p class="level2"><strong><em>D-1 Vandermonde matrix</em></strong></p>
<p class="noindent">Given numbers <em>x</em><sub>0</sub>, <em>x</em><sub>1</sub>, … , <em>x</em><sub><em>n</em>−1</sub>, prove that the determinant of the <strong><em><span class="blue1">Vandermonde matrix</span></em></strong></p>
<a id="p1224"/>
<p class="eql"><img alt="art" src="images/Art_P1791.jpg"/></p>
<p class="noindent">is</p>
<p class="eql"><img alt="art" src="images/Art_P1792.jpg"/></p>
<p class="noindent">(<em>Hint:</em> Multiply column <em>i</em> by −<em>x</em><sub>0</sub> and add it to column <em>i</em> + 1 for <em>i</em> = <em>n</em> − 1, <em>n</em> − 2, … , 1, and then use induction.)</p>
</section>
<section title="D-2 Permutations defined by matrix-vector multiplication over GF.(2)">
<p class="level2"><strong><em>D-2 Permutations defined by matrix-vector multiplication over GF</em>.(<em>2</em>)</strong></p>
<p class="noindent">One class of permutations of the integers in the set <em>S<sub>n</sub></em> = {0, 1, 2, … , 2<em><sup>n</sup></em> − 1} is defined by matrix multiplication over <em>GF</em>(2), the Galois field of two elements. For each integer <em>x</em> ∈ <em>S<sub>n</sub></em>, we view its binary representation as an <em>n</em>-bit vector</p>
<p class="eql"><img alt="art" src="images/Art_P1793.jpg"/></p>
<p class="noindent">where <img alt="art" src="images/Art_P1794.jpg"/>. If <em>A</em> is an <em>n</em> × <em>n</em> matrix in which each entry is either 0 or 1, then we can define a permutation mapping each value <em>x</em> ∈ <em>S<sub>n</sub></em> to the number whose binary representation is the matrix-vector product <em>Ax</em>. All this arithmetic is performed over <span class="blue1"><strong><em>GF</em>(2)</strong></span>: all values are either 0 or 1, and with one exception, the usual rules of addition and multiplication apply. The exception is that 1 + 1 = 0. You can think of arithmetic over <em>GF</em>(2) as being just like regular integer arithmetic, except that you use only the least-significant bit.</p>
<p>As an example, for <em>S</em><sub>2</sub> = {0, 1, 2, 3}, the matrix</p>
<p class="eql"><img alt="art" src="images/Art_P1795.jpg"/></p>
<p class="noindent">defines the following permutation <em>π<sub>A</sub></em>: <em>π<sub>A</sub></em>(0) = 0, <em>π<sub>A</sub></em>(1) = 3, <em>π<sub>A</sub></em>(2) = 2, <em>π<sub>A</sub></em>(3) = 1. To see why <em>π<sub>A</sub></em>(3) = 1, observe that, working in <em>GF</em>(2),</p>
<a id="p1225"/>
<p class="eql"><img alt="art" src="images/Art_P1796.jpg"/></p>
<p class="noindent">which is the binary representation of 1.</p>
<p>For the remainder of this problem, we’ll work over <em>GF</em>(2), and all matrix and vector entries will be 0 or 1. Define the <strong><em><span class="blue1">rank</span></em></strong> of a 0-1 matrix (a matrix for which each entry is either 0 or 1) over <em>GF</em>(2) the same as for a regular matrix, but with all arithmetic that determines linear independence performed over <em>GF</em>(2). We define the <strong><em><span class="blue1">range</span></em></strong> of an <em>n</em> × <em>n</em> 0-1 matrix <em>A</em> by</p>
<p class="eql"><em>R</em>(<em>A</em>) = {<em>y</em> : <em>y</em> = <em>Ax</em> for some <em>x</em> ∈ <em>S<sub>n</sub></em>},</p>
<p class="noindent">so that <em>R</em>(<em>A</em>) is the set of numbers in <em>S<sub>n</sub></em> that are produced by multiplying each value <em>x</em> ∈ <em>S<sub>n</sub></em> by <em>A</em>.</p>
<p class="nl-1list-d"><strong><em>a.</em></strong> If <em>r</em> is the rank of matrix <em>A</em>, prove that |<em>R</em>(<em>A</em>)| = 2<em><sup>r</sup></em>. Conclude that <em>A</em> defines a permutation on <em>S<sub>n</sub></em> only if <em>A</em> has full rank.</p>
<p class="space-break">For a given <em>n</em> × <em>n</em> matrix <em>A</em> and a given value <em>y</em> ∈ <em>R</em>(<em>A</em>), we define the <strong><em><span class="blue1">preimage</span></em></strong> of <em>y</em> by</p>
<p class="eql"><em>P</em> (<em>A</em>, <em>y</em>) = {<em>x</em> : <em>Ax</em> = <em>y</em>},</p>
<p class="noindent">so that <em>P</em>(<em>A</em>, <em>y</em>) is the set of values in <em>S<sub>n</sub></em> that map to <em>y</em> when multiplied by <em>A</em>.</p>
<p class="nl-1list-d"><strong><em>b.</em></strong> If <em>r</em> is the rank of <em>n</em> × <em>n</em> matrix <em>A</em> and <em>y</em> ∈ <em>R</em>(<em>A</em>), prove that |<em>P</em>(<em>A</em>, <em>y</em>)| = 2<sup><em>n</em>−<em>r</em></sup>.</p>
<p class="space-break">Let 0 ≤ <em>m</em> ≤ <em>n</em>, and suppose that we partition the set <em>S<sub>n</sub></em> into blocks of consecutive numbers, where the <em>i</em>th block consists of the 2<sup><em>m</em></sup> numbers <em>i</em>2<sup><em>m</em></sup>, <em>i</em>2<sup><em>m</em></sup> + 1, <em>i</em>2<sup><em>m</em></sup> +2, … , (<em>i</em> +1)2<em><sup>m</sup></em> −1. For any subset <em>S</em> ⊆ <em>S<sub>n</sub></em>, define <em>B</em>(<em>S</em>, <em>m</em>) to be the set of size-2<em><sup>m</sup></em> blocks of <em>S<sub>n</sub></em> containing some element of <em>S</em>. As an example, when <em>n</em> = 3, <em>m</em> = 1, and <em>S</em> = {1, 4, 5}, then <em>B</em>(<em>S</em>, <em>m</em>) consists of blocks 0 (since 1 is in the 0th block) and 2 (since both 4 and 5 belong to block 2).</p>
<p class="nl-1list-d"><strong><em>c.</em></strong> Let <em>r</em> be the rank of the lower left (<em>n</em> − <em>m</em>) × <em>m</em> submatrix of <em>A</em>, that is, the matrix formed by taking the intersection of the bottom <em>n</em> − <em>m</em> rows and the leftmost <em>m</em> columns of <em>A</em>. Let <em>S</em> be any size-2<em><sup>m</sup></em> block of <em>S<sub>n</sub></em>, and let <em>S</em>′ = {<em>y</em> : <em>y</em> = <em>Ax</em> for some <em>x</em> ∈ <em>S</em>}. Prove that |<em>B</em>(<em>S</em>′, <em>m</em>)| = 2<em><sup>r</sup></em> and that for each block in <em>B</em>(<em>S</em>′, <em>m</em>), exactly 2<sup><em>m</em>−<em>r</em></sup> numbers in <em>S</em> map to that block.</p>
<a id="p1226"/>
<p class="space-break">Because multiplying the zero vector by any matrix yields a zero vector, the set of permutations of <em>S<sub>n</sub></em> defined by multiplying by <em>n</em> × <em>n</em> 0-1 matrices with full rank over <em>GF</em>(2) cannot include all permutations of <em>S<sub>n</sub></em>. Let’s extend the class of permutations defined by matrix-vector multiplication to include an additive term, so that <em>x</em> ∈ <em>S<sub>n</sub></em> maps to <em>Ax</em> + <em>c</em>, where <em>c</em> is an <em>n</em>-bit vector and addition is performed over <em>GF</em>(2). For example, when</p>
<p class="eql"><img alt="art" src="images/Art_P1797.jpg"/></p>
<p class="noindent">and</p>
<p class="eql"><img alt="art" src="images/Art_P1798.jpg"/></p>
<p class="noindent">we get the following permutation <em>π<sub>A,c</sub></em>: <em>π<sub>A,c</sub></em>(0) = 2, <em>π<sub>A,c</sub></em>(1) = 1, <em>π<sub>A,c</sub></em>(2) = 0, <em>π<sub>A,c</sub></em>(3) = 3. We call any permutation that maps <em>x</em> ∈ <em>S<sub>n</sub></em> to <em>Ax</em> + <em>c</em>, for some <em>n</em> × <em>n</em> 0-1 matrix <em>A</em> with full rank and some <em>n</em>-bit vector <em>c</em>, a <strong><em><span class="blue1">linear permutation</span></em></strong>.</p>
<p class="nl-1list-d"><strong><em>d.</em></strong> Use a counting argument to show that the number of linear permutations of <em>S<sub>n</sub></em> is much less than the number of permutations of <em>S<sub>n</sub></em>.</p>
<p class="nl-1list-d"><strong><em>e.</em></strong> Give an example of a value of <em>n</em> and a permutation of <em>S<sub>n</sub></em> that cannot be achieved by any linear permutation. (<em>Hint:</em> For a given permutation, think about how multiplying a matrix by a unit vector relates to the columns of the matrix.)</p>
</section>
</section>
<p class="line1"/>
<section title="Appendix notes">
<p class="level1" id="h1-235"><strong>Appendix notes</strong></p>
<p class="noindent">Linear-algebra textbooks provide plenty of background information on matrices. The books by Strang [<a epub:type="noteref" href="bibliography001.xhtml#endnote_422">422</a>, <a epub:type="noteref" href="bibliography001.xhtml#endnote_423">423</a>] are particularly good.</p>
</section>
</section>
</div>
</body>
</html>