<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"/>
<title>Introduction to Algorithms</title>
<link href="css/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4a9ccac5-f2db-4081-af1f-a5a376b433e1" name="Adept.expected.resource"/>
</head>
<body>
<div class="body"><a id="p1042"/>
<p class="line-c"/>
<section epub:type="bodymatter chapter" title="34 NP-Completeness">
<p class="chapter-title"><a href="toc.xhtml#chap-34"><strong><span class="blue1">34        NP-Completeness</span></strong></a></p>
<p class="noindent">Almost all the algorithms we have studied thus far have been <strong><em><span class="blue">polynomial-time algorithms</span></em></strong>: on inputs of size <em>n</em>, their worst-case running time is <em>O</em>(<em>n<sup>k</sup></em>) for some constant <em>k</em>. You might wonder whether <em>all</em> problems can be solved in polynomial time. The answer is no. For example, there are problems, such as Turing’s famous “Halting Problem,” that cannot be solved by any computer, no matter how long you’re willing to wait for an answer.<sup><a epub:type="footnote" href="#footnote_1" id="footnote_ref_1">1</a></sup> There are also problems that can be solved, but not in <em>O</em>(<em>n<sup>k</sup></em>) time for any constant <em>k</em>. Generally, we think of problems that are solvable by polynomial-time algorithms as being tractable, or “easy,” and problems that require superpolynomial time as being intractable, or “hard.”</p>
<p>The subject of this chapter, however, is an interesting class of problems, called the “NP-complete” problems, whose status is unknown. No polynomial-time algorithm has yet been discovered for an NP-complete problem, nor has anyone yet been able to prove that no polynomial-time algorithm can exist for any one of them. This so-called P ≠ NP question has been one of the deepest, most perplexing open research problems in theoretical computer science since it was first posed in 1971.</p>
<p>Several NP-complete problems are particularly tantalizing because they seem on the surface to be similar to problems that we know how to solve in polynomial time. In each of the following pairs of problems, one is solvable in polynomial time and the other is NP-complete, but the difference between the problems appears to be slight:</p>
<p class="para-hang-top"><strong>Shortest versus longest simple paths:</strong> In <a href="chapter022.xhtml">Chapter 22</a>, we saw that even with negative edge weights, we can find <em>shortest</em> paths from a single source in a directed <a id="p1043"/>graph <em>G</em> = (<em>V</em>, <em>E</em>) in <em>O</em>(<em>VE</em>) time. Finding a <em>longest</em> simple path between two vertices is difficult, however. Merely determining whether a graph contains a simple path with at least a given number of edges is NP-complete.</p>
<p class="para-hang-top"><strong>Euler tour versus hamiltonian cycle:</strong> An <strong><em><span class="blue">Euler tour</span></em></strong> of a strongly connected, directed graph <em>G</em> = (<em>V</em>, <em>E</em>) is a cycle that traverses each <em>edge</em> of <em>G</em> exactly once, although it is allowed to visit each vertex more than once. Problem 20-3 on page 583 asks you to show how to determine whether a strongly connected, directed graph has an Euler tour and, if it does, the order of the edges in the Euler tour, all in <em>O</em>(<em>E</em>) time. A <strong><em><span class="blue">hamiltonian cycle</span></em></strong> of a directed graph <em>G</em> = (<em>V</em>, <em>E</em>) is a simple cycle that contains each <em>vertex</em> in <em>V</em>. Determining whether a directed graph has a hamiltonian cycle is NP-complete. (Later in this chapter, we’ll prove that determining whether an <em>undirected</em> graph has a hamiltonian cycle is NP-complete.)</p>
<p class="para-hang-top"><strong>2-CNF satisfiability versus 3-CNF satisfiability:</strong> Boolean formulas contain binary variables whose values are 0 or 1; boolean connectives such as ∧ (AND), ∨ (OR), and ¬ (NOT); and parentheses. A boolean formula is <strong><em><span class="blue">satisfiable</span></em></strong> if there exists some assignment of the values 0 and 1 to its variables that causes it to evaluate to 1. We’ll define terms more formally later in this chapter, but informally, a boolean formula is in <strong><em><span class="blue">k-conjunctive normal form</span></em></strong>, or <em>k</em>-CNF if it is the AND of clauses of ORs of exactly <em>k</em> variables or their negations. For example, the boolean formula (<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub>) ∧ (¬<em>x</em><sub>1</sub> ∨ <em>x</em><sub>3</sub>) ∧ (¬<em>x</em><sub>2</sub> ∨ ¬<em>x</em><sub>3</sub>) is in 2-CNF (with satisfying assignment <em>x</em><sub>1</sub> = 1, <em>x</em><sub>2</sub> = 0, and <em>x</em><sub>3</sub> = 1). Although there is a polynomial-time algorithm to determine whether a 2-CNF formula is satisfiable, we’ll see later in this chapter that determining whether a 3-CNF formula is satisfiable is NP-complete.</p>
<p class="level4"><strong>NP-completeness and the classes P and NP</strong></p>
<p class="noindent">Throughout this chapter, we refer to three classes of problems: P, NP, and NPC, the latter class being the NP-complete problems. We describe them informally here, with formal definitions to appear later on.</p>
<p>The class P consists of those problems that are solvable in polynomial time. More specifically, they are problems that can be solved in <em>O</em>(<em>n<sup>k</sup></em>) time for some constant <em>k</em>, where <em>n</em> is the size of the input to the problem. Most of the problems examined in previous chapters belong to P.</p>
<p>The class NP consists of those problems that are “verifiable” in polynomial time. What do we mean by a problem being verifiable? If you were somehow given a “certificate” of a solution, then you could verify that the certificate is correct in time polynomial in the size of the input to the problem. For example, in the hamiltonian-cycle problem, given a directed graph <em>G</em> = (<em>V</em>, <em>E</em>), a certificate would <a id="p1044"/>be a sequence <span class="font1"><span class="font1">〈</span></span><em>v</em><sub>1</sub>, <em>v</em><sub>2</sub>, <em>v</em><sub>3</sub>, …, <em>v</em><sub>|<em>V</em>|</sub><span class="font1"><span class="font1">〉</span></span> of |<em>V</em>| vertices. You could check in polynomial time that the sequence contains each of the |<em>V</em>| vertices exactly once, that (<em>v<sub>i</sub></em>, <em>v</em><sub><em>i</em>+1</sub>) ∈ <em>E</em> for <em>i</em> = 1, 2, 3, …, |<em>V</em>| − 1, and that (<em>v</em><sub>|<em>V</em>|</sub>, <em>v</em><sub>1</sub>) ∈ <em>E</em>. As another example, for 3-CNF satisfiability, a certificate could be an assignment of values to variables. You could check in polynomial time that this assignment satisfies the boolean formula.</p>
<p>Any problem in P also belongs to NP, since if a problem belongs to P then it is solvable in polynomial time without even being supplied a certificate. We’ll formalize this notion later in this chapter, but for now you can believe that P ⊆ NP. The famous open question is whether P is a proper subset of NP.</p>
<p>Informally, a problem belongs to the class NPC—and we call it <strong><em><span class="blue">NP-complete</span></em></strong>—if it belongs to NP and is as “hard” as any problem in NP. We’ll formally define what it means to be as hard as any problem in NP later in this chapter. In the meantime, we state without proof that if <em>any</em> NP-complete problem can be solved in polynomial time, then <em>every</em> problem in NP has a polynomial-time algorithm. Most theoretical computer scientists believe that the NP-complete problems are intractable, since given the wide range of NP-complete problems that have been studied to date—without anyone having discovered a polynomial-time solution to any of them—it would be truly astounding if all of them could be solved in polynomial time. Yet, given the effort devoted thus far to proving that NP-complete problems are intractable—without a conclusive outcome—we cannot rule out the possibility that the NP-complete problems could turn out to be solvable in polynomial time.</p>
<p>To become a good algorithm designer, you must understand the rudiments of the theory of NP-completeness. If you can establish a problem as NP-complete, you provide good evidence for its intractability. As an engineer, you would then do better to spend your time developing an approximation algorithm (see <a href="chapter035.xhtml">Chapter 35</a>) or solving a tractable special case, rather than searching for a fast algorithm that solves the problem exactly. Moreover, many natural and interesting problems that on the surface seem no harder than sorting, graph searching, or network flow are in fact NP-complete. Therefore, you should become familiar with this remarkable class of problems.</p>
<p class="level4"><strong>Overview of showing problems to be NP-complete</strong></p>
<p class="noindent">The techniques used to show that a particular problem is NP-complete differ fundamentally from the techniques used throughout most of this book to design and analyze algorithms. If you can demonstrate that a problem is NP-complete, you are making a statement about how hard it is (or at least how hard we think it is), rather than about how easy it is. If you prove a problem NP-complete, you are saying that searching for efficient algorithm is likely to be a fruitless endeavor. In this <a id="p1045"/>way, NP-completeness proofs bear some similarity to the proof in <a href="chapter008.xhtml#Sec_8.1">Section 8.1</a> of an Ω(<em>n</em> lg <em>n</em>)-time lower bound for any comparison sort algorithm, although the specific techniques used for showing NP-completeness differ from the decision-tree method used in <a href="chapter008.xhtml#Sec_8.1">Section 8.1</a>.</p>
<p>We rely on three key concepts in showing a problem to be NP-complete:</p>
<p class="level4"><strong><em>Decision problems versus optimization problems</em></strong></p>
<p class="noindent">Many problems of interest are <strong><em><span class="blue">optimization problems</span></em></strong>, in which each feasible (i.e., “legal”) solution has an associated value, and the goal is to find a feasible solution with the best value. For example, in a problem that we call SHORTEST-PATH, the input is an undirected graph <em>G</em> and vertices <em>u</em> and <em>v</em>, and the goal is to find a path from <em>u</em> to <em>v</em> that uses the fewest edges. In other words, SHORTEST-PATH is the single-pair shortest-path problem in an unweighted, undirected graph. NP-completeness applies directly not to optimization problems, however, but to <strong><em><span class="blue">decision problems</span></em></strong>, in which the answer is simply “yes” or “no” (or, more formally, “1” or “0”).</p>
<p>Although NP-complete problems are confined to the realm of decision problems, there is usually a way to cast a given optimization problem as a related decision problem by imposing a bound on the value to be optimized. For example, a decision problem related to SHORTEST-PATH is PATH: given an undirected graph <em>G</em>, vertices <em>u</em> and <em>v</em>, and an integer <em>k</em>, does a path exist from <em>u</em> to <em>v</em> consisting of at most <em>k</em> edges?</p>
<p>The relationship between an optimization problem and its related decision problem works in your favor when you try to show that the optimization problem is “hard.” That is because the decision problem is in a sense “easier,” or at least “no harder.” As a specific example, you can solve PATH by solving SHORTEST-PATH and then comparing the number of edges in the shortest path found to the value of the decision-problem parameter <em>k</em>. In other words, if an optimization problem is easy, its related decision problem is easy as well. Stated in a way that has more relevance to NP-completeness, if you can provide evidence that a decision problem is hard, you also provide evidence that its related optimization problem is hard. Thus, even though it restricts attention to decision problems, the theory of NP-completeness often has implications for optimization problems as well.</p>
<p class="level4"><strong><em>Reductions</em></strong></p>
<p class="noindent">The above notion of showing that one problem is no harder or no easier than another applies even when both problems are decision problems. Almost every NP-completeness proof takes advantage of this idea, as follows. Consider a decision problem <em>A</em>, which you would like to solve in polynomial time. We call the input to a particular problem an <strong><em><span class="blue">instance</span></em></strong> of that problem. For example, in PATH, an <a id="p1046"/>instance is a particular graph <em>G</em>, particular vertices <em>u</em> and <em>v</em> of <em>G</em>, and a particular integer <em>k</em>. Now suppose that you already know how to solve a different decision problem <em>B</em> in polynomial time. Finally, suppose that you have a procedure that transforms any instance <em>α</em> of <em>A</em> into some instance <em>β</em> of <em>B</em> with the following characteristics:</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-1"><img alt="art" class="width100" src="images/Art_P1430.jpg"/></p>
<p class="caption"><strong>Figure 34.1</strong> How to use a polynomial-time reduction algorithm to solve a decision problem <em>A</em> in polynomial time, given a polynomial-time decision algorithm for another problem <em>B</em>. In polynomial time, transform an instance <em>α</em> of <em>A</em> into an instance <em>β</em> of <em>B</em>, solve <em>B</em> in polynomial time, and use the answer for <em>β</em> as the answer for <em>α</em>.</p>
</div>
<ul class="ulnoindent" epub:type="list">
<li>The transformation takes polynomial time.</li>
<li class="litop">The answers are the same. That is, the answer for <em>α</em> is “yes” if and only if the answer for <em>β</em> is also “yes.”</li></ul>
<p class="noindent">We call such a procedure a polynomial-time <strong><em><span class="blue">reduction algorithm</span></em></strong> and, as <a href="chapter034.xhtml#Fig_34-1">Figure 34.1</a> shows, it provides us a way to solve problem <em>A</em> in polynomial time:</p>
<ol class="olnoindent" epub:type="list">
<li>Given an instance <em>α</em> of problem <em>A</em>, use a polynomial-time reduction algorithm to transform it to an instance <em>β</em> of problem <em>B</em>.</li>
<li class="litop">Run the polynomial-time decision algorithm for <em>B</em> on the instance <em>β</em>.</li>
<li class="litop">Use the answer for <em>β</em> as the answer for <em>α</em>.</li></ol>
<p class="noindent">As long as each of these steps takes polynomial time, all three together do also, and so you have a way to decide on <em>α</em> in polynomial time. In other words, by “reducing” solving problem <em>A</em> to solving problem <em>B</em>, you use the “easiness” of <em>B</em> to prove the “easiness” of <em>A</em>.</p>
<p>Recalling that NP-completeness is about showing how hard a problem is rather than how easy it is, you use polynomial-time reductions in the opposite way to show that a problem is NP-complete. Let’s take the idea a step further and show how you can use polynomial-time reductions to show that no polynomial-time algorithm can exist for a particular problem <em>B</em>. Suppose that you have a decision problem <em>A</em> for which you already know that no polynomial-time algorithm can exist. (Ignore for the moment how to find such a problem <em>A</em>.) Suppose further that you have a polynomial-time reduction transforming instances of <em>A</em> to instances of <em>B</em>. Now you can use a simple proof by contradiction to show that no polynomial-time algorithm can exist for <em>B</em>. Suppose otherwise, that is, suppose that <em>B</em> has a <a id="p1047"/>polynomial-time algorithm. Then, using the method shown in <a href="chapter034.xhtml#Fig_34-1">Figure 34.1</a>, you would have a way to solve problem <em>A</em> in polynomial time, which contradicts the assumption that there is no polynomial-time algorithm for <em>A</em>.</p>
<p>To prove that a problem <em>B</em> is NP-complete, the methodology is similar. Although you cannot assume that there is absolutely no polynomial-time algorithm for problem <em>A</em>, you prove that problem <em>B</em> is NP-complete on the assumption that problem <em>A</em> is also NP-complete.</p>
<p class="level4"><strong><em>A first NP-complete problem</em></strong></p>
<p class="noindent">Because the technique of reduction relies on having a problem already known to be NP-complete in order to prove a different problem NP-complete, there must be some “first” NP-complete problem. We’ll use the circuit-satisfiability problem, in which the input is a boolean combinational circuit composed of AND, OR, and NOT gates, and the question is whether there exists some set of boolean inputs to this circuit that causes its output to be 1. <a href="chapter034.xhtml#Sec_34.3">Section 34.3</a> will prove that this first problem is NP-complete.</p>
<p class="level4"><strong>Chapter outline</strong></p>
<p class="noindent">This chapter studies the aspects of NP-completeness that bear most directly on the analysis of algorithms. <a href="chapter034.xhtml#Sec_34.1">Section 34.1</a> formalizes the notion of “problem” and defines the complexity class P of polynomial-time solvable decision problems. We’ll also see how these notions fit into the framework of formal-language theory. <a href="chapter034.xhtml#Sec_34.2">Section 34.2</a> defines the class NP of decision problems whose solutions are verifiable in polynomial time. It also formally poses the P ≠ NP question.</p>
<p><a href="chapter034.xhtml#Sec_34.3">Section 34.3</a> shows how to relate problems via polynomial-time “reductions.” It defines NP-completeness and sketches a proof that the circuit-satisfiability problem is NP-complete. With one problem proven NP-complete, <a href="chapter034.xhtml#Sec_34.4">Section 34.4</a> demonstrates how to prove other problems to be NP-complete much more simply by the methodology of reductions. To illustrate this methodology, the section shows that two formula-satisfiability problems are NP-complete. <a href="chapter034.xhtml#Sec_34.5">Section 34.5</a> proves a variety of other problems to be NP-complete by using reductions. You will probably find several of these reductions to be quite creative, because they convert a problem in one domain to a problem in a completely different domain.</p>
<a id="p1048"/>
<p class="line1"/>
<section title="34.1 Polynomial time">
<a id="Sec_34.1"/>
<p class="level1" id="h1-199"><a href="toc.xhtml#Rh1-199"><strong>34.1    Polynomial time</strong></a></p>
<p class="noindent">Since NP-completeness relies on notions of solving a problem and verifying a certificate in polynomial time, let’s first examine what it means for a problem to be solvable in polynomial time.</p>
<p>Recall that we generally regard problems that have polynomial-time solutions as tractable. Here are three reasons why:</p>
<ol class="olnoindent" epub:type="list">
<li>Although no reasonable person considers a problem that requires Θ(<em>n</em><sup>100</sup>) time to be tractable, few practical problems require time on the order of such a high-degree polynomial. The polynomial-time computable problems encountered in practice typically require much less time. Experience has shown that once the first polynomial-time algorithm for a problem has been discovered, more efficient algorithms often follow. Even if the current best algorithm for a problem has a running time of Θ(<em>n</em><sup>100</sup>), an algorithm with a much better running time will likely soon be discovered.</li>
<li class="litop">For many reasonable models of computation, a problem that can be solved in polynomial time in one model can be solved in polynomial time in another. For example, the class of problems solvable in polynomial time by the serial random-access machine used throughout most of this book is the same as the class of problems solvable in polynomial time on abstract Turing machines.<sup><a epub:type="footnote" href="#footnote_2" id="footnote_ref_2">2</a></sup> It is also the same as the class of problems solvable in polynomial time on a parallel computer when the number of processors grows polynomially with the input size.</li>
<li class="litop">The class of polynomial-time solvable problems has nice closure properties, since polynomials are closed under addition, multiplication, and composition. For example, if the output of one polynomial-time algorithm is fed into the input of another, the composite algorithm is polynomial. Exercise 34.1-5 asks you to show that if an algorithm makes a constant number of calls to polynomial-time subroutines and performs an additional amount of work that also takes polynomial time, then the running time of the composite algorithm is polynomial.</li></ol>
<p class="level4"><strong>Abstract problems</strong></p>
<p class="noindent">To understand the class of polynomial-time solvable problems, you must first have a formal notion of what a “problem” is. We define an <strong><em><span class="blue">abstract problem</span></em></strong> <em>Q</em> to be a <a id="p1049"/>binary relation on a set <em>I</em> of problem <strong><em><span class="blue">instances</span></em></strong> and a set <em>S</em> of problem <strong><em><span class="blue">solutions</span></em></strong>. For example, an instance for SHORTEST-PATH is a triple consisting of a graph and two vertices. A solution is a sequence of vertices in the graph, with perhaps the empty sequence denoting that no path exists. The problem SHORTEST-PATH itself is the relation that associates each instance of a graph and two vertices with a shortest path in the graph that connects the two vertices. Since shortest paths are not necessarily unique, a given problem instance may have more than one solution.</p>
<p>This formulation of an abstract problem is more general than necessary for our purposes. As we saw above, the theory of NP-completeness restricts attention to <strong><em><span class="blue">decision problems</span></em></strong>: those having a yes/no solution. In this case, we can view an abstract decision problem as a function that maps the instance set <em>I</em> to the solution set {0, 1}. For example, a decision problem related to SHORTEST-PATH is the problem PATH that we saw earlier. If <em>i</em> = <span class="font1"><span class="font1">〈</span></span><em>G, u, v, k</em><span class="font1"><span class="font1">〉</span></span> is an instance of PATH, then PATH(<em>i</em>) = 1 (yes) if <em>G</em> contains a path from <em>u</em> to <em>v</em> with at most <em>k</em> edges, and PATH(<em>i</em>) = 0 (no) otherwise. Many abstract problems are not decision problems, but rather <strong><em><span class="blue">optimization problems</span></em></strong>, which require some value to be minimized or maximized. As we saw above, however, you can usually recast an optimization problem as a decision problem that is no harder.</p>
<p class="level4"><strong>Encodings</strong></p>
<p class="noindent">In order for a computer program to solve an abstract problem, its problem instances must appear in a way that the program understands. An <strong><em><span class="blue">encoding</span></em></strong> of a set <em>S</em> of abstract objects is a mapping <em>e</em> from <em>S</em> to the set of binary strings.<sup><a epub:type="footnote" href="#footnote_3" id="footnote_ref_3">3</a></sup> For example, we are all familiar with encoding the natural numbers <span class="font1">ℕ</span> = {0, 1, 2, 3, 4,…} as the strings {0, 1, 10, 11, 100,…}. Using this encoding, <em>e</em>(17) = 10001. If you have looked at computer representations of keyboard characters, you probably have seen the ASCII code, where, for example, the encoding of <span class="courierfont">A</span> is 01000001. You can encode a compound object as a binary string by combining the representations of its constituent parts. Polygons, graphs, functions, ordered pairs, programs—all can be encoded as binary strings.</p>
<p>Thus, a computer algorithm that “solves” some abstract decision problem actually takes an encoding of a problem instance as input. The <strong><em><span class="blue">size</span></em></strong> of an instance <em>i</em> is just the length of its string, which we denote by |<em>i</em>|. We call a problem whose instance set is the set of binary strings a <strong><em><span class="blue">concrete problem</span></em></strong>. We say that an algorithm <strong><em><span class="blue">solves</span></em></strong> a concrete problem in <em>O</em>(<em>T</em> (<em>n</em>)) time if, when it is provided a problem instance <em>i</em> of length <em>n</em> = |<em>i</em>|, the algorithm can produce the solution in <em>O</em>(<em>T</em> (<em>n</em>)) <a id="p1050"/>time.<sup><a epub:type="footnote" href="#footnote_4" id="footnote_ref_4">4</a></sup> A concrete problem is <strong><em><span class="blue">polynomial-time solvable</span></em></strong>, therefore, if there exists an algorithm to solve it in <em>O</em>(<em>n<sup>k</sup></em>) time for some constant <em>k</em>.</p>
<p>We can now formally define the <strong><span class="blue"><em>complexity class</em> P</span></strong> as the set of concrete decision problems that are polynomial-time solvable.</p>
<p>Encodings map abstract problems to concrete problems. Given an abstract decision problem <em>Q</em> mapping an instance set <em>I</em> to {0, 1}, an encoding <em>e</em> : <em>I</em> → {0, 1}<sup>*</sup> can induce a related concrete decision problem, which we denote by <em>e</em>(<em>Q</em>).<sup><a epub:type="footnote" href="#footnote_5" id="footnote_ref_5">5</a></sup> If the solution to an abstract-problem instance <em>i</em> ∈ <em>I</em> is <em>Q</em>(<em>i</em>) ∈ {0, 1}, then the solution to the concrete-problem instance <em>e</em>(<em>i</em>) ∈ {0, 1}<sup>*</sup> is also <em>Q</em>(<em>i</em>). As a technicality, some binary strings might represent no meaningful abstract-problem instance. For convenience, assume that any such string maps arbitrarily to 0. Thus, the concrete problem produces the same solutions as the abstract problem on binary-string instances that represent the encodings of abstract-problem instances.</p>
<p>We would like to extend the definition of polynomial-time solvability from concrete problems to abstract problems by using encodings as the bridge, ideally with the definition independent of any particular encoding. That is, the efficiency of solving a problem should not depend on how the problem is encoded. Unfortunately, it depends quite heavily on the encoding. For example, suppose that the sole input to an algorithm is an integer <em>k</em>, and suppose that the running time of the algorithm is Θ(<em>k</em>). If the integer <em>k</em> is provided in <strong><em><span class="blue">unary</span></em></strong>—a string of <em>k</em> 1s—then the running time of the algorithm is <em>O</em>(<em>n</em>) on length-<em>n</em> inputs, which is polynomial time. If the input <em>k</em> is provided using the more natural binary representation, however, then the input length is <em>n</em> = <span class="font1">⌊</span>lg <em>k</em><span class="font1">⌋</span> + 1, so the size of the unary encoding is exponential in the size of the binary encoding. With the binary representation, the running time of the algorithm is Θ(<em>k</em>) = Θ(2<sup><em>n</em></sup>), which is exponential in the size of the input. Thus, depending on the encoding, the algorithm runs in either polynomial or superpolynomial time.</p>
<p>The encoding of an abstract problem matters quite a bit to how we understand polynomial time. We cannot really talk about solving an abstract problem without first specifying an encoding. Nevertheless, in practice, if we rule out “expensive” encodings such as unary ones, the actual encoding of a problem makes little difference to whether the problem can be solved in polynomial time. For example, representing integers in base 3 instead of binary has no effect on whether a problem is solvable in polynomial time, since we can convert an integer represented in base 3 to an integer represented in base 2 in polynomial time.</p>
<a id="p1051"/>
<p>We say that a function <em>f</em> : {0, 1}<sup>*</sup> → {0, 1}<sup>*</sup> is <strong><em><span class="blue">polynomial-time computable</span></em></strong> if there exists a polynomial-time algorithm <em>A</em> that, given any input <em>x</em> ∈ {0, 1}<sup>*</sup>, produces as output <em>f</em> (<em>x</em>). For some set <em>I</em> of problem instances, we say that two encodings <em>e</em><sub>1</sub> and <em>e</em><sub>2</sub> are <strong><em><span class="blue">polynomially related</span></em></strong> if there exist two polynomial-time computable functions <em>f</em><sub>12</sub> and <em>f</em><sub>21</sub> such that for any <em>i</em> ∈ <em>I</em>, we have <em>f</em><sub>12</sub>(<em>e</em><sub>1</sub>(<em>i</em>)) = <em>e</em><sub>2</sub>(<em>i</em>) and <em>f</em><sub>21</sub>(<em>e</em><sub>2</sub>(<em>i</em>)) = <em>e</em><sub>1</sub>(<em>i</em>).<sup><a epub:type="footnote" href="#footnote_6" id="footnote_ref_6">6</a></sup> That is, a polynomial-time algorithm can compute the encoding <em>e</em><sub>2</sub>(<em>i</em>) from the encoding <em>e</em><sub>1</sub>(<em>i</em>), and vice versa. If two encodings <em>e</em><sub>1</sub> and <em>e</em><sub>2</sub> of an abstract problem are polynomially related, whether the problem is polynomial-time solvable or not is independent of which encoding we use, as the following lemma shows.</p>
<p class="lem"><strong><em>Lemma 34.1</em></strong></p>
<p class="noindent">Let <em>Q</em> be an abstract decision problem on an instance set <em>I</em>, and let <em>e</em><sub>1</sub> and <em>e</em><sub>2</sub> be polynomially related encodings on <em>I</em>. Then, <em>e</em><sub>1</sub>(<em>Q</em>) ∈ P if and only if <em>e</em><sub>2</sub>(<em>Q</em>) ∈ P.</p>
<p class="prof"><strong><em>Proof</em></strong>   We need only prove the forward direction, since the backward direction is symmetric. Suppose, therefore, that <em>e</em><sub>1</sub>(<em>Q</em>) can be solved in <em>O</em>(<em>n<sup>k</sup></em>) time for some constant <em>k</em>. Furthermore, suppose that for any problem instance <em>i</em>, the encoding <em>e</em><sub>1</sub>(<em>i</em>) can be computed from the encoding <em>e</em><sub>2</sub>(<em>i</em>) in <em>O</em>(<em>n<sup>c</sup></em>) time for some constant <em>c</em>, where <em>n</em> = |<em>e</em><sub>2</sub>(<em>i</em>)|. To solve problem <em>e</em><sub>2</sub>(<em>Q</em>) on input <em>e</em><sub>2</sub>(<em>i</em>), first compute <em>e</em><sub>1</sub>(<em>i</em>) and then run the algorithm for <em>e</em><sub>1</sub>(<em>Q</em>) on <em>e</em><sub>1</sub>(<em>i</em>). How long does this procedure take? Converting encodings takes <em>O</em>(<em>n<sup>c</sup></em>) time, and therefore |<em>e</em><sub>1</sub>(<em>i</em>)| = <em>O</em>(<em>n<sup>c</sup></em>), since the output of a serial computer cannot be longer than its running time. Solving the problem on <em>e</em><sub>1</sub>(<em>i</em>) takes <em>O</em>(|<em>e</em><sub>1</sub>(<em>i</em>)|<sup><em>k</em></sup>) = <em>O</em>(<em>n<sup>ck</sup></em>) time, which is polynomial since both <em>c</em> and <em>k</em> are constants.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">Thus, whether an abstract problem has its instances encoded in binary or base 3 does not affect its “complexity,” that is, whether it is polynomial-time solvable or not. If instances are encoded in unary, however, its complexity may change. In order to be able to converse in an encoding-independent fashion, we generally assume that problem instances are encoded in any reasonable, concise fashion, unless we specifically say otherwise. To be precise, we assume that the encoding of an integer is polynomially related to its binary representation, and that the encoding of a finite set is polynomially related to its encoding as a list of its elements, enclosed in braces and separated by commas. (ASCII is one such encoding scheme.) With <a id="p1052"/>such a “standard” encoding in hand, we can derive reasonable encodings of other mathematical objects, such as tuples, graphs, and formulas. To denote the standard encoding of an object, we enclose the object in angle brackets. Thus, <span class="font1"><span class="font1">〈</span></span><em>G</em><span class="font1"><span class="font1">〉</span></span> denotes the standard encoding of a graph <em>G</em>.</p>
<p>As long as the encoding implicitly used is polynomially related to this standard encoding, we can talk directly about abstract problems without reference to any particular encoding, knowing that the choice of encoding has no effect on whether the abstract problem is polynomial-time solvable. From now on, we will generally assume that all problem instances are binary strings encoded using the standard encoding, unless we explicitly specify the contrary. We’ll also typically neglect the distinction between abstract and concrete problems. You should watch out for problems that arise in practice, however, in which a standard encoding is not obvious and the encoding does make a difference.</p>
<p class="level4"><strong>A formal-language framework</strong></p>
<p class="noindent">By focusing on decision problems, we can take advantage of the machinery of formal-language theory. Let’s review some definitions from that theory. An <strong><em><span class="blue">alphabet</span></em></strong> Σ is a finite set of symbols. A <strong><em><span class="blue">language</span></em></strong> <em>L</em> over Σ is any set of strings made up of symbols from Σ. For example, if Σ = {0, 1}, the set <em>L</em> = {10, 11, 101, 111, 1011, 1101, 10001,…} is the language of binary representations of prime numbers. We denote the <strong><em><span class="blue">empty string</span></em></strong> by <em>ε</em>, the <strong><em><span class="blue">empty language</span></em></strong> by Ø, and the language of all strings over Σ by Σ*. For example, if Σ = {0, 1}, then Σ* = {<em>ε</em>, 0, 1, 00, 01, 10, 11, 000,…} is the set of all binary strings. Every language <em>L</em> over Σ is a subset of Σ*.</p>
<p>Languages support a variety of operations. Set-theoretic operations, such as <strong><em><span class="blue">union</span></em></strong> and <strong><em><span class="blue">intersection</span></em></strong>, follow directly from the set-theoretic definitions. We define the <strong><em><span class="blue">complement</span></em></strong> of a language <em>L</em> by <span class="overline"><em>L</em></span> = Σ* − <em>L</em>. The <strong><em><span class="blue">concatenation</span></em></strong> <em>L</em><sub>1</sub><em>L</em><sub>2</sub> of two languages <em>L</em><sub>1</sub> and <em>L</em><sub>2</sub> is the language</p>
<p class="eql"><em>L</em> = {<em>x</em><sub>1</sub><em>x</em><sub>2</sub> : <em>x</em><sub>1</sub> ∈ <em>L</em><sub>1</sub> and <em>x</em><sub>2</sub> ∈ <em>L</em><sub>2</sub>}.</p>
<p class="noindent">The <strong><em><span class="blue">closure</span></em></strong> or <strong><em><span class="blue">Kleene star</span></em></strong> of a language <em>L</em> is the language</p>
<p class="eql"><em>L</em>* = {<em>ε</em>} ∪ <em>L</em> ∪ <em>L</em><sup>2</sup> ∪ <em>L</em><sup>3</sup> ∪ …,</p>
<p class="noindent">where <em>L<sup>k</sup></em> is the language obtained by concatenating <em>L</em> to itself <em>k</em> times.</p>
<p>From the point of view of language theory, the set of instances for any decision problem <em>Q</em> is simply the set Σ*, where Σ = {0, 1}. Since <em>Q</em> is entirely characterized by those problem instances that produce a 1 (yes) answer, we can view <em>Q</em> as a language <em>L</em> over Σ = {0, 1}, where</p>
<p class="eql"><em>L</em> = {<em>x</em> ∈ Σ* : <em>Q</em>(<em>x</em>) = 1}.</p>
<a id="p1053"/>
<p class="noindent">For example, the decision problem PATH has the corresponding language</p>
<table class="table2b">
<tr>
<td class="td2">PATH = {<span class="font1"><span class="font1">〈</span></span><em>G, u, v, k</em><span class="font1"><span class="font1">〉</span></span>:</td>
<td class="td2"><em>G</em> = (<em>V</em>, <em>E</em>) is an undirected graph,</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><em>u, v</em> ∈ <em>V</em>,</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><em>k</em> ≥ 0 is an integer, and</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><em>G</em> contains a path from <em>u</em> to <em>v</em> with at most <em>k</em> edges}.</td>
</tr>
</table>
<p class="noindent">(Where convenient, we’ll sometimes use the same name—PATH in this case—to refer to both a decision problem and its corresponding language.)</p>
<p>The formal-language framework allows us to express concisely the relation between decision problems and algorithms that solve them. We say that an algorithm <em>A <strong><span class="blue">accepts</span></strong></em> a string <em>x</em> ∈ {0, 1}* if, given input <em>x</em>, the algorithm’s output <em>A</em>(<em>x</em>) is 1. The language <strong><em><span class="blue">accepted</span></em></strong> by an algorithm <em>A</em> is the set of strings <em>L</em> = {<em>x</em> ∈ {0, 1}* : <em>A</em>(<em>x</em>) = 1}, that is, the set of strings that the algorithm accepts. An algorithm <em>A <strong><span class="blue">rejects</span></strong></em> a string <em>x</em> if <em>A</em>(<em>x</em>) = 0.</p>
<p>Even if language <em>L</em> is accepted by an algorithm <em>A</em>, the algorithm does not necessarily reject a string <em>x</em> ∉ <em>L</em> provided as input to it. For example, the algorithm might loop forever. A language <em>L</em> is <strong><em><span class="blue">decided</span></em></strong> by an algorithm <em>A</em> if every binary string in <em>L</em> is accepted by <em>A</em> and every binary string not in <em>L</em> is rejected by <em>A</em>. A language <em>L</em> is <strong><em><span class="blue">accepted in polynomial time</span></em></strong> by an algorithm <em>A</em> if it is accepted by <em>A</em> and if in addition there exists a constant <em>k</em> such that for any length-<em>n</em> string <em>x</em> ∈ <em>L</em>, algorithm <em>A</em> accepts <em>x</em> in <em>O</em>(<em>n<sup>k</sup></em>) time. A language <em>L</em> is <strong><em><span class="blue">decided in polynomial time</span></em></strong> by an algorithm <em>A</em> if there exists a constant <em>k</em> such that for any length-<em>n</em> string <em>x</em> ∈ {0, 1}*, the algorithm correctly decides whether <em>x</em> ∈ <em>L</em> in <em>O</em>(<em>n<sup>k</sup></em>) time. Thus, to accept a language, an algorithm need only produce an answer when provided a string in <em>L</em>, but to decide a language, it must correctly accept or reject every string in {0, 1}*.</p>
<p>As an example, the language PATH can be accepted in polynomial time. One polynomial-time accepting algorithm verifies that <em>G</em> encodes an undirected graph, verifies that <em>u</em> and <em>v</em> are vertices in <em>G</em>, uses breadth-first search to compute a path from <em>u</em> to <em>v</em> in <em>G</em> with the fewest edges, and then compares the number of edges on the path obtained with <em>k</em>. If <em>G</em> encodes an undirected graph and the path found from <em>u</em> to <em>v</em> has at most <em>k</em> edges, the algorithm outputs 1 and halts. Otherwise, the algorithm runs forever. This algorithm does not decide PATH, however, since it does not explicitly output 0 for instances in which a shortest path has more than <em>k</em> edges. A decision algorithm for PATH must explicitly reject binary strings that do not belong to PATH. For a decision problem such as PATH, such a decision algorithm is straightforward to design: instead of running forever when there is not a path from <em>u</em> to <em>v</em> with at most <em>k</em> edges, it outputs 0 and halts. (It must also output 0 and halt if the input encoding is faulty.) For other problems, such as Turing’s Halting Problem, there exists an accepting algorithm, but no decision algorithm exists.</p>
<a id="p1054"/>
<p>We can informally define a <strong><em><span class="blue">complexity class</span></em></strong> as a set of languages, membership in which is determined by a <strong><em><span class="blue">complexity measure</span></em></strong>, such as running time, of an algorithm that determines whether a given string <em>x</em> belongs to language <em>L</em>. The actual definition of a complexity class is somewhat more technical.<sup><a epub:type="footnote" href="#footnote_7" id="footnote_ref_7">7</a></sup></p>
<p>Using this language-theoretic framework, we can provide an alternative definition of the complexity class P:</p>
<table class="table2b">
<tr>
<td class="td2">P = {<em>L</em> ⊆ {0, 1}*:</td>
<td class="td2">there exists an algorithm <em>A</em> that decides <em>L</em> in polynomial time}.</td>
</tr>
</table>
<p class="noindent">In fact, as the following theorem shows, P is also the class of languages that can be accepted in polynomial time.</p>
<p class="theo"><strong><em>Theorem 34.2</em></strong></p>
<p class="noindent">P = {<em>L</em> : <em>L</em> is accepted by a polynomial-time algorithm}.</p>
<p class="prof"><em><strong>Proof</strong></em> Because the class of languages decided by polynomial-time algorithms is a subset of the class of languages accepted by polynomial-time algorithms, we need only show that if <em>L</em> is accepted by a polynomial-time algorithm, it is decided by a polynomial-time algorithm. Let <em>L</em> be the language accepted by some polynomial-time algorithm <em>A</em>. We use a classic “simulation” argument to construct another polynomial-time algorithm <em>A</em>′ that decides <em>L</em>. Because <em>A</em> accepts <em>L</em> in <em>O</em>(<em>n<sup>k</sup></em>) time for some constant <em>k</em>, there also exists a constant <em>c</em> such that <em>A</em> accepts <em>L</em> in at most <em>cn<sup>k</sup></em> steps. For any input string <em>x</em>, the algorithm <em>A</em>′ simulates <em>cn<sup>k</sup></em> steps of <em>A</em>. After simulating <em>cn<sup>k</sup></em> steps, algorithm <em>A</em>′ inspects the behavior of <em>A</em>. If <em>A</em> has accepted <em>x</em>, then <em>A</em>′ accepts <em>x</em> by outputting a 1. If <em>A</em> has not accepted <em>x</em>, then <em>A</em>′ rejects <em>x</em> by outputting a 0. The overhead of <em>A</em>′ simulating <em>A</em> does not increase the running time by more than a polynomial factor, and thus <em>A</em>′ is a polynomial-time algorithm that decides <em>L</em>.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">The proof of Theorem 34.2 is nonconstructive. For a given language <em>L</em> ∈ P, we may not actually know a bound on the running time for the algorithm <em>A</em> that accepts <em>L</em>. Nevertheless, we know that such a bound exists, and therefore, that an algorithm <em>A</em>′ exists that can check the bound, even though we may not be able to find the algorithm <em>A</em>′ easily.</p>
<a id="p1055"/>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>34.1-1</em></strong></p>
<p class="noindent">Define the optimization problem LONGEST-PATH-LENGTH as the relation that associates each instance of an undirected graph and two vertices with the number of edges in a longest simple path between the two vertices. Define the decision problem LONGEST-PATH = {<span class="font1"><span class="font1">〈</span></span><em>G, u, v, k</em><span class="font1"><span class="font1">〉</span></span> : <em>G</em> = (<em>V</em>, <em>E</em>) is an undirected graph, <em>u, v</em> ∈ <em>V</em>, <em>k</em> ≥ 0 is an integer, and there exists a simple path from <em>u</em> to <em>v</em> in <em>G</em> consisting of at least <em>k</em> edges}. Show that the optimization problem LONGEST-PATH-LENGTH can be solved in polynomial time if and only if LONGEST-PATH ∈ P.</p>
<p class="level3"><strong><em>34.1-2</em></strong></p>
<p class="noindent">Give a formal definition for the problem of finding the longest simple cycle in an undirected graph. Give a related decision problem. Give the language corresponding to the decision problem.</p>
<p class="level3"><strong><em>34.1-3</em></strong></p>
<p class="noindent">Give a formal encoding of directed graphs as binary strings using an adjacency-matrix representation. Do the same using an adjacency-list representation. Argue that the two representations are polynomially related.</p>
<p class="level3"><strong><em>34.1-4</em></strong></p>
<p class="noindent">Is the dynamic-programming algorithm for the 0-1 knapsack problem that is asked for in Exercise 15.2-2 a polynomial-time algorithm? Explain your answer.</p>
<p class="level3"><strong><em>34.1-5</em></strong></p>
<p class="noindent">Show that if an algorithm makes at most a constant number of calls to polynomial-time subroutines and performs an additional amount of work that also takes polynomial time, then it runs in polynomial time. Also show that a polynomial number of calls to polynomial-time subroutines may result in an exponential-time algorithm.</p>
<p class="level3"><strong><em>34.1-6</em></strong></p>
<p class="noindent">Show that the class P, viewed as a set of languages, is closed under union, intersection, concatenation, complement, and Kleene star. That is, if <em>L</em><sub>1</sub>, <em>L</em><sub>2</sub> ∈ P, then <em>L</em><sub>1</sub> ∪ <em>L</em><sub>2</sub> ∈ P, <em>L</em><sub>1</sub> ∩ <em>L</em><sub>2</sub> ∈ P, <em>L</em><sub>1</sub><em>L</em><sub>2</sub> ∈ P, <span class="overline"><em>L</em></span><sub>1</sub> ∈ <em>P</em>, and <img alt="art" src="images/Art_P1430a.jpg"/>.</p>
<a id="p1056"/>
</section>
<p class="line1"/>
<section title="34.2 Polynomial-time verification">
<a id="Sec_34.2"/>
<p class="level1" id="h1-200"><a href="toc.xhtml#Rh1-200"><strong>34.2    Polynomial-time verification</strong></a></p>
<p class="noindent">Now, let’s look at algorithms that verify membership in languages. For example, suppose that for a given instance <span class="font1"><span class="font1">〈</span></span><em>G, u, v, k</em><span class="font1"><span class="font1">〉</span></span> of the decision problem PATH, you are also given a path <em>p</em> from <em>u</em> to <em>v</em>. You can check whether <em>p</em> is a path in <em>G</em> and whether the length of <em>p</em> is at most <em>k</em>, and if so, you can view <em>p</em> as a “certificate” that the instance indeed belongs to PATH. For the decision problem PATH, this certificate doesn’t seem to buy much. After all, PATH belongs to P—in fact, you can solve PATH in linear time—and so verifying membership from a given certificate takes as long as solving the problem from scratch. Instead, let’s examine a problem for which we know of no polynomial-time decision algorithm and yet, given a certificate, verification is easy.</p>
<p class="level4"><strong>Hamiltonian cycles</strong></p>
<p class="noindent">The problem of finding a hamiltonian cycle in an undirected graph has been studied for over a hundred years. Formally, a <strong><em><span class="blue">hamiltonian cycle</span></em></strong> of an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) is a simple cycle that contains each vertex in <em>V</em>. A graph that contains a hamiltonian cycle is said to be <strong><em><span class="blue">hamiltonian</span></em></strong>, and otherwise, it is <strong><em><span class="blue">nonhamiltonian</span></em></strong>. The name honors W. R. Hamilton, who described a mathematical game on the dodecahedron (<a href="chapter034.xhtml#Fig_34-2">Figure 34.2(a)</a>) in which one player sticks five pins in any five consecutive vertices and the other player must complete the path to form a cycle containing all the vertices.<sup><a epub:type="footnote" href="#footnote_8" id="footnote_ref_8">8</a></sup> The dodecahedron is hamiltonian, and <a href="chapter034.xhtml#Fig_34-2">Figure 34.2(a)</a> shows one hamiltonian cycle. Not all graphs are hamiltonian, however. For example, <a href="chapter034.xhtml#Fig_34-2">Figure 34.2(b)</a> shows a bipartite graph with an odd number of vertices. Exercise 34.2-2 asks you to show that all such graphs are nonhamiltonian.</p>
<p>Here is how to define the <strong><em><span class="blue">hamiltonian-cycle problem</span></em></strong>, “Does a graph <em>G</em> have a hamiltonian cycle?” as a formal language:</p>
<p class="eql">HAM-CYCLE = {<span class="font1"><span class="font1">〈</span></span><em>G</em><span class="font1"><span class="font1">〉</span></span> : <em>G</em> is a hamiltonian graph}.</p>
<p class="noindent">How might an algorithm decide the language HAM-CYCLE? Given a problem instance <span class="font1"><span class="font1">〈</span></span><em>G</em><span class="font1"><span class="font1">〉</span></span>, one possible decision algorithm lists all permutations of the vertices of <em>G</em> and then checks each permutation to see whether it is a hamiltonian cycle. <a id="p1057"/>What is the running time of this algorithm? It depends on the encoding of the graph <em>G</em>. Let’s say that <em>G</em> is encoded as its adjacency matrix. If the adjacency matrix contains <em>n</em> entries, so that the length of the encoding of <em>G</em> equals <em>n</em>, then the number <em>m</em> of vertices in the graph is <img alt="art" src="images/Art_P1431.jpg"/>. There are <em>m</em>! possible permutations of the vertices, and therefore the running time is <img alt="art" src="images/Art_P1432.jpg"/>, which is not <em>O</em>(<em>n<sup>k</sup></em>) for any constant <em>k</em>. Thus, this naive algorithm does not run in polynomial time. In fact, the hamiltonian-cycle problem is NP-complete, as we’ll prove in <a href="chapter034.xhtml#Sec_34.5">Section 34.5</a>.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-2"><img alt="art" src="images/Art_P1433.jpg"/></p>
<p class="caption"><strong>Figure 34.2 (a)</strong> A graph representing the vertices, edges, and faces of a dodecahedron, with a hamiltonian cycle shown by edges highlighted in blue. <strong>(b)</strong> A bipartite graph with an odd number of vertices. Any such graph is nonhamiltonian.</p>
</div>
<p class="level4"><strong>Verification algorithms</strong></p>
<p class="noindent">Consider a slightly easier problem. Suppose that a friend tells you that a given graph <em>G</em> is hamiltonian, and then the friend offers to prove it by giving you the vertices in order along the hamiltonian cycle. It would certainly be easy enough to verify the proof: simply verify that the provided cycle is hamiltonian by checking whether it is a permutation of the vertices of <em>V</em> and whether each of the consecutive edges along the cycle actually exists in the graph. You could certainly implement this verification algorithm to run in <em>O</em>(<em>n</em><sup>2</sup>) time, where <em>n</em> is the length of the encoding of <em>G</em>. Thus, a proof that a hamiltonian cycle exists in a graph can be verified in polynomial time.</p>
<a id="p1058"/>
<p>We define a <strong><em><span class="blue">verification algorithm</span></em></strong> as being a two-argument algorithm <em>A</em>, where one argument is an ordinary input string <em>x</em> and the other is a binary string <em>y</em> called a <strong><em><span class="blue">certificate</span></em></strong>. A two-argument algorithm <em>A <strong><span class="blue">verifies</span></strong></em> an input string <em>x</em> if there exists a certificate <em>y</em> such that <em>A</em>(<em>x, y</em>) = 1. The <strong><em><span class="blue">language verified</span></em></strong> by a verification algorithm <em>A</em> is</p>
<p class="eql"><em>L</em> = {<em>x</em> ∈ {0, 1}* : there exists <em>y</em> ∈ {0, 1}* such that <em>A</em>(<em>x, y</em>) = 1}.</p>
<p class="space-break">Think of an algorithm <em>A</em> as verifying a language <em>L</em> if, for any string <em>x</em> ∈ <em>L</em>, there exists a certificate <em>y</em> that <em>A</em> can use to prove that <em>x</em> ∈ <em>L</em>. Moreover, for any string <em>x</em> ∉ <em>L</em>, there must be no certificate proving that <em>x</em> ∈ <em>L</em>. For example, in the hamiltonian-cycle problem, the certificate is the list of vertices in some hamiltonian cycle. If a graph is hamiltonian, the hamiltonian cycle itself offers enough information to verify that the graph is indeed hamiltonian. Conversely, if a graph is not hamiltonian, there can be no list of vertices that fools the verification algorithm into believing that the graph is hamiltonian, since the verification algorithm carefully checks the so-called cycle to be sure.</p>
<p class="level4"><strong>The complexity class NP</strong></p>
<p class="noindent">The <strong><em><span class="blue">complexity class</span></em> <span class="blue">NP</span></strong> is the class of languages that can be verified by a polynomial-time algorithm.<sup><a epub:type="footnote" href="#footnote_9" id="footnote_ref_9">9</a></sup> More precisely, a language <em>L</em> belongs to NP if and only if there exist a two-input polynomial-time algorithm <em>A</em> and a constant <em>c</em> such that</p>
<table class="table2b">
<tr>
<td class="td2"><em>L</em> = {<em>x</em> ∈ {0, 1}*:</td>
<td class="td2">there exists a certificate <em>y</em> with |<em>y</em>| = <em>O</em>(|<em>x</em>|<sup><em>c</em></sup>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">such that <em>A</em>(<em>x</em>, <em>y</em>) = 1}.</td>
</tr>
</table>
<p class="noindent">We say that algorithm <em>A <strong><span class="blue">verifies</span></strong></em> language <em>L <strong><span class="blue">in polynomial time</span></strong></em>.</p>
<p>From our earlier discussion about the hamiltonian-cycle problem, you can see that HAM-CYCLE ∈ NP. (It is always nice to know that an important set is nonempty.) Moreover, if <em>L</em> ∈ P, then <em>L</em> ∈ NP, since if there is a polynomial-time algorithm to decide <em>L</em>, the algorithm can be converted to a two-argument verification algorithm that simply ignores any certificate and accepts exactly those input strings it determines to belong to <em>L</em>. Thus, P ⊆ NP.</p>
<p>That leaves the question of whether P = NP. A definitive answer is unknown, but most researchers believe that P and NP are not the same class. Think of the class P as consisting of problems that can be solved quickly and the class NP as <a id="p1059"/>consisting of problems for which a solution can be verified quickly. You may have learned from experience that it is often more difficult to solve a problem from scratch than to verify a clearly presented solution, especially when working under time constraints. Theoretical computer scientists generally believe that this analogy extends to the classes P and NP, and thus that NP includes languages that do not belong to P.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-3"><img alt="art" src="images/Art_P1434.jpg"/></p>
<p class="caption"><strong>Figure 34.3</strong> Four possibilities for relationships among complexity classes. In each diagram, one region enclosing another indicates a proper-subset relation. <strong>(a)</strong> P = NP = co-NP. Most researchers regard this possibility as the most unlikely. <strong>(b)</strong> If NP is closed under complement, then NP = co-NP, but it need not be the case that P = NP. <strong>(c)</strong> P = NP ∩ co-NP, but NP is not closed under complement. <strong>(d)</strong> NP ≠ co-NP and P ≠ NP ∩ co-NP. Most researchers regard this possibility as the most likely.</p>
</div>
<p>There is more compelling, though not conclusive, evidence that P ≠ NP—the existence of languages that are “NP-complete.” <a href="chapter034.xhtml#Sec_34.3">Section 34.3</a> will study this class.</p>
<p>Many other fundamental questions beyond the P ≠ NP question remain unresolved. <a href="chapter034.xhtml#Fig_34-3">Figure 34.3</a> shows some possible scenarios. Despite much work by many researchers, no one even knows whether the class NP is closed under complement. That is, does <em>L</em> ∈ NP imply <span class="overline"><em>L</em></span> ∈ NP? We define the <strong><em><span class="blue">complexity class</span></em> <span class="blue">co-NP</span></strong> as the set of languages <em>L</em> such that <span class="overline"><em>L</em></span> ∈ NP, so that the question of whether NP is closed under complement is also whether NP = co-NP. Since P is closed under complement (Exercise 34.1-6), it follows from Exercise 34.2-9 (P ⊆ co-NP) that P ⊆ NP ∩ co-NP. Once again, however, no one knows whether P = NP ∩ co-NP or whether there is some language in (NP ∩ co-NP) − P.</p>
<p>Thus our understanding of the precise relationship between P and NP is woefully incomplete. Nevertheless, even though we might not be able to prove that a particular problem is intractable, if we can prove that it is NP-complete, then we have gained valuable information about it.</p>
<a id="p1060"/>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>34.2-1</em></strong></p>
<p class="noindent">Consider the language GRAPH-ISOMORPHISM = {<span class="font1"><span class="font1">〈</span></span><em>G</em><sub>1</sub>, <em>G</em><sub>2</sub><span class="font1"><span class="font1">〉</span></span> : <em>G</em><sub>1</sub> and <em>G</em><sub>2</sub> are isomorphic graphs}. Prove that GRAPH-ISOMORPHISM ∈ NP by describing a polynomial-time algorithm to verify the language.</p>
<p class="level3"><strong><em>34.2-2</em></strong></p>
<p class="noindent">Prove that if <em>G</em> is an undirected bipartite graph with an odd number of vertices, then <em>G</em> is nonhamiltonian.</p>
<p class="level3"><strong><em>34.2-3</em></strong></p>
<p class="noindent">Show that if HAM-CYCLE ∈ P, then the problem of listing the vertices of a hamiltonian cycle, in order, is polynomial-time solvable.</p>
<p class="level3"><strong><em>34.2-4</em></strong></p>
<p class="noindent">Prove that the class NP of languages is closed under union, intersection, concatenation, and Kleene star. Discuss the closure of NP under complement.</p>
<p class="level3"><strong><em>34.2-5</em></strong></p>
<p class="noindent">Show that any language in NP can be decided by an algorithm with a running time of <img alt="art" src="images/Art_P1434a.jpg"/> for some constant <em>k</em>.</p>
<p class="level3"><strong><em>34.2-6</em></strong></p>
<p class="noindent">A <strong><em><span class="blue">hamiltonian path</span></em></strong> in a graph is a simple path that visits every vertex exactly once. Show that the language HAM-PATH = {<span class="font1"><span class="font1">〈</span></span><em>G, u, v</em><span class="font1"><span class="font1">〉</span></span> : there is a hamiltonian path from <em>u</em> to <em>v</em> in graph <em>G</em>} belongs to NP.</p>
<p class="level3"><strong><em>34.2-7</em></strong></p>
<p class="noindent">Show that the hamiltonian-path problem from Exercise 34.2-6 can be solved in polynomial time on directed acyclic graphs. Give an efficient algorithm for the problem.</p>
<p class="level3"><strong><em>34.2-8</em></strong></p>
<p class="noindent">Let <em><span class="symbolfont">ϕ</span></em> be a boolean formula constructed from the boolean input variables <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, … , <em>x<sub>k</sub></em>, negations (¬), ANDs (∧), ORs (∨), and parentheses. The formula <em><span class="symbolfont">ϕ</span></em> is a <strong><em><span class="blue">tautology</span></em></strong> if it evaluates to 1 for every assignment of 1 and 0 to the input variables. Define TAUTOLOGY as the language of boolean formulas that are tautologies. Show that TAUTOLOGY ∈ co-NP.</p>
<p class="level3"><strong><em>34.2-9</em></strong></p>
<p class="noindent">Prove that P ⊆ co-NP.</p>
<a id="p1061"/>
<p class="level3"><strong><em>34.2-10</em></strong></p>
<p class="noindent">Prove that if NP ≠ co-NP, then P ≠ NP.</p>
<p class="level3"><strong><em>34.2-11</em></strong></p>
<p class="noindent">Let <em>G</em> be a connected, undirected graph with at least three vertices, and let <em>G</em><sup>3</sup> be the graph obtained by connecting all pairs of vertices that are connected by a path in <em>G</em> of length at most 3. Prove that <em>G</em><sup>3</sup> is hamiltonian. (<em>Hint:</em> Construct a spanning tree for <em>G</em>, and use an inductive argument.)</p>
</section>
<p class="line1"/>
<section title="34.3 NP-completeness and reducibility">
<a id="Sec_34.3"/>
<p class="level1" id="h1-201"><a href="toc.xhtml#Rh1-201"><strong>34.3    NP-completeness and reducibility</strong></a></p>
<p class="noindent">Perhaps the most compelling reason why theoretical computer scientists believe that P ≠ NP comes from the existence of the class of NP-complete problems. This class has the intriguing property that if <em>any</em> NP-complete problem can be solved in polynomial time, then <em>every</em> problem in NP has a polynomial-time solution, that is, P = NP. Despite decades of study, though, no polynomial-time algorithm has ever been discovered for any NP-complete problem.</p>
<p>The language HAM-CYCLE is one NP-complete problem. If there were an algorithm to decide HAM-CYCLE in polynomial time, then every problem in NP could be solved in polynomial time. The NP-complete languages are, in a sense, the “hardest” languages in NP. In fact, if NP − P turns out to be nonempty, we will be able to say with certainty that HAM-CYCLE ∈ NP − P.</p>
<p>This section starts by showing how to compare the relative “hardness” of languages using a precise notion called “polynomial-time reducibility.” It then formally defines the NP-complete languages, finishing by sketching a proof that one such language, called CIRCUIT-SAT, is NP-complete. <a href="chapter034.xhtml#Sec_34.4">Sections 34.4</a> and <a href="chapter034.xhtml#Sec_34.5">34.5</a> will use the notion of reducibility to show that many other problems are NP-complete.</p>
<p class="level4"><strong>Reducibility</strong></p>
<p class="noindent">One way that sometimes works for solving a problem is to recast it as a different problem. We call that strategy “reducing” one problem to another. Think of a problem <em>Q</em> as being reducible to another problem <em>Q</em>′ if any instance of <em>Q</em> can be recast as an instance of <em>Q</em>′, and the solution to the instance of <em>Q</em>′ provides a solution to the instance of <em>Q</em>. For example, the problem of solving linear equations in an indeterminate <em>x</em> reduces to the problem of solving quadratic equations. Given a linear-equation instance <em>ax</em> + <em>b</em> = 0 (with solution <em>x</em> = −<em>b</em>/<em>a</em>), you can transform it to the quadratic equation <em>ax</em><sup>2</sup> + <em>bx</em> + 0 = 0. This quadratic equation has the solutions <img alt="art" src="images/Art_P1435.jpg"/>, where <em>c</em> = 0, so that <img alt="art" src="images/Art_P1436.jpg"/>. The <a id="p1062"/>solutions are then <em>x</em> = (−<em>b</em> + <em>b</em>)/2<em>a</em> = 0 and <em>x</em> = (−<em>b</em> − <em>b</em>)/2<em>a</em> = −<em>b</em>/<em>a</em>, thereby providing a solution to <em>ax</em> + <em>b</em> = 0. Thus, if a problem <em>Q</em> reduces to another problem <em>Q</em>′, then <em>Q</em> is, in a sense, “no harder to solve” than <em>Q</em>′.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-4"><img alt="art" src="images/Art_P1437.jpg"/></p>
<p class="caption"><strong>Figure 34.4</strong> A function <em>f</em> that reduces language <em>L</em><sub>1</sub> to language <em>L</em><sub>2</sub>. For any input <em>x</em> ∈ {0, 1}*, the question of whether <em>x</em> ∈ <em>L</em><sub>1</sub> has the same answer as the question of whether <em>f</em> (<em>x</em>) ∈ <em>L</em><sub>2</sub>.</p>
</div>
<p>Returning to our formal-language framework for decision problems, we say that a language <em>L</em><sub>1</sub> is <strong><em><span class="blue">polynomial-time reducible</span></em></strong> to a language <em>L</em><sub>2</sub>, written <em>L</em><sub>1</sub> ≤<sub>P</sub> <em>L</em><sub>2</sub>, if there exists a polynomial-time computable function <em>f</em> : {0, 1}* → {0, 1}* such that for all <em>x</em> ∈ {0, 1}*,</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P1438.jpg"/></p>
<p class="noindent">We call the function <em>f</em> the <strong><em><span class="blue">reduction function</span></em></strong>, and a polynomial-time algorithm <em>F</em> that computes <em>f</em> is a <strong><em><span class="blue">reduction algorithm</span></em></strong>.</p>
<p><a href="chapter034.xhtml#Fig_34-4">Figure 34.4</a> illustrates the idea of a reduction from a language <em>L</em><sub>1</sub> to another language <em>L</em><sub>2</sub>. Each language is a subset of {0, 1}*. The reduction function <em>f</em> provides a mapping such that if <em>x</em> ∈ <em>L</em><sub>1</sub>, then <em>f</em> (<em>x</em>) ∈ <em>L</em><sub>2</sub>. Moreover, if <em>x</em> ∉ <em>L</em><sub>1</sub>, then <em>f</em> (<em>x</em>) ∉ <em>L</em><sub>2</sub>. Thus, the reduction function maps any instance <em>x</em> of the decision problem represented by the language <em>L</em><sub>1</sub> to an instance <em>f</em> (<em>x</em>) of the problem represented by <em>L</em><sub>2</sub>. Providing an answer to whether <em>f</em> (<em>x</em>) ∈ <em>L</em><sub>2</sub> directly provides the answer to whether <em>x</em> ∈ <em>L</em><sub>1</sub>. If, in addition, <em>f</em> can be computed in polynomial time, it is a polynomial-time reduction function.</p>
<p>Polynomial-time reductions give us a powerful tool for proving that various languages belong to P.</p>
<p class="lem"><strong><em>Lemma 34.3</em></strong></p>
<p class="noindent">If <em>L</em><sub>1</sub>, <em>L</em><sub>2</sub> ⊆ {0, 1}* are languages such that <em>L</em><sub>1</sub> ≤<sub>P</sub> <em>L</em><sub>2</sub>, then <em>L</em><sub>2</sub> ∈ P implies <em>L</em><sub>1</sub> ∈ P.</p>
<a id="p1063"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-5"><img alt="art" src="images/Art_P1439.jpg"/></p>
<p class="caption"><strong>Figure 34.5</strong> The proof of Lemma 34.3. The algorithm <em>F</em> is a reduction algorithm that computes the reduction function <em>f</em> from <em>L</em><sub>1</sub> to <em>L</em><sub>2</sub> in polynomial time, and <em>A</em><sub>2</sub> is a polynomial-time algorithm that decides <em>L</em><sub>2</sub>. Algorithm <em>A</em><sub>1</sub> decides whether <em>x</em> ∈ <em>L</em><sub>1</sub> by using <em>F</em> to transform any input <em>x</em> into <em>f</em> (<em>x</em>) and then using <em>A</em><sub>2</sub> to decide whether <em>f</em> (<em>x</em>) ∈ <em>L</em><sub>2</sub>.</p>
</div>
<p class="prof"><strong><em>Proof</em></strong>   Let <em>A</em><sub>2</sub> be a polynomial-time algorithm that decides <em>L</em><sub>2</sub>, and let <em>F</em> be a polynomial-time reduction algorithm that computes the reduction function <em>f</em>. We show how to construct a polynomial-time algorithm <em>A</em><sub>1</sub> that decides <em>L</em><sub>1</sub>.</p>
<p><a href="chapter034.xhtml#Fig_34-5">Figure 34.5</a> illustrates how we construct <em>A</em><sub>1</sub>. For a given input <em>x</em> ∈ {0, 1}*, algorithm <em>A</em><sub>1</sub> uses <em>F</em> to transform <em>x</em> into <em>f</em> (<em>x</em>), and then it uses <em>A</em><sub>2</sub> to test whether <em>f</em> (<em>x</em>) ∈ <em>L</em><sub>2</sub>. Algorithm <em>A</em><sub>1</sub> takes the output from algorithm <em>A</em><sub>2</sub> and produces that answer as its own output.</p>
<p>The correctness of <em>A</em><sub>1</sub> follows from condition (34.1). The algorithm runs in polynomial time, since both <em>F</em> and <em>A</em><sub>2</sub> run in polynomial time (see Exercise 34.1-5).</p>
<p class="right"><span class="font1">▪</span></p>
<p class="level4"><strong>NP-completeness</strong></p>
<p class="noindent">Polynomial-time reductions allow us to formally show that one problem is at least as hard as another, to within a polynomial-time factor. That is, if <em>L</em><sub>1</sub> ≤<sub>P</sub> <em>L</em><sub>2</sub>, then <em>L</em><sub>1</sub> is not more than a polynomial factor harder than <em>L</em><sub>2</sub>, which is why the “less than or equal to” notation for reduction is mnemonic. We can now define the set of NP-complete languages, which are the hardest problems in NP.</p>
<p>A language <em>L</em> ⊆ {0, 1}* is <strong><em><span class="blue">NP-complete</span></em></strong> if</p>
<ol class="olnoindent" epub:type="list">
<li><em>L</em> ∈ NP, and</li>
<li class="litop"><em>L</em>′ ≤<sub>P</sub> <em>L</em> for every <em>L</em>′ ∈ NP.</li></ol>
<p class="noindent">If a language <em>L</em> satisfies property 2, but not necessarily property 1, we say that <em>L</em> is <strong><em><span class="blue">NP-hard</span></em></strong>. We also define NPC to be the class of NP-complete languages.</p>
<p>As the following theorem shows, NP-completeness is at the crux of deciding whether P is in fact equal to NP.</p>
<p class="theo"><strong><em>Theorem 34.4</em></strong></p>
<p class="noindent">If any NP-complete problem is polynomial-time solvable, then P = NP. Equivalently, if any problem in NP is not polynomial-time solvable, then no NP-complete problem is polynomial-time solvable.</p>
<a id="p1064"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-6"><img alt="art" src="images/Art_P1440.jpg"/></p>
<p class="caption"><strong>Figure 34.6</strong> How most theoretical computer scientists view the relationships among P, NP, and NPC. Both P and NPC are wholly contained within NP, and P ∩ NPC = Ø.</p>
</div>
<p class="prof"><strong><em>Proof</em></strong>   Suppose that <em>L</em> ∈ P and also that <em>L</em> ∈ NPC. For any <em>L</em>′ ∈ NP, we have <em>L</em>′ ≤<sub>P</sub> <em>L</em> by property 2 of the definition of NP-completeness. Thus, by Lemma 34.3, we also have that <em>L</em>′ ∈ P, which proves the first statement of the theorem.</p>
<p>To prove the second statement, consider the contrapositive of the first statement: if P ≠ NP, then there does not exist an NP-complete problem that is polynomial-time solvable. But P ≠ NP means that there is some problem in NP that is not polynomial-time solvable, and hence the second statement is the contrapositive of the first statement.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">It is for this reason that research into the P ≠ NP question centers around the NP-complete problems. Most theoretical computer scientists believe that P ≠ NP, which leads to the relationships among P, NP, and NPC shown in <a href="chapter034.xhtml#Fig_34-6">Figure 34.6</a>. For all we know, however, someone may yet come up with a polynomial-time algorithm for an NP-complete problem, thus proving that P = NP. Nevertheless, since no polynomial-time algorithm for any NP-complete problem has yet been discovered, a proof that a problem is NP-complete provides excellent evidence that it is intractable.</p>
<p class="level4"><strong>Circuit satisfiability</strong></p>
<p class="noindent">We have defined the notion of an NP-complete problem, but up to this point, we have not actually proved that any problem is NP-complete. Once we prove that at least one problem is NP-complete, polynomial-time reducibility becomes a tool to prove other problems to be NP-complete. Thus, we now focus on demonstrating the existence of an NP-complete problem: the circuit-satisfiability problem.</p>
<p>Unfortunately, the formal proof that the circuit-satisfiability problem is NP-complete requires technical detail beyond the scope of this text. Instead, we’ll informally describe a proof that relies on a basic understanding of boolean combinational circuits.</p>
<a id="p1065"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-7"><img alt="art" src="images/Art_P1441.jpg"/></p>
<p class="caption"><strong>Figure 34.7</strong> Three basic logic gates, with binary inputs and outputs. Under each gate is the truth table that describes the gate’s operation. <strong>(a)</strong> The NOT gate. <strong>(b)</strong> The AND gate. <strong>(c)</strong> The OR gate.</p>
</div>
<p>Boolean combinational circuits are built from boolean combinational elements that are interconnected by wires. A <strong><em><span class="blue">boolean combinational element</span></em></strong> is any circuit element that has a constant number of boolean inputs and outputs and that performs a well-defined function. Boolean values are drawn from the set {0, 1}, where 0 represents <small>FALSE</small> and 1 represents <small>TRUE</small>.</p>
<p>The boolean combinational elements appearing in the circuit-satisfiability problem compute simple boolean functions, and they are known as <strong><em><span class="blue">logic gates</span></em></strong>. <a href="chapter034.xhtml#Fig_34-7">Figure 34.7</a> shows the three basic logic gates used in the circuit-satisfiability problem: the <strong><em><span class="blue">NOT gate</span></em></strong> (or <strong><em><span class="blue">inverter</span></em></strong>), the <strong><em><span class="blue">AND gate</span></em></strong>, and the <strong><em><span class="blue">OR gate</span></em></strong>. The NOT gate takes a single binary <strong><em><span class="blue">input</span></em></strong> <em>x</em>, whose value is either 0 or 1, and produces a binary <strong><em><span class="blue">output</span></em></strong> <em>z</em> whose value is opposite that of the input value. Each of the other two gates takes two binary inputs <em>x</em> and <em>y</em> and produces a single binary output <em>z</em>.</p>
<p>The operation of each gate, or of any boolean combinational element, is defined by a <strong><em><span class="blue">truth table</span></em></strong>, shown under each gate in <a href="chapter034.xhtml#Fig_34-7">Figure 34.7</a>. A truth table gives the outputs of the combinational element for each possible setting of the inputs. For example, the truth table for the OR gate says that when the inputs are <em>x</em> = 0 and <em>y</em> = 1, the output value is <em>z</em> = 1. The symbol ¬ denotes the NOT function, ∧ denotes the AND function, and ∨ denotes the OR function. Thus, for example, 0 ∨ 1 = 1.</p>
<p>AND and OR gates are not limited to just two inputs. An AND gate’s output is 1 if all of its inputs are 1, and its output is 0 otherwise. An OR gate’s output is 1 if any of its inputs are 1, and its output is 0 otherwise.</p>
<p>A <strong><em><span class="blue">boolean combinational circuit</span></em></strong> consists of one or more boolean combinational elements interconnected by <strong><em><span class="blue">wires</span></em></strong>. A wire can connect the output of one element to the input of another, so that the output value of the first element becomes an input value of the second. <a href="chapter034.xhtml#Fig_34-8">Figure 34.8</a> shows two similar boolean combinational circuits, differing in only one gate. Part (a) of the figure also shows the values on <a id="p1066"/>the individual wires, given the input <span class="font1"><span class="font1">〈</span></span><em>x</em><sub>1</sub> = 1, <em>x</em><sub>2</sub> = 1, <em>x</em><sub>3</sub> = 0<span class="font1"><span class="font1">〉</span></span>. Although a single wire may have no more than one combinational-element output connected to it, it can feed several element inputs. The number of element inputs fed by a wire is called the <strong><em><span class="blue">fan-out</span></em></strong> of the wire. If no element output is connected to a wire, the wire is a <strong><em><span class="blue">circuit input</span></em></strong>, accepting input values from an external source. If no element input is connected to a wire, the wire is a <strong><em><span class="blue">circuit output</span></em></strong>, providing the results of the circuit’s computation to the outside world. (An internal wire can also fan out to a circuit output.) For the purpose of defining the circuit-satisfiability problem, we limit the number of circuit outputs to 1, though in actual hardware design, a boolean combinational circuit may have multiple outputs.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-8"><img alt="art" class="width100" src="images/Art_P1442.jpg"/></p>
<p class="caption"><strong>Figure 34.8</strong> Two instances of the circuit-satisfiability problem. <strong>(a)</strong> The assignment <span class="font1"><span class="font1">〈</span></span><em>x</em><sub>1</sub> = 1, <em>x</em><sub>2</sub> = 1, <em>x</em><sub>3</sub> = 0<span class="font1"><span class="font1">〉</span></span> to the inputs of this circuit causes the output of the circuit to be 1. The circuit is therefore satisfiable. <strong>(b)</strong> No assignment to the inputs of this circuit can cause the output of the circuit to be 1. The circuit is therefore unsatisfiable.</p>
</div>
<p>Boolean combinational circuits contain no cycles. In other words, for a given combinational circuit, imagine a directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with one vertex for each combinational element and with <em>k</em> directed edges for each wire whose fan-out is <em>k</em>, where the graph contains a directed edge (<em>u</em>, <em>v</em>) if a wire connects the output of element <em>u</em> to an input of element <em>v</em>. Then <em>G</em> must be acyclic.</p>
<p>A <strong><em><span class="blue">truth assignment</span></em></strong> for a boolean combinational circuit is a set of boolean input values. We say that a 1-output boolean combinational circuit is <strong><em><span class="blue">satisfiable</span></em></strong> if it has a <strong><em><span class="blue">satisfying assignment</span></em></strong>: a truth assignment that causes the output of the circuit to be 1. For example, the circuit in <a href="chapter034.xhtml#Fig_34-8">Figure 34.8(a)</a> has the satisfying assignment <span class="font1"><span class="font1">〈</span></span><em>x</em><sub>1</sub> = 1, <em>x</em><sub>2</sub> = 1, <em>x</em><sub>3</sub> = 0<span class="font1"><span class="font1">〉</span></span>, and so it is satisfiable. As Exercise 34.3-1 asks you to show, no assignment of values to <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, and <em>x</em><sub>3</sub> causes the circuit in <a href="chapter034.xhtml#Fig_34-8">Figure 34.8(b)</a> to produce a 1 output. Since it always produces 0, it is unsatisfiable.</p>
<p>The <strong><em><span class="blue">circuit-satisfiability problem</span></em></strong> is, “Given a boolean combinational circuit composed of AND, OR, and NOT gates, is it satisfiable?” In order to pose this <a id="p1067"/>question formally, however, we must agree on a standard encoding for circuits. The <strong><em><span class="blue">size</span></em></strong> of a boolean combinational circuit is the number of boolean combinational elements plus the number of wires in the circuit. We could devise a graph-like encoding that maps any given circuit <em>C</em> into a binary string <span class="font1"><span class="font1">〈</span></span><em>C</em><span class="font1"><span class="font1">〉</span></span> whose length is polynomial in the size of the circuit itself. As a formal language, we can therefore define</p>
<p class="eql">CIRCUIT-SAT = {<span class="font1"><span class="font1">〈</span></span><em>C</em><span class="font1"><span class="font1">〉</span></span> : <em>C</em> is a satisfiable boolean combinational circuit}.</p>
<p class="space-break">The circuit-satisfiability problem arises in the area of computer-aided hardware optimization. If a subcircuit always produces 0, that subcircuit is unnecessary: the designer can replace it by a simpler subcircuit that omits all logic gates and provides the constant 0 value as its output. You can see the value in having a polynomial-time algorithm for this problem.</p>
<p>Given a circuit <em>C</em>, you can determine whether it is satisfiable by simply checking all possible assignments to the inputs. Unfortunately, if the circuit has <em>k</em> inputs, then you would have to check up to 2<sup><em>k</em></sup> possible assignments. When the size of <em>C</em> is polynomial in <em>k</em>, checking all possible assignments to the inputs takes Ω(2<sup><em>k</em></sup>) time, which is superpolynomial in the size of the circuit.<sup><a epub:type="footnote" href="#footnote_10" id="footnote_ref_10">10</a></sup> In fact, as we have claimed, there is strong evidence that no polynomial-time algorithm exists that solves the circuit-satisfiability problem because circuit satisfiability is NP-complete. We break the proof of this fact into two parts, based on the two parts of the definition of NP-completeness.</p>
<p class="lem"><strong><em>Lemma 34.5</em></strong></p>
<p class="noindent">The circuit-satisfiability problem belongs to the class NP.</p>
<p class="prof"><strong><em>Proof</em></strong>   We provide a two-input, polynomial-time algorithm <em>A</em> that can verify CIRCUIT-SAT. One of the inputs to <em>A</em> is (a standard encoding of) a boolean combinational circuit <em>C</em>. The other input is a certificate corresponding to an assignment of a boolean value to each of the wires in <em>C</em>. (See Exercise 34.3-4 for a smaller certificate.)</p>
<p>The algorithm <em>A</em> works as follows. For each logic gate in the circuit, it checks that the value provided by the certificate on the output wire is correctly computed as a function of the values on the input wires. Then, if the output of the entire circuit is 1, algorithm <em>A</em> outputs 1, since the values assigned to the inputs of <em>C</em> provide a satisfying assignment. Otherwise, <em>A</em> outputs 0.</p>
<a id="p1068"/>
<p>Whenever a satisfiable circuit <em>C</em> is input to algorithm <em>A</em>, there exists a certificate whose length is polynomial in the size of <em>C</em> and that causes <em>A</em> to output a 1. Whenever an unsatisfiable circuit is input, no certificate can fool <em>A</em> into believing that the circuit is satisfiable. Algorithm <em>A</em> runs in polynomial time, and with a good implementation, linear time suffices. Thus, CIRCUIT-SAT is verifiable in polynomial time, and CIRCUIT-SAT ∈ NP.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">The second part of proving that CIRCUIT-SAT is NP-complete is to show that the language is NP-hard: that <em>every</em> language in NP is polynomial-time reducible to CIRCUIT-SAT. The actual proof of this fact is full of technical intricacies, and so instead we’ll sketch the proof based on some understanding of the workings of computer hardware.</p>
<p>A computer program is stored in the computer’s memory as a sequence of instructions. A typical instruction encodes an operation to be performed, addresses of operands in memory, and an address where the result is to be stored. A special memory location, called the <strong><em><span class="blue">program counter</span></em></strong>, keeps track of which instruction is to be executed next. The program counter automatically increments when each instruction is fetched, thereby causing the computer to execute instructions sequentially. Certain instructions can cause a value to be written to the program counter, however, which alters the normal sequential execution and allows the computer to loop and perform conditional branches.</p>
<p>At any point while a program executes, the computer’s memory holds the entire state of the computation. (Consider the memory to include the program itself, the program counter, working storage, and any of the various bits of state that a computer maintains for bookkeeping.) We call any particular state of computer memory a <strong><em><span class="blue">configuration</span></em></strong>. When an instruction executes, it transforms the configuration. Think of an instruction as mapping one configuration to another. The computer hardware that accomplishes this mapping can be implemented as a boolean combinational circuit, which we denote by <em>M</em> in the proof of the following lemma.</p>
<p class="lem"><strong><em>Lemma 34.6</em></strong></p>
<p class="noindent">The circuit-satisfiability problem is NP-hard.</p>
<p class="prof"><strong><em>Proof</em></strong>   Let <em>L</em> be any language in NP. We’ll describe a polynomial-time algorithm <em>F</em> computing a reduction function <em>f</em> that maps every binary string <em>x</em> to a circuit <em>C</em> = <em>f</em> (<em>x</em>) such that <em>x</em> ∈ <em>L</em> if and only if <em>C</em> ∈ CIRCUIT-SAT.</p>
<p>Since <em>L</em> ∈ NP, there must exist an algorithm <em>A</em> that verifies <em>L</em> in polynomial time. The algorithm <em>F</em> that we construct uses the two-input algorithm <em>A</em> to compute the reduction function <em>f</em>.</p>
<p>Let <em>T</em> (<em>n</em>) denote the worst-case running time of algorithm <em>A</em> on length-<em>n</em> input strings, and let <em>k</em> ≥ 1 be a constant such that <em>T</em> (<em>n</em>) = <em>O</em>(<em>n<sup>k</sup></em>) and the length of the <a id="p1069"/>certificate is <em>O</em>(<em>n<sup>k</sup></em>). (The running time of <em>A</em> is actually a polynomial in the total input size, which includes both an input string and a certificate, but since the length of the certificate is polynomial in the length <em>n</em> of the input string, the running time is polynomial in <em>n</em>.)</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-9"><img alt="art" src="images/Art_P1443.jpg"/></p>
<p class="caption"><strong>Figure 34.9</strong> The sequence of configurations produced by an algorithm <em>A</em> running on an input <em>x</em> and certificate <em>y</em>. Each configuration represents the state of the computer for one step of the computation and, besides <em>A</em>, <em>x</em>, and <em>y</em>, includes the program counter (PC), auxiliary machine state, and working storage. Except for the certificate <em>y</em>, the initial configuration <em>c</em><sub>0</sub> is constant. A boolean combinational circuit <em>M</em> maps each configuration to the next configuration. The output is a distinguished bit in the working storage.</p>
</div>
<p>The basic idea of the proof is to represent the computation of <em>A</em> as a sequence of configurations. As <a href="chapter034.xhtml#Fig_34-9">Figure 34.9</a> illustrates, consider each configuration as comprising <a id="p1070"/>a few parts: the program for <em>A</em>, the program counter and auxiliary machine state, the input <em>x</em>, the certificate <em>y</em>, and working storage. The combinational circuit <em>M</em>, which implements the computer hardware, maps each configuration <em>c<sub>i</sub></em> to the next configuration <em>c</em><sub><em>i</em>+1</sub>, starting from the initial configuration <em>c</em><sub>0</sub>. Algorithm <em>A</em> writes its output—0 or 1—to some designated location by the time it finishes executing. After <em>A</em> halts, the output value never changes. Thus, if the algorithm runs for at most <em>T</em> (<em>n</em>) steps, the output appears as one of the bits in <em>c<sub>T</sub></em>(<em>n</em>).</p>
<p>The reduction algorithm <em>F</em> constructs a single combinational circuit that computes all configurations produced by a given initial configuration. The idea is to paste together <em>T</em> (<em>n</em>) copies of the circuit <em>M</em>. The output of the <em>i</em>th circuit, which produces configuration <em>c<sub>i</sub></em>, feeds directly into the input of the (<em>i</em> +1)st circuit. Thus, the configurations, rather than being stored in the computer’s memory, simply reside as values on the wires connecting copies of <em>M</em>.</p>
<p>Recall what the polynomial-time reduction algorithm <em>F</em> must do. Given an input <em>x</em>, it must compute a circuit <em>C</em> = <em>f</em> (<em>x</em>) that is satisfiable if and only if there exists a certificate <em>y</em> such that <em>A</em>(<em>x</em>, <em>y</em>) = 1. When <em>F</em> obtains an input <em>x</em>, it first computes <em>n</em> = |<em>x</em>| and constructs a combinational circuit <em>C</em>′ consisting of <em>T</em> (<em>n</em>) copies of <em>M</em>. The input to <em>C</em>′ is an initial configuration corresponding to a computation on <em>A</em>(<em>x</em>, <em>y</em>), and the output is the configuration <em>c<sub>T</sub></em>(<em>n</em>).</p>
<p>Algorithm <em>F</em> modifies circuit <em>C</em>′ slightly to construct the circuit <em>C</em> = <em>f</em> (<em>x</em>). First, it wires the inputs to <em>C</em>′ corresponding to the program for <em>A</em>, the initial program counter, the input <em>x</em>, and the initial state of memory directly to these known values. Thus, the only remaining inputs to the circuit correspond to the certificate <em>y</em>. Second, it ignores all outputs from <em>C</em>′, except for the one bit of <em>c<sub>T</sub></em>(<em>n</em>) corresponding to the output of <em>A</em>. This circuit <em>C</em>, so constructed, computes <em>C</em>(<em>y</em>) = <em>A</em>(<em>x</em>, <em>y</em>) for any input <em>y</em> of length <em>O</em>(<em>n<sup>k</sup></em>). The reduction algorithm <em>F</em>, when provided an input string <em>x</em>, computes such a circuit <em>C</em> and outputs it.</p>
<p>We need to prove two properties. First, we must show that <em>F</em> correctly computes a reduction function <em>f</em>. That is, we must show that <em>C</em> is satisfiable if and only if there exists a certificate <em>y</em> such that <em>A</em>(<em>x</em>, <em>y</em>) = 1. Second, we must show that <em>F</em> runs in polynomial time.</p>
<p>To show that <em>F</em> correctly computes a reduction function, suppose that there exists a certificate <em>y</em> of length <em>O</em>(<em>n<sup>k</sup></em>) such that <em>A</em>(<em>x</em>, <em>y</em>) = 1. Then, upon applying the bits of <em>y</em> to the inputs of <em>C</em>, the output of <em>C</em> is <em>C</em>(<em>y</em>) = <em>A</em>(<em>x</em>, <em>y</em>) = 1. Thus, if a certificate exists, then <em>C</em> is satisfiable. For the other direction, suppose that <em>C</em> is satisfiable. Hence, there exists an input <em>y</em> to <em>C</em> such that <em>C</em>(<em>y</em>) = 1, from which we conclude that <em>A</em>(<em>x</em>, <em>y</em>) = 1. Thus, <em>F</em> correctly computes a reduction function.</p>
<p>To complete the proof sketch, we need to show that <em>F</em> runs in time polynomial in <em>n</em> = |<em>x</em>|. First, the number of bits required to represent a configuration is polynomial in <em>n</em>. Why? The program for <em>A</em> itself has constant size, independent of the length of its input <em>x</em>. The length of the input <em>x</em> is <em>n</em>, and the length of the certificate <a id="p1071"/><em>y</em> is <em>O</em>(<em>n<sup>k</sup></em>). Since the algorithm runs for at most <em>O</em>(<em>n<sup>k</sup></em>) steps, the amount of working storage required by <em>A</em> is polynomial in <em>n</em> as well. (We implicitly assume that this memory is contiguous. Exercise 34.3-5 asks you to extend the argument to the situation in which the locations accessed by <em>A</em> are scattered across a much larger region of memory and the particular pattern of scattering can differ for each input <em>x</em>.)</p>
<p>The combinational circuit <em>M</em> implementing the computer hardware has size polynomial in the length of a configuration, which is <em>O</em>(<em>n<sup>k</sup></em>), and hence, the size of <em>M</em> is polynomial in <em>n</em>. (Most of this circuitry implements the logic of the memory system.) The circuit <em>C</em> consists of <em>O</em>(<em>n<sup>k</sup></em>) copies of <em>M</em>, and hence it has size polynomial in <em>n</em>. The reduction algorithm <em>F</em> can construct <em>C</em> from <em>x</em> in polynomial time, since each step of the construction takes polynomial time.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">The language CIRCUIT-SAT is therefore at least as hard as any language in NP, and since it belongs to NP, it is NP-complete.</p>
<p class="theo"><strong><em>Theorem 34.7</em></strong></p>
<p class="noindent">The circuit-satisfiability problem is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   Immediate from Lemmas 34.5 and 34.6 and from the definition of NP-completeness.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>34.3-1</em></strong></p>
<p class="noindent">Verify that the circuit in <a href="chapter034.xhtml#Fig_34-8">Figure 34.8(b)</a> is unsatisfiable.</p>
<p class="level3"><strong><em>34.3-2</em></strong></p>
<p class="noindent">Show that the ≤<sub>P</sub> relation is a transitive relation on languages. That is, show that if <em>L</em><sub>1</sub> ≤<sub>P</sub> <em>L</em><sub>2</sub> and <em>L</em><sub>2</sub> ≤<sub>P</sub> <em>L</em><sub>3</sub>, then <em>L</em><sub>1</sub> ≤<sub>P</sub> <em>L</em><sub>3</sub>.</p>
<p class="level3"><strong><em>34.3-3</em></strong></p>
<p class="noindent">Prove that <em>L</em> ≤<sub>P</sub> <span class="overline"><em>L</em></span> if and only if <span class="overline"><em>L</em></span> ≤<sub>P</sub> <em>L</em>.</p>
<p class="level3"><strong><em>34.3-4</em></strong></p>
<p class="noindent">Show that an alternative proof of Lemma 34.5 can use a satisfying assignment as a certificate. Which certificate makes for an easier proof?</p>
<p class="level3"><strong><em>34.3-5</em></strong></p>
<p class="noindent">The proof of Lemma 34.6 assumes that the working storage for algorithm <em>A</em> occupies a contiguous region of polynomial size. Where does the proof exploit this assumption? Argue that this assumption does not involve any loss of generality.</p>
<a id="p1072"/>
<p class="level3"><strong><em>34.3-6</em></strong></p>
<p class="noindent">A language <em>L</em> is <strong><em><span class="blue">complete</span></em></strong> for a language class <em>C</em> with respect to polynomial-time reductions if <em>L</em> ∈ <em>C</em> and <em>L</em>′ ≤<sub>P</sub> <em>L</em> for all <em>L</em>′ ∈ <em>C</em>. Show that Ø and {0, 1}* are the only languages in P that are not complete for P with respect to polynomial-time reductions.</p>
<p class="level3"><strong><em>34.3-7</em></strong></p>
<p class="noindent">Show that, with respect to polynomial-time reductions (see Exercise 34.3-6), <em>L</em> is complete for NP if and only if <span class="overline"><em>L</em></span> is complete for co-NP.</p>
<p class="level3"><strong><em>34.3-8</em></strong></p>
<p class="noindent">The reduction algorithm <em>F</em> in the proof of Lemma 34.6 constructs the circuit <em>C</em> = <em>f</em> (<em>x</em>) based on knowledge of <em>x</em>, <em>A</em>, and <em>k</em>. Professor Sartre observes that the string <em>x</em> is input to <em>F</em>, but only the existence of <em>A</em>, <em>k</em>, and the constant factor implicit in the <em>O</em>(<em>n<sup>k</sup></em>) running time is known to <em>F</em> (since the language <em>L</em> belongs to NP), not their actual values. Thus, the professor concludes that <em>F</em> cannot possibly construct the circuit <em>C</em> and that the language CIRCUIT-SAT is not necessarily NP-hard. Explain the flaw in the professor’s reasoning.</p>
</section>
<p class="line1"/>
<section title="34.4 NP-completeness proofs">
<a id="Sec_34.4"/>
<p class="level1" id="h1-202"><a href="toc.xhtml#Rh1-202"><strong>34.4    NP-completeness proofs</strong></a></p>
<p class="noindent">The proof that the circuit-satisfiability problem is NP-complete showed directly that <em>L</em> ≤<sub>P</sub> CIRCUIT-SAT for every language <em>L</em> ∈ NP. This section shows how to prove that languages are NP-complete without directly reducing <em>every</em> language in NP to the given language. We’ll explore examples of this methodology by proving that various formula-satisfiability problems are NP-complete. <a href="chapter034.xhtml#Sec_34.5">Section 34.5</a> provides many more examples.</p>
<p>The following lemma provides a foundation for showing that a given language is NP-complete.</p>
<p class="lem"><strong><em>Lemma 34.8</em></strong></p>
<p class="noindent">If <em>L</em> is a language such that <em>L</em>′ ≤<sub>P</sub> <em>L</em> for some <em>L</em>′ ∈ NPC, then <em>L</em> is NP-hard. If, in addition, we have <em>L</em> ∈ NP, then <em>L</em> ∈ NPC.</p>
<p class="prof"><strong><em>Proof</em></strong>   Since <em>L</em>′ is NP-complete, for all <em>L</em>″ ∈ NP, we have <em>L</em>″ ≤<sub>P</sub> <em>L</em>′. By supposition, we have <em>L</em>′ ≤<sub>P</sub> <em>L</em>, and thus by transitivity (Exercise 34.3-2), we have <em>L</em>″ ≤<sub>P</sub> <em>L</em>, which shows that <em>L</em> is NP-hard. If <em>L</em> ∈ NP, we also have <em>L</em> ∈ NPC.</p>
<p class="right"><span class="font1">▪</span></p>
<a id="p1073"/>
<p class="space-break">In other words, by reducing a known NP-complete language <em>L</em>′ to <em>L</em>, we implicitly reduce every language in NP to <em>L</em>. Thus, Lemma 34.8 provides a method for proving that a language <em>L</em> is NP-complete:</p>
<ol class="olnoindent" epub:type="list">
<li>Prove <em>L</em> ∈ NP.</li>
<li class="litop">Prove that <em>L</em> is NP-hard:
<p class="nl">a. Select a known NP-complete language <em>L</em>′.</p>
<p class="nl">b. Describe an algorithm that computes a function <em>f</em> mapping every instance <em>x</em> ∈ {0, 1}* of <em>L</em>′ to an instance <em>f</em> (<em>x</em>) of <em>L</em>.</p>
<p class="nl">c. Prove that the function <em>f</em> satisfies <em>x</em> ∈ <em>L</em>′ if and only if <em>f</em> (<em>x</em>) ∈ <em>L</em> for all <em>x</em> ∈ {0, 1}*.</p>
<p class="nl">d. Prove that the algorithm computing <em>f</em> runs in polynomial time.</p></li>
</ol>
<p class="noindent">This methodology of reducing from a single known NP-complete language is far simpler than the more complicated process of showing directly how to reduce from every language in NP. Proving CIRCUIT-SAT ∈ NPC furnishes a starting point. Knowing that the circuit-satisfiability problem is NP-complete makes it much easier to prove that other problems are NP-complete. Moreover, as the catalog of known NP-complete problems grows, so will the choices for languages from which to reduce.</p>
<p class="level4"><strong>Formula satisfiability</strong></p>
<p class="noindent">To illustrate the reduction methodology, let’s see an NP-completeness proof for the problem of determining whether a boolean <em>formula</em>, not a <em>circuit</em>, is satisfiable. This problem has the historical honor of being the first problem ever shown to be NP-complete.</p>
<p>We formulate the <strong><em><span class="blue">(formula) satisfiability</span></em></strong> problem in terms of the language SAT as follows. An instance of SAT is a boolean formula <em><span class="symbolfont">ϕ</span></em> composed of</p>
<ol class="olnoindent" epub:type="list">
<li><em>n</em> boolean variables: <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, … , <em>x<sub>n</sub></em>;</li>
<li class="litop"><em>m</em> boolean connectives: any boolean function with one or two inputs and one output, such as ∧ (AND), ∨ (OR), ¬ (NOT), → (implication), ↔ (if and only if); and</li>
<li class="litop">parentheses. (Without loss of generality, assume that there are no redundant parentheses, i.e., a formula contains at most one pair of parentheses per boolean connective.)</li></ol>
<p class="noindent">We can encode a boolean formula <em><span class="symbolfont">ϕ</span></em> in a length that is polynomial in <em>n</em> + <em>m</em>. As in boolean combinational circuits, a <strong><em><span class="blue">truth assignment</span></em></strong> for a boolean formula <em><span class="symbolfont">ϕ</span></em> <a id="p1074"/>is a set of values for the variables of <em><span class="symbolfont">ϕ</span></em>, and a <strong><em><span class="blue">satisfying assignment</span></em></strong> is a truth assignment that causes it to evaluate to 1. A formula with a satisfying assignment is a <strong><em><span class="blue">satisfiable</span></em></strong> formula. The satisfiability problem asks whether a given boolean formula is satisfiable, which we can express in formal-language terms as</p>
<p class="eql">SAT = {<span class="font1"><span class="font1">〈</span></span><em><span class="symbolfont">ϕ</span></em><span class="font1"><span class="font1">〉</span></span> : <em><span class="symbolfont">ϕ</span></em> is a satisfiable boolean formula}.</p>
<p class="noindent">As an example, the formula</p>
<p class="eql"><em><span class="symbolfont">ϕ</span></em> = ((<em>x</em><sub>1</sub> → <em>x</em><sub>2</sub>) ∨ ¬((¬<em>x</em><sub>1</sub> ↔ <em>x</em><sub>3</sub>) ∨ <em>x</em><sub>4</sub>)) ∧ ¬<em>x</em><sub>2</sub></p>
<p class="noindent">has the satisfying assignment <span class="font1"><span class="font1">〈</span></span><em>x</em><sub>1</sub> = 0, <em>x</em><sub>2</sub> = 0, <em>x</em><sub>3</sub> = 1, <em>x</em><sub>4</sub> = 1<span class="font1"><span class="font1">〉</span></span>, since</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P1444.jpg"/></p>
<p class="noindent">and thus this formula <em><span class="symbolfont">ϕ</span></em> belongs to SAT.</p>
<p>The naive algorithm to determine whether an arbitrary boolean formula is satisfiable does not run in polynomial time. A formula with <em>n</em> variables has 2<sup><em>n</em></sup> possible assignments. If the length of <span class="font1"><span class="font1">〈</span></span><em><span class="symbolfont">ϕ</span></em><span class="font1"><span class="font1">〉</span></span> is polynomial in <em>n</em>, then checking every assignment requires Ω(2<sup><em>n</em></sup>) time, which is superpolynomial in the length of <span class="font1"><span class="font1">〈</span></span><em><span class="symbolfont">ϕ</span></em><span class="font1"><span class="font1">〉</span></span>. As the following theorem shows, a polynomial-time algorithm is unlikely to exist.</p>
<p class="theo"><strong><em>Theorem 34.9</em></strong></p>
<p class="noindent">Satisfiability of boolean formulas is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   We start by arguing that SAT ∈ NP. Then we prove that SAT is NP-hard by showing that CIRCUIT-SAT ≤<sub>P</sub> SAT, which by Lemma 34.8 will prove the theorem.</p>
<p>To show that SAT belongs to NP, we show that a certificate consisting of a satisfying assignment for an input formula <em><span class="symbolfont">ϕ</span></em> can be verified in polynomial time. The verifying algorithm simply replaces each variable in the formula with its corresponding value and then evaluates the expression, much as we did in equation (34.2) above. This task can be done in polynomial time. If the expression evaluates to 1, then the algorithm has verified that the formula is satisfiable. Thus, SAT belongs to NP.</p>
<p>To prove that SAT is NP-hard, we show that CIRCUIT-SAT ≤<sub>P</sub> SAT. In other words, we need to show how to reduce any instance of circuit satisfiability to an instance of formula satisfiability in polynomial time. We can use induction to express any boolean combinational circuit as a boolean formula. We simply look at the gate that produces the circuit output and inductively express each of the <a id="p1075"/>gate’s inputs as formulas. We then obtain the formula for the circuit by writing an expression that applies the gate’s function to its inputs’ formulas.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-10"><img alt="art" src="images/Art_P1445.jpg"/></p>
<p class="caption"><strong>Figure 34.10</strong> Reducing circuit satisfiability to formula satisfiability. The formula produced by the reduction algorithm has a variable for each wire in the circuit and a clause for each logic gate.</p>
</div>
<p>Unfortunately, this straightforward method does not amount to a polynomial-time reduction. As Exercise 34.4-1 asks you to show, shared subformulas—which arise from gates whose output wires have fan-out of 2 or more—can cause the size of the generated formula to grow exponentially. Thus, the reduction algorithm must be somewhat more clever.</p>
<p><a href="chapter034.xhtml#Fig_34-10">Figure 34.10</a> illustrates how to overcome this problem, using as an example the circuit from <a href="chapter034.xhtml#Fig_34-8">Figure 34.8(a)</a>. For each wire <em>x<sub>i</sub></em> in the circuit <em>C</em>, the formula <em><span class="symbolfont">ϕ</span></em> has a variable <em>x<sub>i</sub></em>. To express how each gate operates, construct a small formula involving the variables of its incident wires. The formula has the form of an “if and only if” (↔), with the variable for the gate’s output on the left and on the right a logical expression encapsulating the gate’s function on its inputs. For example, the operation of the output AND gate (the rightmost gate in the figure) is <em>x</em><sub>10</sub> ↔ (<em>x</em><sub>7</sub> ∧ <em>x</em><sub>8</sub> ∧ <em>x</em><sub>9</sub>). We call each of these small formulas a <strong><em><span class="blue">clause</span></em></strong>.</p>
<p>The formula <em><span class="symbolfont">ϕ</span></em> produced by the reduction algorithm is the AND of the circuit-output variable with the conjunction of clauses describing the operation of each gate. For the circuit in the figure, the formula is</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="symbolfont">ϕ</span> = <em>x</em><sub>10</sub></em></td>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>4</sub> ↔ ¬<em>x</em><sub>3</sub>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>5</sub> ↔ (<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>6</sub> ↔ ¬<em>x</em><sub>4</sub>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>7</sub> ↔ (<em>x</em><sub>1</sub> ∧ <em>x</em><sub>2</sub> ∧ <em>x</em><sub>4</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>8</sub> ↔ (<em>x</em><sub>5</sub> ∨ <em>x</em><sub>6</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>9</sub> ↔ (<em>x</em><sub>6</sub> ∨ <em>x</em><sub>7</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>x</em><sub>10</sub> ↔ (<em>x</em><sub>7</sub> ∧ <em>x</em><sub>8</sub> ∧ <em>x</em><sub>9</sub>)).</td>
</tr>
</table>
<a id="p1076"/>
<p class="noindent">Given a circuit <em>C</em>, it is straightforward to produce such a formula <em><span class="symbolfont">ϕ</span></em> in polynomial time.</p>
<p>Why is the circuit <em>C</em> satisfiable exactly when the formula <em><span class="symbolfont">ϕ</span></em> is satisfiable? If <em>C</em> has a satisfying assignment, then each wire of the circuit has a well-defined value, and the output of the circuit is 1. Therefore, when wire values are assigned to variables in <em><span class="symbolfont">ϕ</span></em>, each clause of <em><span class="symbolfont">ϕ</span></em> evaluates to 1, and thus the conjunction of all evaluates to 1. Conversely, if some assignment causes <em><span class="symbolfont">ϕ</span></em> to evaluate to 1, the circuit <em>C</em> is satisfiable by an analogous argument. Thus, we have shown that CIRCUIT-SAT ≤<sub>P</sub> SAT, which completes the proof.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="level4"><strong>3-CNF satisfiability</strong></p>
<p class="noindent">Reducing from formula satisfiability gives us an avenue to prove many problems NP-complete. The reduction algorithm must handle any input formula, though, and this requirement can lead to a huge number of cases to consider. Instead, it is usually simpler to reduce from a restricted language of boolean formulas. Of course, the restricted language must not be polynomial-time solvable. One convenient language is 3-CNF satisfiability, or 3-CNF-SAT.</p>
<p>In order to define 3-CNF satisfiability, we first need to define a few terms. A <strong><em><span class="blue">literal</span></em></strong> in a boolean formula is an occurrence of a variable (such as <em>x</em><sub>1</sub>) or its negation (¬<em>x</em><sub>1</sub>). A <strong><em><span class="blue">clause</span></em></strong> is the OR of one or more literals, such as <em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>2</sub> ∨ ¬<em>x</em><sub>3</sub>. A boolean formula is in <strong><em><span class="blue">conjunctive normal form</span></em></strong>, or <strong><em><span class="blue">CNF</span></em></strong>, if it is expressed as an AND of clauses, and it’s in <strong><em><span class="blue">3-conjunctive normal form</span></em></strong>, or <strong><em><span class="blue">3-CNF</span></em></strong>, if each clause contains exactly three distinct literals.</p>
<p>For example, the boolean formula</p>
<p class="eql">(<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>2</sub>) ∧ (<em>x</em><sub>3</sub> ∨ <em>x</em><sub>2</sub> ∨ <em>x</em><sub>4</sub>) ∧ (¬<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>3</sub> ∨ ¬<em>x</em><sub>4</sub>)</p>
<p class="noindent">is in 3-CNF. The first of its three clauses is (<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>2</sub>), which contains the three literals <em>x</em><sub>1</sub>, ¬<em>x</em><sub>1</sub>, and ¬<em>x</em><sub>2</sub>.</p>
<p>The language 3-CNF-SAT consists of encodings of boolean formulas in 3-CNF that are satisfiable. The following theorem shows that a polynomial-time algorithm that can determine the satisfiability of boolean formulas is unlikely to exist, even when they are expressed in this simple normal form.</p>
<p class="theo"><strong><em>Theorem 34.10</em></strong></p>
<p class="noindent">Satisfiability of boolean formulas in 3-conjunctive normal form is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   The argument from the proof of Theorem 34.9 to show that SAT ∈ NP applies equally well here to show that 3-CNF-SAT ∈ NP. By Lemma 34.8, therefore, we need only show that SAT ≤<sub>P</sub> 3-CNF-SAT.</p>
<a id="p1077"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-11"><img alt="art" src="images/Art_P1446.jpg"/></p>
<p class="caption"><strong>Figure 34.11</strong> The tree corresponding to the formula <em><span class="symbolfont">ϕ</span></em> = ((<em>x</em><sub>1</sub> →<em>x</em><sub>2</sub>)∨¬((¬<em>x</em><sub>1</sub> ↔ <em>x</em><sub>3</sub>)∨<em>x</em><sub>4</sub>))∧¬<em>x</em><sub>2</sub>.</p>
</div>
<p>We break the reduction algorithm into three basic steps. Each step progressively transforms the input formula <em><span class="symbolfont">ϕ</span></em> closer to the desired 3-conjunctive normal form.</p>
<p>The first step is similar to the one used to prove CIRCUIT-SAT ≤<sub>P</sub> SAT in Theorem 34.9. First, construct a binary “parse” tree for the input formula <em><span class="symbolfont">ϕ</span></em>, with literals as leaves and connectives as internal nodes. <a href="chapter034.xhtml#Fig_34-11">Figure 34.11</a> shows such a parse tree for the formula</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P1447.jpg"/></p>
<p class="noindent">If the input formula contains a clause such as the OR of several literals, use associativity to parenthesize the expression fully so that every internal node in the resulting tree has just one or two children. The binary parse tree is like a circuit for computing the function.</p>
<p>Mimicking the reduction in the proof of Theorem 34.9, introduce a variable <em>y<sub>i</sub></em> for the output of each internal node. Then rewrite the original formula <em><span class="symbolfont">ϕ</span></em> as the AND of the variable at the root of the parse tree and a conjunction of clauses describing the operation of each node. For the formula (34.3), the resulting expression is</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="symbolfont">ϕ</span></em>′ = <em>y</em><sub>1</sub></td>
<td class="td2">∧</td>
<td class="td2">(<em>y</em><sub>1</sub> ↔ (<em>y</em><sub>2</sub> ∧ ¬<em>x</em><sub>2</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>y</em><sub>2</sub> ↔ (<em>y</em><sub>3</sub> ∨ <em>y</em><sub>4</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>y</em><sub>3</sub> ↔ (<em>x</em><sub>1</sub> → <em>x</em><sub>2</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>y</em><sub>4</sub> ↔ ¬<em>y</em><sub>5</sub>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>y</em><sub>5</sub> ↔ (<em>y</em><sub>6</sub> ∨ <em>x</em><sub>4</sub>))</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">∧</td>
<td class="td2">(<em>y</em><sub>6</sub> ↔ (¬<em>x</em><sub>1</sub> ↔ <em>x</em><sub>3</sub>)).</td>
</tr>
</table>
<a id="p1078"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-12"><img alt="art" src="images/Art_P1448.jpg"/></p>
<p class="caption"><strong>Figure 34.12</strong> The truth table for the clause (<em>y</em><sub>1</sub> ↔ (<em>y</em><sub>2</sub> ∧ ¬<em>x</em><sub>2</sub>)).</p>
</div>
<p class="noindent">The formula <em><span class="symbolfont">ϕ</span></em>′ thus obtained is a conjunction of clauses <img alt="art" src="images/Art_P1448a.jpg"/>, each of which has at most three literals. These clauses are not yet ORs of three literals.</p>
<p>The second step of the reduction converts each clause <img alt="art" src="images/Art_P1448a.jpg"/> into conjunctive normal form. Construct a truth table for <img alt="art" src="images/Art_P1448a.jpg"/> by evaluating all possible assignments to its variables. Each row of the truth table consists of a possible assignment of the variables of the clause, together with the value of the clause under that assignment. Using the truth-table entries that evaluate to 0, build a formula in <strong><em><span class="blue">disjunctive normal form</span></em></strong> (or <strong><em><span class="blue">DNF</span></em></strong>)—an OR of ANDs—that is equivalent to ¬ <img alt="art" src="images/Art_P1448a.jpg"/>. Then negate this formula and convert it into a CNF formula <img alt="art" src="images/Art_P1448b.jpg"/> by using <strong><em><span class="blue">DeMorgan’s laws</span></em></strong> for propositional logic,</p>
<table class="table2b">
<tr>
<td class="td2">¬(<em>a</em> ∧ <em>b</em>)</td>
<td class="td2">=</td>
<td class="td2">¬<em>a</em> ∨ ¬<em>b,</em></td>
</tr>
<tr>
<td class="td2">¬(<em>a</em> ∨ <em>b</em>)</td>
<td class="td2">=</td>
<td class="td2">¬<em>a</em> ∧ ¬<em>b,</em></td>
</tr>
</table>
<p class="noindent">to complement all literals, change ORs into ANDs, and change ANDs into ORs.</p>
<p>In our example, the clause <img alt="art" src="images/Art_P1448c.jpg"/> converts into CNF as follows. The truth table for <img alt="art" src="images/Art_P1448d.jpg"/> appears in <a href="chapter034.xhtml#Fig_34-12">Figure 34.12</a>. The DNF formula equivalent to ¬ <img alt="art" src="images/Art_P1448d.jpg"/> is</p>
<p class="eql">(<em>y</em><sub>1</sub> ∧ <em>y</em><sub>2</sub> ∧ <em>x</em><sub>2</sub>) ∨ (<em>y</em><sub>1</sub> ∧ ¬<em>y</em><sub>2</sub> ∧ <em>x</em><sub>2</sub>) ∨ (<em>y</em><sub>1</sub> ∧ ¬<em>y</em><sub>2</sub> ∧ ¬<em>x</em><sub>2</sub>) ∨ (¬<em>y</em><sub>1</sub> ∧ <em>y</em><sub>2</sub> ∧ ¬<em>x</em><sub>2</sub>).</p>
<p class="noindent">Negating and applying DeMorgan’s laws yields the CNF formula</p>
<p class="eql"><img alt="art" src="images/Art_P1448e.jpg"/></p>
<p class="noindent">which is equivalent to the original clause <img alt="art" src="images/Art_P1448d.jpg"/>.</p>
<p>At this point, each clause <img alt="art" src="images/Art_P1448a.jpg"/> of the formula <em><span class="symbolfont">ϕ</span></em>′ has been converted into a CNF formula <img alt="art" src="images/Art_P1448b.jpg"/>, and thus <em><span class="symbolfont">ϕ</span></em>′ is equivalent to the CNF formula <em><span class="symbolfont">ϕ</span></em>″ consisting of the conjunction of the <img alt="art" src="images/Art_P1448b.jpg"/>. Moreover, each clause of <em><span class="symbolfont">ϕ</span></em>″ has at most three literals.</p>
<a id="p1079"/>
<p>The third and final step of the reduction further transforms the formula so that each clause has <em>exactly</em> three distinct literals. From the clauses of the CNF formula <em><span class="symbolfont">ϕ</span></em>″, construct the final 3-CNF formula <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span>. This formula also uses two auxiliary variables, <em>p</em> and <em>q</em>. For each clause <em>C<sub>i</sub></em> of <em><span class="symbolfont">ϕ</span></em>″, include the following clauses in <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span>:</p>
<ul class="ulnoindent" epub:type="list">
<li>If <em>C<sub>i</sub></em> contains three distinct literals, then simply include <em>C<sub>i</sub></em> as a clause of <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span>.</li>
<li class="litop">If <em>C<sub>i</sub></em> contains exactly two distinct literals, that is, if <em>C<sub>i</sub></em> = (<em>l</em><sub>1</sub> ∨ <em>l</em><sub>2</sub>), where <em>l</em><sub>1</sub> and <em>l</em><sub>2</sub> are literals, then include (<em>l</em><sub>1</sub> ∨ <em>l</em><sub>2</sub> ∨ <em>p</em>) ∧ (<em>l</em><sub>1</sub> ∨ <em>l</em><sub>2</sub> ∨ ¬<em>p</em>) as clauses of <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span>. The literals <em>p</em> and ¬<em>p</em> merely fulfill the syntactic requirement that each clause of <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span> contain exactly three distinct literals. Whether <em>p</em> = 0 or <em>p</em> = 1, one of the clauses is equivalent to <em>l</em><sub>1</sub> ∨ <em>l</em><sub>2</sub>, and the other evaluates to 1, which is the identity for AND.</li>
<li class="litop">If <em>C<sub>i</sub></em> contains just one distinct literal <em>l</em>, then include (<em>l</em> ∨<em>p</em> ∨<em>q</em>)∧(<em>l</em> ∨ <em>p</em> ∨ ¬<em>q</em>) ∧ (<em>l</em> ∨ ¬<em>p</em> ∨ <em>q</em>) ∧ (<em>l</em> ∨ ¬<em>p</em> ∨ ¬<em>q</em>) as clauses of <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span>. Regardless of the values of <em>p</em> and <em>q</em>, one of the four clauses is equivalent to <em>l</em>, and the other three evaluate to 1.</li></ul>
<p>We can see that the 3-CNF formula <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span> is satisfiable if and only if <em><span class="symbolfont">ϕ</span></em> is satisfiable by inspecting each of the three steps. Like the reduction from CIRCUIT-SAT to SAT, the construction of <em><span class="symbolfont">ϕ</span></em>′ from <em><span class="symbolfont">ϕ</span></em> in the first step preserves satisfiability. The second step produces a CNF formula <em><span class="symbolfont">ϕ</span></em>″ that is algebraically equivalent to <em><span class="symbolfont">ϕ</span></em>′. Then the third step produces a 3-CNF formula <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span> that is effectively equivalent to <em><span class="symbolfont">ϕ</span></em>″, since any assignment to the variables <em>p</em> and <em>q</em> produces a formula that is algebraically equivalent to <em><span class="symbolfont">ϕ</span></em>″.</p>
<p>We must also show that the reduction can be computed in polynomial time. Constructing <em><span class="symbolfont">ϕ</span></em>′ from <em><span class="symbolfont">ϕ</span></em> introduces at most one variable and one clause per connective in <em><span class="symbolfont">ϕ</span></em>. Constructing <em><span class="symbolfont">ϕ</span></em>″ from <em><span class="symbolfont">ϕ</span></em>′ can introduce at most eight clauses into <em><span class="symbolfont">ϕ</span></em>″ for each clause from <em><span class="symbolfont">ϕ</span></em>′, since each clause of <em><span class="symbolfont">ϕ</span></em>′ contains at most three variables, and the truth table for each clause has at most 2<sup>3</sup> = 8 rows. The construction of <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span> from <em><span class="symbolfont">ϕ</span></em>″ introduces at most four clauses into <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span> for each clause of <em><span class="symbolfont">ϕ</span></em>″. Thus the size of the resulting formula <em><span class="symbolfont">ϕ</span></em><span class="font1">‴</span> is polynomial in the length of the original formula. Each of the constructions can be accomplished in polynomial time.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>34.4-1</em></strong></p>
<p class="noindent">Consider the straightforward (nonpolynomial-time) reduction in the proof of Theorem 34.9. Describe a circuit of size <em>n</em> that, when converted to a formula by this method, yields a formula whose size is exponential in <em>n</em>.</p>
<a id="p1080"/>
<p class="level3"><strong><em>34.4-2</em></strong></p>
<p class="noindent">Show the 3-CNF formula that results upon using the method of Theorem 34.10 on the formula (34.3).</p>
<p class="level3"><strong><em>34.4-3</em></strong></p>
<p class="noindent">Professor Jagger proposes to show that SAT ≤<sub>P</sub> 3-CNF-SAT by using only the truth-table technique in the proof of Theorem 34.10, and not the other steps. That is, the professor proposes to take the boolean formula <em><span class="symbolfont">ϕ</span></em>, form a truth table for its variables, derive from the truth table a formula in 3-DNF that is equivalent to ¬<em><span class="symbolfont">ϕ</span></em>, and then negate and apply DeMorgan’s laws to produce a 3-CNF formula equivalent to <em><span class="symbolfont">ϕ</span></em>. Show that this strategy does not yield a polynomial-time reduction.</p>
<p class="level3"><strong><em>34.4-4</em></strong></p>
<p class="noindent">Show that the problem of determining whether a boolean formula is a tautology is complete for co-NP. (<em>Hint:</em> See Exercise 34.3-7.)</p>
<p class="level3"><strong><em>34.4-5</em></strong></p>
<p class="noindent">Show that the problem of determining the satisfiability of boolean formulas in disjunctive normal form is polynomial-time solvable.</p>
<p class="level3"><strong><em>34.4-6</em></strong></p>
<p class="noindent">Someone gives you a polynomial-time algorithm to decide formula satisfiability. Describe how to use this algorithm to find satisfying assignments in polynomial time.</p>
<p class="level3"><strong><em>34.4-7</em></strong></p>
<p class="noindent">Let 2-CNF-SAT be the set of satisfiable boolean formulas in CNF with exactly two literals per clause. Show that 2-CNF-SAT ∈ P. Make your algorithm as efficient as possible. (<em>Hint:</em> Observe that <em>x</em> ∨ <em>y</em> is equivalent to ¬<em>x</em> → <em>y</em>. Reduce 2-CNF-SAT to an efficiently solvable problem on a directed graph.)</p>
</section>
<p class="line1"/>
<section title="34.5 NP-complete problems">
<a id="Sec_34.5"/>
<p class="level1" id="h1-203"><a href="toc.xhtml#Rh1-203"><strong>34.5    NP-complete problems</strong></a></p>
<p class="noindent">NP-complete problems arise in diverse domains: boolean logic, graphs, arithmetic, network design, sets and partitions, storage and retrieval, sequencing and scheduling, mathematical programming, algebra and number theory, games and puzzles, automata and language theory, program optimization, biology, chemistry, physics, and more. This section uses the reduction methodology to provide NP-completeness proofs for a variety of problems drawn from graph theory and set partitioning.</p>
<a id="p1081"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-13"><img alt="art" src="images/Art_P1449.jpg"/></p>
<p class="caption"><strong>Figure 34.13</strong> The structure of NP-completeness proofs in <a href="chapter034.xhtml#Sec_34.4">Sections 34.4</a> and <a href="chapter034.xhtml#Sec_34.5">34.5</a>. All proofs ultimately follow by reduction from the NP-completeness of CIRCUIT-SAT.</p>
</div>
<p><a href="chapter034.xhtml#Fig_34-13">Figure 34.13</a> outlines the structure of the NP-completeness proofs in this section and <a href="chapter034.xhtml#Sec_34.4">Section 34.4</a>. We prove each language in the figure to be NP-complete by reduction from the language that points to it. At the root is CIRCUIT-SAT, which we proved NP-complete in Theorem 34.7. This section concludes with a recap of reduction strategies.</p>
<section title="34.5.1 The clique problem">
<p class="level2" id="Sec_34.5.1"><strong>34.5.1    The clique problem</strong></p>
<p class="noindent">A <strong><em><span class="blue">clique</span></em></strong> in an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) is a subset <em>V</em>′ ⊆ <em>V</em> of vertices, each pair of which is connected by an edge in <em>E</em>. In other words, a clique is a complete subgraph of <em>G</em>. The <strong><em><span class="blue">size</span></em></strong> of a clique is the number of vertices it contains. The <strong><em><span class="blue">clique problem</span></em></strong> is the optimization problem of finding a clique of maximum size in a graph. The corresponding decision problem asks simply whether a clique of a given size <em>k</em> exists in the graph. The formal definition is</p>
<p class="eql">CLIQUE = {<span class="font1"><span class="font1">〈</span></span><em>G, k</em><span class="font1"><span class="font1">〉</span></span> : <em>G</em> is a graph containing a clique of size <em>k</em>}.</p>
<p class="space-break">A naive algorithm for determining whether a graph <em>G</em> = (<em>V</em>, <em>E</em>) with |<em>V</em>| vertices contains a clique of size <em>k</em> lists all <em>k</em>-subsets of <em>V</em> and checks each one to see whether it forms a clique. The running time of this algorithm is <img alt="art" src="images/Art_P1450.jpg"/>, which is polynomial if <em>k</em> is a constant. In general, however, <em>k</em> could be near |<em>V</em>|/2, in which case the algorithm runs in superpolynomial time. Indeed, an efficient algorithm for the clique problem is unlikely to exist.</p>
<a id="p1082"/>
<p class="theo"><strong><em>Theorem 34.11</em></strong></p>
<p class="noindent">The clique problem is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   First, we show that CLIQUE ∈ NP. For a given graph <em>G</em> = (<em>V</em>, <em>E</em>), use the set <em>V</em>′ ⊆ <em>V</em> of vertices in the clique as a certificate for <em>G</em>. To check whether <em>V</em>′ is a clique in polynomial time, check whether, for each pair <em>u, v</em> ∈ <em>V</em>′, the edge (<em>u</em>, <em>v</em>) belongs to <em>E</em>.</p>
<p>We next prove that 3-CNF-SAT ≤<sub>P</sub> CLIQUE, which shows that the clique problem is NP-hard. You might be surprised that the proof reduces an instance of 3-CNF-SAT to an instance of CLIQUE, since on the surface logical formulas seem to have little to do with graphs.</p>
<p>The reduction algorithm begins with an instance of 3-CNF-SAT. Let <em><span class="symbolfont">ϕ</span></em> = <em>C</em><sub>1</sub> ∧ <em>C</em><sub>2</sub> ∧ <span class="font1">⋯</span> ∧ <em>C<sub>k</sub></em> be a boolean formula in 3-CNF with <em>k</em> clauses. For <em>r</em> = 1, 2, … , <em>k</em>, each clause <em>C<sub>r</sub></em> contains exactly three distinct literals: <img alt="art" src="images/Art_P1451.jpg"/>, and <img alt="art" src="images/Art_P1452.jpg"/>. We will construct a graph <em>G</em> such that <em><span class="symbolfont">ϕ</span></em> is satisfiable if and only if <em>G</em> contains a clique of size <em>k</em>.</p>
<p>We construct the undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) as follows. For each clause <img alt="art" src="images/Art_P1453.jpg"/> in <em><span class="symbolfont">ϕ</span></em>, place a triple of vertices <img alt="art" src="images/Art_P1454.jpg"/>, and <img alt="art" src="images/Art_P1455.jpg"/> into <em>V</em>. Add edge <img alt="art" src="images/Art_P1456.jpg"/> into <em>E</em> if both of the following hold:</p>
<ul class="ulnoindent" epub:type="list">
<li><img alt="art" src="images/Art_P1457.jpg"/> and <img alt="art" src="images/Art_P1458.jpg"/> are in different triples, that is, <em>r</em> ≠ <em>s</em>, and</li>
<li class="litop">their corresponding literals are <strong><em><span class="blue">consistent</span></em></strong>, that is, <img alt="art" src="images/Art_P1459.jpg"/> is not the negation of <img alt="art" src="images/Art_P1460.jpg"/>.</li></ul>
<p class="noindent">We can build this graph from <em><span class="symbolfont">ϕ</span></em> in polynomial time. As an example of this construction, if</p>
<p class="eql"><em><span class="symbolfont">ϕ</span></em> = (<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>2</sub> ∨ ¬<em>x</em><sub>3</sub>) ∧ (¬<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub> ∨ <em>x</em><sub>3</sub>) ∧ (<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub> ∨ <em>x</em><sub>3</sub>),</p>
<p class="noindent">then <em>G</em> is the graph shown in <a href="chapter034.xhtml#Fig_34-14">Figure 34.14</a>.</p>
<p>We must show that this transformation of <em><span class="symbolfont">ϕ</span></em> into <em>G</em> is a reduction. First, suppose that <em><span class="symbolfont">ϕ</span></em> has a satisfying assignment. Then each clause <em>C<sub>r</sub></em> contains at least one literal <img alt="art" src="images/Art_P1459.jpg"/> that is assigned 1, and each such literal corresponds to a vertex <img alt="art" src="images/Art_P1457.jpg"/>. Picking one such “true” literal from each clause yields a set <em>V</em>′ of <em>k</em> vertices. We claim that <em>V</em>′ is a clique. For any two vertices <img alt="art" src="images/Art_P1463.jpg"/>, where <em>r</em> ≠ <em>s</em>, both corresponding literals <img alt="art" src="images/Art_P1459.jpg"/> and <img alt="art" src="images/Art_P1460.jpg"/> map to 1 by the given satisfying assignment, and thus the literals cannot be complements. Thus, by the construction of <em>G</em>, the edge <img alt="art" src="images/Art_P1456.jpg"/> belongs to <em>E</em>.</p>
<p>Conversely, suppose that <em>G</em> contains a clique <em>V</em>′ of size <em>k</em>. No edges in <em>G</em> connect vertices in the same triple, and so <em>V</em>′ contains exactly one vertex per triple. If <img alt="art" src="images/Art_P1467.jpg"/>, then assign 1 to the corresponding literal <img alt="art" src="images/Art_P1459.jpg"/>. Since <em>G</em> contains no edges between inconsistent literals, no literal and its complement are both assigned 1. Each clause is satisfied, and so <em><span class="symbolfont">ϕ</span></em> is satisfied. (Any variables that do not correspond to a vertex in the clique may be set arbitrarily.)</p>
<p class="right"><span class="font1">▪</span></p>
<a id="p1083"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-14"><img alt="art" class="width100" src="images/Art_P1469.jpg"/></p>
<p class="caption"><strong>Figure 34.14</strong> The graph <em>G</em> derived from the 3-CNF formula <em><span class="symbolfont">ϕ</span></em> = <em>C</em><sub>1</sub> ∧ <em>C</em><sub>2</sub> ∧ <em>C</em><sub>3</sub>, where <em>C</em><sub>1</sub> = (<em>x</em><sub>1</sub> ∨ ¬<em>x</em><sub>2</sub> ∨ ¬<em>x</em><sub>3</sub>), <em>C</em><sub>2</sub> = (¬<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub> ∨ <em>x</em><sub>3</sub>), and <em>C</em><sub>3</sub> = (<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub> ∨ <em>x</em><sub>3</sub>), in reducing 3-CNF-SAT to CLIQUE. A satisfying assignment of the formula has <em>x</em><sub>2</sub> = 0, <em>x</em><sub>3</sub> = 1, and <em>x</em><sub>1</sub> set to either 0 or 1. This assignment satisfies <em>C</em><sub>1</sub> with ¬<em>x</em><sub>2</sub>, and it satisfies <em>C</em><sub>2</sub> and <em>C</em><sub>3</sub> with <em>x</em><sub>3</sub>, corresponding to the clique with blue vertices.</p>
</div>
<p>In the example of <a href="chapter034.xhtml#Fig_34-14">Figure 34.14</a>, a satisfying assignment of <em><span class="symbolfont">ϕ</span></em> has <em>x</em><sub>2</sub> = 0 and <em>x</em><sub>3</sub> = 1. A corresponding clique of size <em>k</em> = 3 consists of the vertices corresponding to ¬<em>x</em><sub>2</sub> from the first clause, <em>x</em><sub>3</sub> from the second clause, and <em>x</em><sub>3</sub> from the third clause. Because the clique contains no vertices corresponding to either <em>x</em><sub>1</sub> or ¬<em>x</em><sub>1</sub>, this satisfying assignment can set <em>x</em><sub>1</sub> to either 0 or 1.</p>
<p>The proof of Theorem 34.11 reduced an arbitrary instance of 3-CNF-SAT to an instance of CLIQUE with a particular structure. You might think that we have shown only that CLIQUE is NP-hard in graphs in which the vertices are restricted to occur in triples and in which there are no edges between vertices in the same triple. Indeed, we have shown that CLIQUE is NP-hard only in this restricted case, but this proof suffices to show that CLIQUE is NP-hard in general graphs. Why? If there were a polynomial-time algorithm that solves CLIQUE on general graphs, it would also solve CLIQUE on restricted graphs.</p>
<p>The opposite approach—reducing instances of 3-CNF-SAT with a special structure to general instances of CLIQUE—does not suffice, however. Why not? Perhaps the instances of 3-CNF-SAT that we choose to reduce from are “easy,” and so we would not have reduced an NP-hard problem to CLIQUE.</p>
<p>Moreover, the reduction uses the instance of 3-CNF-SAT, but not the solution. We would have erred if the polynomial-time reduction had relied on knowing <a id="p1084"/>whether the formula <em><span class="symbolfont">ϕ</span></em> is satisfiable, since we do not know how to decide whether <em><span class="symbolfont">ϕ</span></em> is satisfiable in polynomial time.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-15"><img alt="art" src="images/Art_P1470.jpg"/></p>
<p class="caption"><strong>Figure 34.15</strong> Reducing CLIQUE to VERTEX-COVER. <strong>(a)</strong> An undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) with clique <em>V</em>′ = {<em>u, v, x, y</em>}, shown in blue. <strong>(b)</strong> The graph <em><span class="overline">G</span></em> produced by the reduction algorithm that has vertex cover <em>V</em> − <em>V′</em> = {<em>w, z</em>}, in blue.</p>
</div>
</section>
<section title="34.5.2 The vertex-cover problem">
<p class="level2" id="Sec_34.5.2"><strong>34.5.2    The vertex-cover problem</strong></p>
<p class="noindent">A <strong><em><span class="blue">vertex cover</span></em></strong> of an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) is a subset <em>V</em>′ ⊆ <em>V</em> such that if (<em>u</em>, <em>v</em>) ∈ <em>E</em>, then <em>u</em> ∈ <em>V</em>′ or <em>v</em> ∈ <em>V</em>′ (or both). That is, each vertex “covers” its incident edges, and a vertex cover for <em>G</em> is a set of vertices that covers all the edges in <em>E</em>. The <strong><em><span class="blue">size</span></em></strong> of a vertex cover is the number of vertices in it. For example, the graph in <a href="chapter034.xhtml#Fig_34-15">Figure 34.15(b)</a> has a vertex cover {<em>w, z</em>} of size 2.</p>
<p>The <strong><em><span class="blue">vertex-cover problem</span></em></strong> is to find a vertex cover of minimum size in a given graph. For this optimization problem, the corresponding decision problem asks whether a graph has a vertex cover of a given size <em>k</em>. As a language, we define</p>
<p class="eql">VERTEX-COVER = {<span class="font1"><span class="font1">〈</span></span><em>G, k</em><span class="font1"><span class="font1">〉</span></span> : graph <em>G</em> has a vertex cover of size <em>k</em>}.</p>
<p class="noindent">The following theorem shows that this problem is NP-complete.</p>
<p class="theo"><strong><em>Theorem 34.12</em></strong></p>
<p class="noindent">The vertex-cover problem is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   We first show that VERTEX-COVER ∈ NP. Given a graph <em>G</em> = (<em>V</em>, <em>E</em>) and an integer <em>k</em>, the certificate is the vertex cover <em>V</em>′ ⊆ <em>V</em> itself. The verification algorithm affirms that |<em>V</em>′| = <em>k</em>, and then it checks, for each edge (<em>u</em>, <em>v</em>) ∈ <em>E</em>, that <em>u</em> ∈ <em>V</em>′ or <em>v</em> ∈ <em>V</em>′. It is easy to verify the certificate in polynomial time.</p>
<p>To prove that the vertex-cover problem is NP-hard, we reduce from the clique problem, showing that CLIQUE ≤<sub>P</sub> VERTEX-COVER. This reduction relies <a id="p1085"/>on the notion of the complement of a graph. Given an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>), we define the <strong><em><span class="blue">complement</span></em></strong> of <em>G</em> as a graph <em><span class="overline">G</span></em> = (<em>V</em>, <em><span class="overline">E</span></em>), where <em><span class="overline">E</span></em> = {(<em>u</em>, <em>v</em>) : <em>u, v</em> ∈ <em>V, u</em> ≠ <em>v</em>, and (<em>u</em>, <em>v</em>) ∉ <em>E</em>}. In other words, <em><span class="overline">G</span></em> is the graph containing exactly those edges that are not in <em>G</em>. <a href="chapter034.xhtml#Fig_34-15">Figure 34.15</a> shows a graph and its complement and illustrates the reduction from CLIQUE to VERTEX-COVER.</p>
<p>The reduction algorithm takes as input an instance <span class="font1"><span class="font1">〈</span></span><em>G, k</em><span class="font1"><span class="font1">〉</span></span> of the clique problem and computes the complement <em><span class="overline">G</span></em> in polynomial time. The output of the reduction algorithm is the instance <span class="font1"><span class="font1">〈</span></span><em><span class="overline">G</span></em>, |<em>V</em>| − <em>k</em><span class="font1"><span class="font1">〉</span></span> of the vertex-cover problem. To complete the proof, we show that this transformation is indeed a reduction: the graph <em>G</em> contains a clique of size <em>k</em> if and only if the graph <em><span class="overline">G</span></em> has a vertex cover of size |<em>V</em>| − <em>k</em>.</p>
<p>Suppose that <em>G</em> contains a clique <em>V</em>′ ⊆ <em>V</em> with |<em>V</em>′| = <em>k</em>. We claim that <em>V</em> − <em>V</em>′ is a vertex cover in <em><span class="overline">G</span></em>. Let (<em>u</em>, <em>v</em>) be any edge in <em><span class="overline">E</span></em>. Then, (<em>u</em>, <em>v</em>) ∉ <em>E</em>, which implies that at least one of <em>u</em> or <em>v</em> does not belong to <em>V</em>′, since every pair of vertices in <em>V</em>′ is connected by an edge of <em>E</em>. Equivalently, at least one of <em>u</em> or <em>v</em> belongs to <em>V</em> − <em>V</em>′, which means that edge (<em>u</em>, <em>v</em>) is covered by <em>V</em> − <em>V</em>′. Since (<em>u</em>, <em>v</em>) was chosen arbitrarily from <em><span class="overline">E</span></em>, every edge of <em><span class="overline">E</span></em> is covered by a vertex in <em>V</em> −<em>V</em>′. Hence the set <em>V</em> − <em>V</em>′, which has size |<em>V</em>| − <em>k</em>, forms a vertex cover for <em><span class="overline">G</span></em>.</p>
<p>Conversely, suppose that <em><span class="overline">G</span></em> has a vertex cover <em>V</em>′ ⊆ <em>V</em>, where |<em>V</em>′| = |<em>V</em>| − <em>k</em>. Then for all <em>u, v</em> ∈ <em>V</em>, if (<em>u</em>, <em>v</em>) ∈ <em><span class="overline">E</span></em>, then <em>u</em> ∈ <em>V</em>′ or <em>v</em> ∈ <em>V</em>′ or both. The contrapositive of this implication is that for all <em>u, v</em> ∈ <em>V</em>, if <em>u</em> ∉ <em>V</em>′ and <em>v</em> ∉ <em>V</em>′, then (<em>u</em>, <em>v</em>) ∈ <em>E</em>. In other words, <em>V</em> − <em>V</em>′ is a clique, and it has size |<em>V</em>|−|<em>V</em>′| = <em>k</em>.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">Since VERTEX-COVER is NP-complete, we don’t expect to find a polynomial-time algorithm for finding a minimum-size vertex cover. <a href="chapter035.xhtml#Sec_35.1">Section 35.1</a> presents a polynomial-time “approximation algorithm,” however, which produces “approximate” solutions for the vertex-cover problem. The size of a vertex cover produced by the algorithm is at most twice the minimum size of a vertex cover.</p>
<p>Thus, you shouldn’t give up hope just because a problem is NP-complete. You might be able to design a polynomial-time approximation algorithm that obtains near-optimal solutions, even though finding an optimal solution is NP-complete. <a href="chapter035.xhtml">Chapter 35</a> gives several approximation algorithms for NP-complete problems.</p>
</section>
<section title="34.5.3 The hamiltonian-cycle problem">
<p class="level2" id="Sec_34.5.3"><strong>34.5.3    The hamiltonian-cycle problem</strong></p>
<p class="noindent">We now return to the hamiltonian-cycle problem defined in <a href="chapter034.xhtml#Sec_34.2">Section 34.2</a>.</p>
<p class="theo"><strong><em>Theorem 34.13</em></strong></p>
<p class="noindent">The hamiltonian cycle problem is NP-complete.</p>
<a id="p1086"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-16"><img alt="art" class="width100" src="images/Art_P1471.jpg"/></p>
<p class="caption"><strong>Figure 34.16</strong> The gadget used in reducing the vertex-cover problem to the hamiltonian-cycle problem. An edge (<em>u</em>, <em>v</em>) of graph <em>G</em> corresponds to gadget Γ<sub><em>uv</em></sub> in the graph <em>G</em>′ created in the reduction. <strong>(a)</strong> The gadget, with individual vertices labeled. <strong>(b)–(d)</strong> The paths highlighted in blue are the only possible ones through the gadget that include all vertices, assuming that the only connections from the gadget to the remainder of <em>G</em>′ are through vertices [<em>u, v</em>, 1], [<em>u, v</em>, 6], [<em>v, u</em>, 1], and [<em>v, u</em>, 6].</p>
</div>
<p class="prof"><strong><em>Proof</em></strong>   We first show that HAM-CYCLE ∈ NP. Given an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>), the certificate is the sequence of |<em>V</em>| vertices that makes up the hamiltonian cycle. The verification algorithm checks that this sequence contains each vertex in <em>V</em> exactly once and that with the first vertex repeated at the end, it forms a cycle in <em>G</em>. That is, it checks that there is an edge between each pair of consecutive vertices and between the first and last vertices. This certificate can be verified in polynomial time.</p>
<p>We now prove that VERTEX-COVER ≤<sub>P</sub> HAM-CYCLE, which shows that HAM-CYCLE is NP-complete. Given an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) and an integer <em>k</em>, we construct an undirected graph <em>G</em>′ = (<em>V</em>′, <em>E</em>′) that has a hamiltonian cycle if and only if <em>G</em> has a vertex cover of size <em>k</em>. We assume without loss of generality that <em>G</em> contains no isolated vertices (that is, every vertex in <em>V</em> has at least one incident edge) and that <em>k</em> ≤ |<em>V</em>|. (If an isolated vertex belongs to a vertex cover of size <em>k</em>, then there also exists a vertex cover of size <em>k</em> − 1, and for any graph, the entire set <em>V</em> is always a vertex cover.)</p>
<p>Our construction uses a <strong><em><span class="blue">gadget</span></em></strong>, which is a piece of a graph that enforces certain properties. <a href="chapter034.xhtml#Fig_34-16">Figure 34.16(a)</a> shows the gadget we use. For each edge (<em>u</em>, <em>v</em>) ∈ <em>E</em>, the constructed graph <em>G</em>′ contains one copy of this gadget, which we denote by Γ<em><sub>uv</sub></em>. We denote each vertex in Γ<em><sub>uv</sub></em> by [<em>u, v, i</em>] or [<em>v, u, i</em>], where 1 ≤ <em>i</em> ≤ 6, so that each gadget Γ<em><sub>uv</sub></em> contains 12 vertices. Gadget Γ<em><sub>uv</sub></em> also contains the 14 edges shown in <a href="chapter034.xhtml#Fig_34-16">Figure 34.16(a)</a>.</p>
<p>Along with the internal structure of the gadget, we enforce the properties we want by limiting the connections between the gadget and the remainder of the graph <em>G</em>′ that we construct. In particular, only vertices [<em>u, v,</em> 1], [<em>u, v,</em> 6], [<em>v, u,</em> 1], and [<em>v, u,</em> 6] will have edges incident from outside Γ<em><sub>uv</sub></em>. Any hamiltonian cycle <a id="p1087"/>of <em>G</em>′ must traverse the edges of Γ<em><sub>uv</sub></em> in one of the three ways shown in <a href="chapter034.xhtml#Fig_34-16">Figures 34.16(b)</a>–<a href="chapter034.xhtml#Fig_34-16">(d)</a>. If the cycle enters through vertex [<em>u, v,</em> 1], it must exit through vertex [<em>u, v,</em> 6], and it either visits all 12 of the gadget’s vertices (<a href="chapter034.xhtml#Fig_34-16">Figure 34.16(b)</a>) or the six vertices [<em>u, v,</em> 1] through [<em>u, v,</em> 6] (<a href="chapter034.xhtml#Fig_34-16">Figure 34.16(c)</a>). In the latter case, the cycle will have to reenter the gadget to visit vertices [<em>v, u,</em> 1] through [<em>v, u,</em> 6]. Similarly, if the cycle enters through vertex [<em>v, u,</em> 1], it must exit through vertex [<em>v, u,</em> 6], and either it visits all 12 of the gadget’s vertices (<a href="chapter034.xhtml#Fig_34-16">Figure 34.16(d)</a>) or it visits the six vertices [<em>v, u,</em> 1] through [<em>v, u,</em> 6] and reenters to visit [<em>u, v,</em> 1] through [<em>u, v,</em> 6] (<a href="chapter034.xhtml#Fig_34-16">Figure 34.16(c)</a>). No other paths through the gadget that visit all 12 vertices are possible. In particular, it is impossible to construct two vertex-disjoint paths, one of which connects [<em>u, v,</em> 1] to [<em>v, u,</em> 6] and the other of which connects [<em>v, u,</em> 1] to [<em>u, v,</em> 6], such that the union of the two paths contains all of the gadget’s vertices.</p>
<p>The only other vertices in <em>V</em>′ other than those of gadgets are <strong><em><span class="blue">selector vertices</span></em></strong> <em>s</em><sub>1</sub>, <em>s</em><sub>2</sub>, … , <em>s<sub>k</sub></em>. We’ll use edges incident on selector vertices in <em>G</em>′ to select the <em>k</em> vertices of the cover in <em>G</em>.</p>
<p>In addition to the edges in gadgets, <em>E</em>′ contains two other types of edges, which <a href="chapter034.xhtml#Fig_34-17">Figure 34.17</a> shows. First, for each vertex <em>u</em> ∈ <em>V</em>, edges join pairs of gadgets in order to form a path containing all gadgets corresponding to edges incident on <em>u</em> in <em>G</em>. We arbitrarily order the vertices adjacent to each vertex <em>u</em> ∈ <em>V</em> as <em>u</em><sup>(1)</sup>, <em>u</em><sup>(2)</sup>, … , <em>u</em><sup>(degree(<em>u</em>))</sup>, where degree(<em>u</em>) is the number of vertices adjacent to <em>u</em>. To create a path in <em>G</em>′ through all the gadgets corresponding to edges incident on <em>u</em>, <em>E</em>′ contains the edges {([<em>u</em>, <em>u</em><sup>(<em>i</em>)</sup>, 6], [<em>u</em>, <em>u</em><sup>(<em>i</em>+1)</sup>, 1]) : 1 ≤ <em>i</em> ≤ degree(<em>u</em>) − 1}. In <a href="chapter034.xhtml#Fig_34-17">Figure 34.17</a>, for example, we order the vertices adjacent to <em>w</em> as <span class="font1"><span class="font1">〈</span></span><em>x, y, z</em><span class="font1"><span class="font1">〉</span></span>, and so graph <em>G</em>′ in part (b) of the figure includes the edges ([<em>w</em>, <em>x</em>, 6], [<em>w, y</em>, 1]) and ([<em>w</em>, <em>y</em>, 6], [<em>w</em>, <em>z</em>, 1]). The vertices adjacent to <em>x</em> are ordered as <span class="font1"><span class="font1">〈</span></span><em>w, y</em><span class="font1"><span class="font1">〉</span></span>, so that <em>G</em>′ includes the edge ([<em>x</em>, <em>w</em>, 6], [<em>x</em>, <em>y</em>, 1]). For each vertex <em>u</em> ∈ <em>V</em>, these edges in <em>G</em>′ fill in a path containing all gadgets corresponding to edges incident on <em>u</em> in <em>G</em>.</p>
<p>The intuition behind these edges is that if vertex <em>u</em> ∈ <em>V</em> belongs to the vertex cover of <em>G</em>, then <em>G</em>′ contains a path from [<em>u, u</em><sup>(1)</sup>, 1] to [<em>u, u</em><sup>(degree(<em>u</em>))</sup>, 6] that “covers” all gadgets corresponding to edges incident on <em>u</em>. That is, for each of these gadgets, say <img alt="art" src="images/Art_P1472.jpg"/>, the path either includes all 12 vertices (if <em>u</em> belongs to the vertex cover but <em>u</em><sup>(<em>i</em>)</sup> does not) or just the six vertices [<em>u, u</em><sup>(<em>i</em>)</sup>, 1] through [<em>u, u</em><sup>(<em>i</em>)</sup>, 6] (if both <em>u</em> and <em>u</em><sup>(<em>i</em>)</sup> belong to the vertex cover).</p>
<p>The final type of edge in <em>E</em>′ joins the first vertex [<em>u, u</em><sup>(1)</sup>, 1] and the last vertex [<em>u, u</em><sup>(degree(<em>u</em>))</sup>, 6] of each of these paths to each of the selector vertices. That is, <em>E</em>′ includes the edges</p>
<table class="table1a">
<tr>
<td class="td2">{(<em>s</em><sub><em>j</em></sub>, [<em>u, u</em><sup>(1)</sup>, 1]) : <em>u</em> ∈ <em>V</em> and 1 ≤ <em>j</em> ≤ <em>k</em>}</td>
</tr>
<tr>
<td class="td3"><p class="indent3">∪ {(<em>s</em><sub><em>j</em></sub>, [<em>u, u</em><sup>(degree(<em>u</em>))</sup>, 6]) : <em>u</em> ∈ <em>V</em> and 1 ≤ <em>j</em> ≤ <em>k</em>}.</p></td>
</tr>
</table>
<a id="p1088"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-17"><img alt="art" class="width100" src="images/Art_P1473.jpg"/></p>
<p class="caption"><strong>Figure 34.17</strong> Reducing an instance of the vertex-cover problem to an instance of the hamiltonian-cycle problem. <strong>(a)</strong> An undirected graph <em>G</em> with a vertex cover of size 2, consisting of the blue vertices <em>w</em> and <em>y</em>. <strong>(b)</strong> The undirected graph <em>G</em>′ produced by the reduction, with the hamiltonian cycle corresponding to the vertex cover highlighted in blue. The vertex cover {<em>w, y</em>} corresponds to edges (<em>s</em><sub>1</sub>, [<em>w, x</em>, 1]) and (<em>s</em><sub>2</sub>, [<em>y, x</em>, 1]) appearing in the hamiltonian cycle.</p>
</div>
<p>Next we show that the size of <em>G</em>′ is polynomial in the size of <em>G</em>, and hence it takes time polynomial in the size of <em>G</em> to construct <em>G</em>′. The vertices of <em>G</em>′ are those in the gadgets, plus the selector vertices. With 12 vertices per gadget, plus <em>k</em> ≤ |<em>V</em> | selector vertices, <em>G</em>′ contains a total of</p>
<table class="table2b">
<tr>
<td class="td2">|<em>V′</em>|</td>
<td class="td2">=</td>
<td class="td2">12 |<em>E</em>| + <em>k</em></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">≤</td>
<td class="td2">12 |<em>E</em>| + |<em>V</em>|</td>
</tr>
</table>
<p class="noindent">vertices. The edges of <em>G</em>′ are those in the gadgets, those that go between gadgets, and those connecting selector vertices to gadgets. Each gadget contains 14 edges, totaling 14 |<em>E</em>| in all gadgets. For each vertex <em>u</em> ∈ <em>V</em>, graph <em>G</em>′ has degree(<em>u</em>) − 1 edges going between gadgets, so that summed over all vertices in <em>V</em>,</p>
<a id="p1089"/>
<p class="eql"><img alt="art" src="images/Art_P1474.jpg"/></p>
<p class="noindent">edges go between gadgets. Finally, <em>G</em>′ has two edges for each pair consisting of a selector vertex and a vertex of <em>V</em>, totaling 2<em>k</em> |<em>V</em>| such edges. The total number of edges of <em>G</em>′ is therefore</p>
<table class="table2b">
<tr>
<td class="td2">|<em>E′</em>|</td>
<td class="td2">=</td>
<td class="td2">(14 |<em>E</em>|) + (2 |<em>E</em>| − |<em>V</em>|) + (2<em>k</em> |<em>V</em>|)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">16 |<em>E</em>| + (2<em>k</em> − 1) |<em>V</em>|</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">≤</td>
<td class="td2">16 |<em>E</em>| + (2 |<em>V</em>| − 1) |<em>V</em>|.</td>
</tr>
</table>
<p>Now we show that the transformation from graph <em>G</em> to <em>G</em>′ is a reduction. That is, we must show that <em>G</em> has a vertex cover of size <em>k</em> if and only if <em>G</em>′ has a hamiltonian cycle.</p>
<p>Suppose that <em>G</em> = (<em>V</em>, <em>E</em>) has a vertex cover <em>V</em>* ⊆ <em>V</em>, where |<em>V</em>*| = <em>k</em>. Let <em>V</em>* = {<em>u</em><sub>1</sub>, <em>u</em><sub>2</sub>, … , <em>u<sub>k</sub></em>}. As <a href="chapter034.xhtml#Fig_34-17">Figure 34.17</a> shows, we can construct a hamiltonian cycle in <em>G</em>′ by including the following edges<sup><a epub:type="footnote" href="#footnote_11" id="footnote_ref_11">11</a></sup> for each vertex <em>u<sub>j</sub></em> ∈ <em>V</em>*. Start by including edges <img alt="art" src="images/Art_P1475.jpg"/>, which connect all gadgets corresponding to edges incident on <em>u<sub>j</sub></em>. Also include the edges within these gadgets as <a href="chapter034.xhtml#Fig_34-16">Figures 34.16(b)</a>–<a href="chapter034.xhtml#Fig_34-16">(d)</a> show, depending on whether the edge is covered by one or two vertices in <em>V</em>*. The hamiltonian cycle also includes the edges</p>
<p class="eql"><img alt="art" src="images/Art_P1476.jpg"/></p>
<p class="noindent">By inspecting <a href="chapter034.xhtml#Fig_34-17">Figure 34.17</a>, you can verify that these edges form a cycle, where <em>u</em><sub>1</sub> = <em>w</em> and <em>u</em><sub>2</sub> = <em>y</em>. The cycle starts at <em>s</em><sub>1</sub>, visits all gadgets corresponding to edges incident on <em>u</em><sub>1</sub>, then visits <em>s</em><sub>2</sub>, visits all gadgets corresponding to edges incident on <em>u</em><sub>2</sub>, and so on, until it returns to <em>s</em><sub>1</sub>. The cycle visits each gadget either once or twice, depending on whether one or two vertices of <em>V</em>* cover its corresponding edge. Because <em>V</em>* is a vertex cover for <em>G</em>, each edge in <em>E</em> is incident on some vertex in <em>V</em>*, and so the cycle visits each vertex in each gadget of <em>G</em>′. Because the cycle also visits every selector vertex, it is hamiltonian.</p>
<p>Conversely, suppose that <em>G</em>′ = (<em>V</em>′, <em>E</em>′) contains a hamiltonian cycle <em>C</em> ⊆ <em>E</em>′. We claim that the set</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P1477.jpg"/></p>
<a id="p1090"/>
<p class="noindent">is a vertex cover for <em>G</em>.</p>
<p>We first argue that the set <em>V</em>* is well defined, that is, for each selector vertex <em>s<sub>j</sub></em>, exactly one of the incident edges in the hamiltonian cycle <em>C</em> is of the form (<em>s</em><sub><em>j</em></sub>, [<em>u</em>, <em>u</em><sup>(1)</sup>, 1]) for some vertex <em>u</em> ∈ <em>V</em>. To see why, partition the hamiltonian cycle <em>C</em> into maximal paths that start at some selector vertex <em>s<sub>i</sub></em>, visit one or more gadgets, and end at some selector vertex <em>s<sub>j</sub></em> without passing through any other selector vertex. Let’s call each of these maximal paths a “cover path.” Let <em>P</em> be one such cover path, and orient it going from <em>s<sub>i</sub></em> to <em>s<sub>j</sub></em>. If <em>P</em> contains the edge (<em>s<sub>i</sub></em>, [<em>u</em>, <em>u</em><sup>(1)</sup>, 1]) for some vertex <em>u</em> ∈ <em>V</em>, then we have shown that one edge incident on <em>s<sub>i</sub></em> has the required form. Assume, then, that <em>P</em> contains the edge (<em>s</em><sub><em>i</em></sub>, [<em>v, v</em><sup>(degree(<em>v</em>))</sup>, 6]) for some vertex <em>v</em> ∈ <em>V</em>. This path enters a gadget from the bottom, as drawn in <a href="chapter034.xhtml#Fig_34-16">Figures 34.16</a> and <a href="chapter034.xhtml#Fig_34-17">34.17</a>, and it leaves from the top. It might go through several gadgets, but it always enters from the bottom of a gadget and leaves from the top. The only edges incident on vertices at the top of a gadget either go to the bottoms of other gadgets or to selector vertices. Therefore, after the last gadget in the series of gadgets visited by <em>P</em>, the edge taken must go to a selector vertex <em>s<sub>j</sub></em>, so that <em>P</em> contains an edge of the form (<em>s</em><sub><em>j</em></sub>, [<em>u</em>, <em>u</em><sup>(1)</sup>, 1]), where [<em>u, u</em><sup>(1)</sup>, 1] is a vertex at the top of some gadget. To see that not both edges incident on <em>s<sub>j</sub></em> have this form, simply reverse the direction of traversing <em>P</em> in the above argument.</p>
<p>Having established that the set <em>V</em>* is well defined, let’s see why it is a vertex cover for <em>G</em>. We have already established that each cover path starts at some <em>s<sub>i</sub></em>, takes the edge (<em>s</em><sub><em>i</em></sub>, [<em>u, u</em><sup>(1)</sup>, 1]) for some vertex <em>u</em> ∈ <em>V</em>, passes through all the gadgets corresponding to edges in <em>E</em> incident on <em>u</em>, and then ends at some selector vertex <em>s<sub>j</sub></em>. (This orientation is the reverse of the orientation in the paragraph above.) Let’s call this cover path <em>P<sub>u</sub></em>, and by equation (34.4), the vertex cover <em>V</em>* includes <em>u</em>. Each gadget visited by <em>P<sub>u</sub></em> must be Γ<em><sub>uv</sub></em> or Γ<em><sub>vu</sub></em> for some <em>v</em> ∈ <em>V</em>. For each gadget visited by <em>P<sub>u</sub></em>, its vertices are visited by either one or two cover paths. If they are visited by one cover path, then edge (<em>u</em>, <em>v</em>) ∈ <em>E</em> is covered in <em>G</em> by vertex <em>u</em>. If two cover paths visit the gadget, then the other cover path must be <em>P<sub>v</sub></em>, which implies that <em>v</em> ∈ <em>V</em>*, and edge (<em>u</em>, <em>v</em>) ∈ <em>E</em> is covered by both <em>u</em> and <em>v</em>. Because each vertex in each gadget is visited by some cover path, we see that each edge in <em>E</em> is covered by some vertex in <em>V</em>*.</p>
<p class="right"><span class="font1">▪</span></p>
</section>
<section title="34.5.4 The traveling-salesperson problem">
<p class="level2" id="Sec_34.5.4"><strong>34.5.4    The traveling-salesperson problem</strong></p>
<p class="noindent">In the <strong><em><span class="blue">traveling-salesperson problem</span></em></strong>, which is closely related to the hamiltonian-cycle problem, a salesperson must visit <em>n</em> cities. Let’s model the problem as a complete graph with <em>n</em> vertices, so that the salesperson wishes to make a <strong><em><span class="blue">tour</span></em></strong>, or hamiltonian cycle, visiting each city exactly once and finishing at the starting city. The salesperson incurs a nonnegative integer cost <em>c</em>(<em>i, j</em>) to travel from city <em>i</em> <a id="p1091"/>to city <em>j</em>. In the optimization version of the problem, the salesperson wishes to make the tour whose total cost is minimum, where the total cost is the sum of the individual costs along the edges of the tour. For example, in <a href="chapter034.xhtml#Fig_34-18">Figure 34.18</a>, a minimum-cost tour is <span class="font1"><span class="font1">〈</span></span><em>u, w, v, x, u</em><span class="font1"><span class="font1">〉</span></span>, with cost 7. The formal language for the corresponding decision problem is</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-18"><img alt="art" src="images/Art_P1478.jpg"/></p>
<p class="caption"><strong>Figure 34.18</strong> An instance of the traveling-salesperson problem. Edges highlighted in blue represent a minimum-cost tour, with cost 7.</p>
</div>
<table class="table2b">
<tr>
<td class="td2">TSP = {<span class="font1"><span class="font1">〈</span></span><em>G, c, k</em><span class="font1"><span class="font1">〉</span></span>:</td>
<td class="td2"><em>G</em> = (<em>V</em>, <em>E</em>) is a complete graph,</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><em>c</em> is a function from <em>V</em> × <em>V</em> → <span class="font1">ℕ</span>,</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><em>k</em> ∈ <span class="font1">ℕ</span>, and</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><em>G</em> has a traveling-salesperson tour with cost at most <em>k</em>}.</td>
</tr>
</table>
<p>The following theorem shows that a fast algorithm for the traveling-salesperson problem is unlikely to exist.</p>
<p class="theo"><strong><em>Theorem 34.14</em></strong></p>
<p class="noindent">The traveling-salesperson problem is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   We first show that TSP ∈ NP. Given an instance of the problem, the certificate is the sequence of <em>n</em> vertices in the tour. The verification algorithm checks that this sequence contains each vertex exactly once, sums up the edge costs, and checks that the sum is at most <em>k</em>. This process can certainly be done in polynomial time.</p>
<p>To prove that TSP is NP-hard, we show that HAM-CYCLE ≤<sub>P</sub> TSP. Given an instance <em>G</em> = (<em>V</em>, <em>E</em>) of HAM-CYCLE, construct an instance of TSP by forming the complete graph <em>G</em>′ = (<em>V</em>, <em>E</em>′), where <em>E</em>′ = {(<em>i</em>, <em>j</em>) : <em>i, j</em> ∈ <em>V</em> and <em>i</em> ≠ <em>j</em> }, with the cost function <em>c</em> defined as</p>
<p class="eql"><img alt="art" src="images/Art_P1479.jpg"/></p>
<p class="noindent">(Because <em>G</em> is undirected, it contains no self-loops, and so <em>c</em>(<em>v, v</em>) = 1 for all vertices <em>v</em> ∈ <em>V</em>.) The instance of TSP is then <span class="font1"><span class="font1">〈</span></span><em>G</em>′, <em>c</em>, 0<span class="font1"><span class="font1">〉</span></span>, which can be created in polynomial time.</p>
<a id="p1092"/>
<p>We now show that graph <em>G</em> has a hamiltonian cycle if and only if graph <em>G</em>′ has a tour of cost at most 0. Suppose that graph <em>G</em> has a hamiltonian cycle <em>H</em>. Each edge in <em>H</em> belongs to <em>E</em> and thus has cost 0 in <em>G</em>′. Thus, <em>H</em> is a tour in <em>G</em>′ with cost 0. Conversely, suppose that graph <em>G</em>′ has a tour <em>H</em>′ of cost at most 0. Since the costs of the edges in <em>E</em>′ are 0 and 1, the cost of tour <em>H</em>′ is exactly 0 and each edge on the tour must have cost 0. Therefore, <em>H</em>′ contains only edges in <em>E</em>. We conclude that <em>H</em>′ is a hamiltonian cycle in graph <em>G</em>.</p>
<p class="right"><span class="font1">▪</span></p>
</section>
<section title="34.5.5 The subset-sum problem">
<p class="level2" id="Sec_34.5.5"><strong>34.5.5    The subset-sum problem</strong></p>
<p class="noindent">We next consider an arithmetic NP-complete problem. The <strong><em><span class="blue">subset-sum problem</span></em></strong> takes as inputs a finite set <em>S</em> of positive integers and an integer <strong><em><span class="blue">target</span></em></strong> <em>t</em> &gt; 0. It asks whether there exists a subset <em>S</em>′ ⊆ <em>S</em> whose elements sum to exactly <em>t</em>. For example, if <em>S</em> = {1, 2, 7, 14, 49, 98, 343, 686, 2409, 2793, 16808, 17206, 117705, 117993} and <em>t</em> = 138457, then the subset <em>S</em>′ = {1, 2, 7, 98, 343, 686, 2409, 17206, 117705} is a solution.</p>
<p>As usual, we express the problem as a language:</p>
<p class="eql">SUBSET-SUM = {<span class="font1"><span class="font1">〈</span></span><em>S</em>, <em>t</em><span class="font1"><span class="font1">〉</span></span> : there exists a subset <em>S</em>′ ⊆ <em>S</em> such that <em>t</em> = Σ<sub><em>s</em>∈<em>S</em>′</sub> <em>S</em>}.</p>
<p class="noindent">As with any arithmetic problem, it is important to recall that our standard encoding assumes that the input integers are coded in binary. With this assumption in mind, we can show that the subset-sum problem is unlikely to have a fast algorithm.</p>
<p class="theo"><strong><em>Theorem 34.15</em></strong></p>
<p class="noindent">The subset-sum problem is NP-complete.</p>
<p class="prof"><strong><em>Proof</em></strong>   To show that SUBSET-SUM ∈ NP, for an instance <span class="font1"><span class="font1">〈</span></span><em>S, t</em><span class="font1"><span class="font1">〉</span></span> of the problem, let the subset <em>S</em>′ be the certificate. A verification algorithm can check whether <em>t</em> = Σ<sub><em>s</em>∈<em>S</em>′</sub> <em>S</em> in polynomial time.</p>
<p>We now show that 3-CNF-SAT ≤<sub>P</sub> SUBSET-SUM. Given a 3-CNF formula <em><span class="symbolfont">ϕ</span></em> over variables <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, … , <em>x<sub>n</sub></em> with clauses <em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, … , <em>C<sub>k</sub></em>, each containing exactly three distinct literals, the reduction algorithm constructs an instance <span class="font1"><span class="font1">〈</span></span><em>S, t</em><span class="font1"><span class="font1">〉</span></span> of the subset-sum problem such that <em><span class="symbolfont">ϕ</span></em> is satisfiable if and only if there exists a subset of <em>S</em> whose sum is exactly <em>t</em>. Without loss of generality, we make two simplifying assumptions about the formula <em><span class="symbolfont">ϕ</span></em>. First, no clause contains both a variable and its negation, for such a clause is automatically satisfied by any assignment of values to the variables. Second, each variable appears in at least one clause, because it does not matter what value is assigned to a variable that appears in no clauses.</p>
<p>The reduction creates two numbers in set <em>S</em> for each variable <em>x<sub>i</sub></em> and two numbers in <em>S</em> for each clause <em>C<sub>j</sub></em>. The numbers will be represented in base 10, with each number containing <em>n</em> + <em>k</em> digits and each digit corresponding to either one variable <a id="p1093"/>or one clause. Base 10 (and other bases, as we shall see) has the property we need of preventing carries from lower digits to higher digits.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_34-19"><img alt="art" src="images/Art_P1480.jpg"/></p>
<p class="caption"><strong>Figure 34.19</strong> The reduction of 3-CNF-SAT to SUBSET-SUM. The formula in 3-CNF is <em><span class="symbolfont">ϕ</span></em> = <em>C</em><sub>1</sub>∧<em>C</em><sub>2</sub>∧<em>C</em><sub>3</sub>∧<em>C</em><sub>4</sub>, where <em>C</em><sub>1</sub> = (<em>x</em><sub>1</sub>∨¬<em>x</em><sub>2</sub>∨¬<em>x</em><sub>3</sub>), <em>C</em><sub>2</sub> = (¬<em>x</em><sub>1</sub>∨¬<em>x</em><sub>2</sub>∨¬<em>x</em><sub>3</sub>), <em>C</em><sub>3</sub> = (¬<em>x</em><sub>1</sub>∨¬<em>x</em><sub>2</sub>∨<em>x</em><sub>3</sub>), and <em>C</em><sub>4</sub> = (<em>x</em><sub>1</sub> ∨ <em>x</em><sub>2</sub> ∨ <em>x</em><sub>3</sub>). A satisfying assignment of <em><span class="symbolfont">ϕ</span></em> is <span class="font1"><span class="font1">〈</span></span><em>x</em><sub>1</sub> = 0, <em>x</em><sub>2</sub> = 0, <em>x</em><sub>3</sub> = 1<span class="font1"><span class="font1">〉</span></span>. The set <em>S</em> produced by the reduction consists of the base-10 numbers shown: reading from top to bottom, <em>S</em> = {1001001, 1000110, 100001, 101110, 10011, 11100, 1000, 2000, 100, 200, 10, 20, 1, 2}. The target <em>t</em> is 1114444. The subset <em>S</em>′ ⊆ <em>S</em> is shaded blue, and it contains <img alt="art" src="images/Art_P1480a.jpg"/>, and <em>v</em><sub>3</sub>, corresponding to the satisfying assignment. Subset <em>S</em>′ also contains slack variables <em>s</em><sub>1</sub>, <img alt="art" src="images/Art_P1480b.jpg"/>, <em>s</em><sub>3</sub>, <em>s</em><sub>4</sub>, and <img alt="art" src="images/Art_P1480c.jpg"/> to achieve the target value of 4 in the digits labeled by <em>C</em><sub>1</sub> through <em>C</em><sub>4</sub>.</p>
</div>
<p>As <a href="chapter034.xhtml#Fig_34-19">Figure 34.19</a> shows, we construct set <em>S</em> and target <em>t</em> as follows. Label each digit position by either a variable or a clause. The least significant <em>k</em> digits are labeled by the clauses, and the most significant <em>n</em> digits are labeled by variables.</p>
<ul class="ulnoindent" epub:type="list">
<li>The target <em>t</em> has a 1 in each digit labeled by a variable and a 4 in each digit labeled by a clause.</li>
<li class="litop">For each variable <em>x<sub>i</sub></em>, set <em>S</em> contains two integers <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/>. Each of <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> has a 1 in the digit labeled by <em>x<sub>i</sub></em> and 0s in the other variable digits. If literal <em>x<sub>i</sub></em> appears in clause <em>C<sub>j</sub></em>, then the digit labeled by <em>C<sub>j</sub></em> in <em>v<sub>i</sub></em> contains a 1. If literal ¬<em>x<sub>i</sub></em> appears in clause <em>C<sub>j</sub></em>, then the digit labeled by <em>C<sub>j</sub></em> in <img alt="art" src="images/Art_P1480d.jpg"/> contains a 1. All other digits labeled by clauses in <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> are 0.<a id="p1094"/>
<p class="noindent1-top">All <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> values in set <em>S</em> are unique. Why? For <em>ℓ</em> ≠ <em>i</em>, no <em>v</em><sub><em>ℓ</em></sub> or <img alt="art" src="images/Art_P1480e.jpg"/> values can equal <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> in the most significant <em>n</em> digits. Furthermore, by our simplifying assumptions above, no <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> can be equal in all <em>k</em> least significant digits. If <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> were equal, then <em>x<sub>i</sub></em> and ¬<em>x<sub>i</sub></em> would have to appear in exactly the same set of clauses. But we assume that no clause contains both <em>x<sub>i</sub></em> and ¬<em>x<sub>i</sub></em> and that either <em>x<sub>i</sub></em> or ¬<em>x<sub>i</sub></em> appears in some clause, and so there must be some clause <em>C<sub>j</sub></em> for which <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> differ.</p>
</li>
<li class="litop">For each clause <em>C<sub>j</sub></em>, set <em>S</em> contains two integers <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/>. Each of <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/> has 0s in all digits other than the one labeled by <em>C<sub>j</sub></em>. For <em>s<sub>j</sub></em>, there is a 1 in the <em>C<sub>j</sub></em> digit, and <img alt="art" src="images/Art_P1480f.jpg"/> has a 2 in this digit. These integers are “slack variables,” which we use to get each clause-labeled digit position to add to the target value of 4.
<p class="noindent1-top">Simple inspection of <a href="chapter034.xhtml#Fig_34-19">Figure 34.19</a> demonstrates that all <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/> values in <em>S</em> are unique in set <em>S</em>.</p>
</li></ul>
<p>The greatest sum of digits in any one digit position is 6, which occurs in the digits labeled by clauses (three 1s from the <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> values, plus 1 and 2 from the <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/> values). Interpreting these numbers in base 10, therefore, no carries can occur from lower digits to higher digits.<sup><a epub:type="footnote" href="#footnote_12" id="footnote_ref_12">12</a></sup></p>
<p>The reduction can be performed in polynomial time. The set <em>S</em> consists of 2<em>n</em> + 2<em>k</em> values, each of which has <em>n</em> + <em>k</em> digits, and the time to produce each digit is polynomial in <em>n</em> + <em>k</em>. The target <em>t</em> has <em>n</em> + <em>k</em> digits, and the reduction produces each in constant time.</p>
<p>Let’s now show that the 3-CNF formula <em><span class="symbolfont">ϕ</span></em> is satisfiable if and only if there exists a subset <em>S</em>′ ⊆ <em>S</em> whose sum is <em>t</em>. First, suppose that <em><span class="symbolfont">ϕ</span></em> has a satisfying assignment. For <em>i</em> = 1, 2, … , <em>n</em>, if <em>x<sub>i</sub></em> = 1 in this assignment, then include <em>v<sub>i</sub></em> in <em>S</em>′. Otherwise, include <img alt="art" src="images/Art_P1480d.jpg"/>. In other words, <em>S</em>′ includes exactly the <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> values that correspond to literals with the value 1 in the satisfying assignment. Having included either <em>v<sub>i</sub></em> or <img alt="art" src="images/Art_P1480d.jpg"/>, but not both, for all <em>i</em>, and having put 0 in the digits labeled by variables in all <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/>, we see that for each variable-labeled digit, the sum of the values of <em>S</em>′ must be 1, which matches those digits of the target <em>t</em>. Because each clause is satisfied, the clause contains some literal with the value 1. Therefore, each digit labeled by a clause has at least one 1 contributed to its sum by a <em>v<sub>i</sub></em> or <img alt="art" src="images/Art_P1480d.jpg"/> value in <em>S</em>′. In fact, one, two, or three literals may be 1 in each clause, and so each clause-labeled digit has a sum of 1, 2, or 3 from the <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> values in <em>S</em>′. In <a href="chapter034.xhtml#Fig_34-19">Figure 34.19</a> for example, literals ¬<em>x</em><sub>1</sub>, ¬<em>x</em><sub>2</sub>, and <em>x</em><sub>3</sub> have the value 1 in a satisfying assignment. Each of clauses <em>C</em><sub>1</sub> and <em>C</em><sub>4</sub> contains exactly one of these literals, and so together <img alt="art" src="images/Art_P1480i.jpg"/>, and <em>v</em><sub>3</sub> contribute 1 to the sum in the digits for <em>C</em><sub>1</sub> and <em>C</em><sub>4</sub>. <a id="p1095"/>Clause <em>C</em><sub>2</sub> contains two of these literals, and <img alt="art" src="images/Art_P1480i.jpg"/>, and <em>v</em><sub>3</sub> contribute 2 to the sum in the digit for <em>C</em><sub>2</sub>. Clause <em>C</em><sub>3</sub> contains all three of these literals, and <img alt="art" src="images/Art_P1480i.jpg"/>, and <em>v</em><sub>3</sub> contribute 3 to the sum in the digit for <em>C</em><sub>3</sub>. To achieve the target of 4 in each digit labeled by clause <em>C<sub>j</sub></em>, include in <em>S</em>′ the appropriate nonempty subset of slack variables {<em>s</em><sub><em>j</em></sub>, <img alt="art" src="images/Art_P1480f.jpg"/> }. In <a href="chapter034.xhtml#Fig_34-19">Figure 34.19</a>, <em>S</em>′ includes <em>s</em><sub>1</sub>, <img alt="art" src="images/Art_P1480b.jpg"/>, <em>s</em><sub>3</sub>, <em>s</em><sub>4</sub>, and <img alt="art" src="images/Art_P1480c.jpg"/>. Since <em>S</em>′ matches the target in all digits of the sum, and no carries can occur, the values of <em>S</em>′ sum to <em>t</em>.</p>
<p>Now suppose that some subset <em>S</em>′ ⊆ <em>S</em> sums to <em>t</em>. The subset <em>S</em>′ must include exactly one of <em>v<sub>i</sub></em> and <img alt="art" src="images/Art_P1480d.jpg"/> for each <em>i</em> = 1, 2, … , <em>n</em>, for otherwise the digits labeled by variables would not sum to 1. If <em>v<sub>i</sub></em> ∈ <em>S</em>′, then set <em>x<sub>i</sub></em> = 1. Otherwise, <img alt="art" src="images/Art_P1480j.jpg"/>, and set <em>x<sub>i</sub></em> = 0. We claim that every clause <em>C<sub>j</sub></em>, for <em>j</em> = 1, 2, … , <em>k</em>, is satisfied by this assignment. To prove this claim, note that to achieve a sum of 4 in the digit labeled by <em>C<sub>j</sub></em>, the subset <em>S</em>′ must include at least one <em>v<sub>i</sub></em> or <img alt="art" src="images/Art_P1480d.jpg"/> value that has a 1 in the digit labeled by <em>C<sub>j</sub></em>, since the contributions of the slack variables <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/> together sum to at most 3. If <em>S</em>′ includes a <img alt="art" src="images/Art_P1480d.jpg"/> that has a 1 in <em>C<sub>j</sub></em>’s position, then the literal <em>x<sub>i</sub></em> appears in clause <em>C<sub>j</sub></em>. Since <em>x<sub>i</sub></em> = 1 when <em>v<sub>i</sub></em> ∈ <em>S</em>′, clause <em>C<sub>j</sub></em> is satisfied. If <em>S</em>′ includes a <img alt="art" src="images/Art_P1480d.jpg"/> that has a 1 in that position, then the literal ¬<em>x<sub>i</sub></em> appears in <em>C<sub>j</sub></em>. Since <em>x<sub>i</sub></em> = 0 when <img alt="art" src="images/Art_P1480d.jpg"/> ∈ <em>S</em>′, clause <em>C<sub>j</sub></em> is again satisfied. Thus, all clauses of <em><span class="symbolfont">ϕ</span></em> are satisfied, which completes the proof.</p>
<p class="right"><span class="font1">▪</span></p>
</section>
<section title="34.5.6 Reduction strategies">
<p class="level2" id="Sec_34.5.6"><strong>34.5.6    Reduction strategies</strong></p>
<p class="noindent">From the reductions in this section, you can see that no single strategy applies to all NP-complete problems. Some reductions are straightforward, such as reducing the hamiltonian-cycle problem to the traveling-salesperson problem. Others are considerably more complicated. Here are a few things to keep in mind and some strategies that you can often bring to bear.</p>
<p class="level4"><strong>Pitfalls</strong></p>
<p class="noindent">Make sure that you don’t get the reduction backward. That is, in trying to show that problem <em>Y</em> is NP-complete, you might take a known NP-complete problem <em>X</em> and give a polynomial-time reduction from <em>Y</em> to <em>X</em>. That is the wrong direction. The reduction should be from <em>X</em> to <em>Y</em>, so that a solution to <em>Y</em> gives a solution to <em>X</em>.</p>
<p>Remember also that reducing a known NP-complete problem <em>X</em> to a problem <em>Y</em> does not in itself prove that <em>Y</em> is NP-complete. It proves that <em>Y</em> is NP-hard. In order to show that <em>Y</em> is NP-complete, you additionally need to prove that it’s in NP by showing how to verify a certificate for <em>Y</em> in polynomial time.</p>
<a id="p1096"/>
<p class="level4"><strong>Go from general to specific</strong></p>
<p class="noindent">When reducing problem <em>X</em> to problem <em>Y</em>, you always have to start with an arbitrary input to problem <em>X</em>. But you are allowed to restrict the input to problem <em>Y</em> as much as you like. For example, when reducing 3-CNF satisfiability to the subset-sum problem, the reduction had to be able to handle <em>any</em> 3-CNF formula as its input, but the input to the subset-sum problem that it produced had a particular structure: 2<em>n</em> + 2<em>k</em> integers in the set, and each integer was formed in a particular way. The reduction did not need to produce <em>every</em> possible input to the subset-sum problem. The point is that one way to solve the 3-CNF satisfiability problem transforms the input into an input to the subset-sum problem and then uses the answer to the subset-sum problem as the answer to the 3-CNF satisfiability problem.</p>
<p class="level4"><strong>Take advantage of structure in the problem you are reducing from</strong></p>
<p class="noindent">When you are choosing a problem to reduce from, you might consider two problems in the same domain, but one problem has more structure than the other. For example, it’s almost always much easier to reduce from 3-CNF satisfiability than to reduce from formula satisfiability. Boolean formulas can be arbitrarily complicated, but you can exploit the structure of 3-CNF formulas when reducing.</p>
<p>Likewise, it is usually more straightforward to reduce from the hamiltonian-cycle problem than from the traveling-salesperson problem, even though they are so similar. That’s because you can view the hamiltonian-cycle problem as taking a complete graph but with edge weights of just 0 or 1, as they would appear in the adjacency matrix. In that sense, the hamiltonian-cycle problem has more structure than the traveling-salesperson problem, in which edge weights are unrestricted.</p>
<p class="level4"><strong>Look for special cases</strong></p>
<p class="noindent">Several NP-complete problems are just special cases of other NP-complete problems. For example, consider the decision version of the 0-1 knapsack problem: given a set of <em>n</em> items, each with a weight and a value, does there exist a subset of items whose total weight is at most a given weight <em>W</em> and whose total value is at least a given value <em>V</em>? You can view the set-partition problem in Exercise 34.5-5 as a special case of the 0-1 knapsack problem: let the value of each item equal its weight, and set both <em>W</em> and <em>V</em> to half the total weight. If problem <em>X</em> is NP-hard and it is a special case of problem <em>Y</em>, then problem <em>Y</em> must be NP-hard as well. That is because a polynomial-time solution for problem <em>Y</em> automatically gives a polynomial-time solution for problem <em>X</em>. More intuitively, problem <em>Y</em>, being more general than problem <em>X</em>, is at least as hard.</p>
<a id="p1097"/>
<p class="level4"><strong>Select an appropriate problem to reduce from</strong></p>
<p class="noindent">It’s often a good strategy to reduce from a problem in a domain that is the same as, or at least related to, the domain of the problem that you’re trying to prove NP-complete. For example, we saw that the vertex-cover problem—a graph problem—was NP-hard by reducing from the clique problem—also a graph problem. From the vertex-cover problem, we reduced to the hamiltonian-cycle problem, and from the hamiltonian-cycle problem, we reduced to the traveling-salesperson problem. All of these problems take undirected graphs as inputs.</p>
<p>Sometimes, however, you will find that is it better to cross over from one domain to another, such as when we reduced from 3-CNF satisfiability to the clique problem or to the subset-sum problem. 3-CNF satisfiability often turns out to be a good choice as a problem to reduce from when crossing domains.</p>
<p>Within graph problems, if you need to select a portion of the graph, without regard to ordering, then the vertex-cover problem is often a good place to start. If ordering matters, then consider starting from the hamiltonian-cycle or hamiltonian-path problem (see Exercise 34.5-6).</p>
<p class="level4"><strong>Make big rewards and big penalties</strong></p>
<p class="noindent">The strategy for reducing the hamiltonian-cycle problem with a graph <em>G</em> to the traveling-salesperson problem encouraged using edges present in <em>G</em> when choosing edges for the traveling-salesperson tour. The reduction did so by giving these edges a low weight: 0. In other words, we gave a big reward for using these edges.</p>
<p>Alternatively, the reduction could have given the edges in <em>G</em> a finite weight and given edges not in <em>G</em> infinite weight, thereby exacting a hefty penalty for using edges not in <em>G</em>. With this approach, if each edge in <em>G</em> has weight <em>W</em>, then the target weight of the traveling-salesperson tour becomes <em>W</em> · |<em>V</em>|. You can sometimes think of the penalties as a way to enforce requirements. For example, if the traveling-salesperson tour includes an edge with infinite weight, then it violates the requirement that the tour should include only edges belonging to <em>G</em>.</p>
<p class="level4"><strong>Design gadgets</strong></p>
<p class="noindent">The reduction from the vertex-cover problem to the hamiltonian-cycle problem uses the gadget shown in <a href="chapter034.xhtml#Fig_34-16">Figure 34.16</a>. This gadget is a subgraph that is connected to other parts of the constructed graph in order to restrict the ways that a cycle can visit each vertex in the gadget once. More generally, a gadget is a component that enforces certain properties. Gadgets can be complicated, as in the reduction to the hamiltonian-cycle problem. Or they can be simple: in the reduction of 3-CNF satisfiability to the subset-sum problem, you can view the slack variables <em>s<sub>j</sub></em> and <img alt="art" src="images/Art_P1480f.jpg"/> <a id="p1098"/>as gadgets enabling each clause-labeled digit position to achieve the target value of 4.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>34.5-1</em></strong></p>
<p class="noindent">The <strong><em><span class="blue">subgraph-isomorphism problem</span></em></strong> takes two undirected graphs <em>G</em><sub>1</sub> and <em>G</em><sub>2</sub>, and asks whether <em>G</em><sub>1</sub> is isomorphic to a subgraph of <em>G</em><sub>2</sub>. Show that the subgraph-isomorphism problem is NP-complete.</p>
<p class="level3"><strong><em>34.5-2</em></strong></p>
<p class="noindent">Given an integer <em>m</em> × <em>n</em> matrix <em>A</em> and an integer <em>m</em>-vector <em>b</em>, the <strong><em><span class="blue">0-1 integer-programming problem</span></em></strong> asks whether there exists an integer <em>n</em>-vector <em>x</em> with elements in the set {0, 1} such that <em>Ax</em> ≤ <em>b</em>. Prove that 0-1 integer programming is NP-complete. (<em>Hint:</em> Reduce from 3-CNF-SAT.)</p>
<p class="level3"><strong><em>34.5-3</em></strong></p>
<p class="noindent">The <strong><em><span class="blue">integer linear-programming problem</span></em></strong> is like the 0-1 integer-programming problem given in Exercise 34.5-2, except that the values of the vector <em>x</em> may be any integers rather than just 0 or 1. Assuming that the 0-1 integer-programming problem is NP-hard, show that the integer linear-programming problem is NP-complete.</p>
<p class="level3"><strong><em>34.5-4</em></strong></p>
<p class="noindent">Show how to solve the subset-sum problem in polynomial time if the target value <em>t</em> is expressed in unary.</p>
<p class="level3"><strong><em>34.5-5</em></strong></p>
<p class="noindent">The <strong><em><span class="blue">set-partition problem</span></em></strong> takes as input a set <em>S</em> of numbers. The question is whether the numbers can be partitioned into two sets <em>A</em> and <em><span class="overline">A</span></em> = <em>S</em> − <em>A</em> such that Σ<sub><em>x</em>∈<em>A</em></sub> <em>x</em> = Σ<sub><em>x</em>∈<em><span class="overline">A</span></em></sub> <em>x</em>. Show that the set-partition problem is NP-complete.</p>
<p class="level3"><strong><em>34.5-6</em></strong></p>
<p class="noindent">Show that the hamiltonian-path problem is NP-complete.</p>
<p class="level3"><strong><em>34.5-7</em></strong></p>
<p class="noindent">The <strong><em><span class="blue">longest-simple-cycle problem</span></em></strong> is the problem of determining a simple cycle (no repeated vertices) of maximum length in a graph. Formulate a related decision problem, and show that the decision problem is NP-complete.</p>
<a id="p1099"/>
<p class="level3"><strong><em>34.5-8</em></strong></p>
<p class="noindent">In the <strong><em><span class="blue">half 3-CNF satisfiability</span></em></strong> problem, the input is a 3-CNF formula <em><span class="symbolfont">ϕ</span></em> with <em>n</em> variables and <em>m</em> clauses, where <em>m</em> is even. The question is whether there exists a truth assignment to the variables of <em><span class="symbolfont">ϕ</span></em> such that exactly half the clauses evaluate to 0 and exactly half the clauses evaluate to 1. Prove that the half 3-CNF satisfiability problem is NP-complete.</p>
<p class="level3"><strong><em>34.5-9</em></strong></p>
<p class="noindent">The proof that VERTEX-COVER ≤<sub>P</sub> HAM-CYCLE assumes that the graph <em>G</em> given as input to the vertex-cover problem has no isolated vertices. Show how the reduction in the proof can break down if <em>G</em> has an isolated vertex.</p>
</section>
</section>
<p class="line1"/>
<section title="Problems">
<p class="level1" id="h1-204"><strong>Problems</strong></p>
<section title="34-1 Independent set">
<p class="level2"><strong><em>34-1     Independent set</em></strong></p>
<p class="noindent">An <strong><em><span class="blue">independent set</span></em></strong> of a graph <em>G</em> = (<em>V</em>, <em>E</em>) is a subset <em>V</em>′ ⊆ <em>V</em> of vertices such that each edge in <em>E</em> is incident on at most one vertex in <em>V</em>′. The <strong><em><span class="blue">independent-set problem</span></em></strong> is to find a maximum-size independent set in <em>G</em>.</p>
<p class="nl"><strong><em>a.</em></strong> Formulate a related decision problem for the independent-set problem, and prove that it is NP-complete. (<em>Hint:</em> Reduce from the clique problem.)</p>
<p class="nl"><strong><em>b.</em></strong> You are given a “black-box” subroutine to solve the decision problem you defined in part (a). Give an algorithm to find an independent set of maximum size. The running time of your algorithm should be polynomial in |<em>V</em> | and |<em>E</em>|, counting queries to the black box as a single step.</p>
<p class="noindent1-top">Although the independent-set decision problem is NP-complete, certain special cases are polynomial-time solvable.</p>
<p class="nl"><strong><em>c.</em></strong> Give an efficient algorithm to solve the independent-set problem when each vertex in <em>G</em> has degree 2. Analyze the running time, and prove that your algorithm works correctly.</p>
<p class="nl"><strong><em>d.</em></strong> Give an efficient algorithm to solve the independent-set problem when <em>G</em> is bipartite. Analyze the running time, and prove that your algorithm works correctly. (<em>Hint:</em> First prove that in a bipartite graph, the size of the maximimum independent set plus the size of the maximum matching is equal to |<em>V</em>|. Then use a maximum-matching algorithm (see <a href="chapter025.xhtml#Sec_25.1">Section 25.1</a>) as a first step in an algorithm to find an independent set.)</p>
<a id="p1100"/>
</section>
<section title="34-2 Bonnie and Clyde">
<p class="level2"><strong><em>34-2     Bonnie and Clyde</em></strong></p>
<p class="noindent">Bonnie and Clyde have just robbed a bank. They have a bag of money and want to divide it up. For each of the following scenarios, either give a polynomial-time algorithm to divide the money or prove that the problem of dividing the money in the manner described is NP-complete. The input in each case is a list of the <em>n</em> items in the bag, along with the value of each.</p>
<p class="nl"><strong><em>a.</em></strong> The bag contains <em>n</em> coins, but only two different denominations: some coins are worth <em>x</em> dollars, and some are worth <em>y</em> dollars. Bonnie and Clyde wish to divide the money exactly evenly.</p>
<p class="nl"><strong><em>b.</em></strong> The bag contains <em>n</em> coins, with an arbitrary number of different denominations, but each denomination is a nonnegative exact power of 2, so that the possible denominations are 1 dollar, 2 dollars, 4 dollars, etc. Bonnie and Clyde wish to divide the money exactly evenly.</p>
<p class="nl"><strong><em>c.</em></strong> The bag contains <em>n</em> checks, which are, in an amazing coincidence, made out to “Bonnie or Clyde.” They wish to divide the checks so that they each get the exact same amount of money.</p>
<p class="nl"><strong><em>d.</em></strong> The bag contains <em>n</em> checks as in part (c), but this time Bonnie and Clyde are willing to accept a split in which the difference is no larger than 100 dollars.</p>
</section>
<section title="34-3 Graph coloring">
<p class="level2"><strong><em>34-3     Graph coloring</em></strong></p>
<p class="noindent">Mapmakers try to use as few colors as possible when coloring countries on a map, subject to the restriction that if two countries share a border, they must have different colors. You can model this problem with an undirected graph <em>G</em> = (<em>V</em>, <em>E</em>) in which each vertex represents a country and vertices whose respective countries share a border are adjacent. Then, a <strong><em><span class="blue">k-coloring</span></em></strong> is a function <em>c</em> : <em>V</em> → {1, 2, … , <em>k</em>} such that <em>c</em>(<em>u</em>) ≠ <em>c</em>(<em>v</em>) for every edge (<em>u</em>, <em>v</em>) ∈ <em>E</em>. In other words, the numbers 1, 2, … , <em>k</em> represent the <em>k</em> colors, and adjacent vertices must have different colors. The <strong><em><span class="blue">graph-coloring problem</span></em></strong> is to determine the minimum number of colors needed to color a given graph.</p>
<p class="nl"><strong><em>a.</em></strong> Give an efficient algorithm to determine a 2-coloring of a graph, if one exists.</p>
<p class="nl"><strong><em>b.</em></strong> Cast the graph-coloring problem as a decision problem. Show that your decision problem is solvable in polynomial time if and only if the graph-coloring problem is solvable in polynomial time.</p>
<p class="nl"><strong><em>c.</em></strong> Let the language 3-COLOR be the set of graphs that can be 3-colored. Show that if 3-COLOR is NP-complete, then your decision problem from part (b) is NP-complete.</p>
<a id="p1101"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-20"><img alt="art" src="images/Art_P1481.jpg"/></p>
<p class="caption"><strong>Figure 34.20</strong> The subgraph of <em>G</em> in Problem 34-3 formed by the literal edges. The special vertices <small>TRUE</small>, <small>FALSE</small>, and <small>RED</small> form a triangle, and for each variable <em>x<sub>i</sub></em>, the vertices <em>x<sub>i</sub></em>, ¬<em>x<sub>i</sub></em>, and <small>RED</small> form a triangle.</p>
</div>
<p class="block"/>
<div class="divimage">
<p class="fig-imga" id="Fig_34-21"><img alt="art" src="images/Art_P1482.jpg"/></p>
<p class="caption"><strong>Figure 34.21</strong> The gadget corresponding to a clause (<em>x</em> ∨ <em>y</em> ∨ <em>z</em>), used in Problem 34-3.</p>
</div>
<p class="noindent">To prove that 3-COLOR is NP-complete, you can reduce from 3-CNF-SAT. Given a formula <em><span class="symbolfont">ϕ</span></em> of <em>m</em> clauses on <em>n</em> variables <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, … , <em>x<sub>n</sub></em>, construct a graph <em>G</em> = (<em>V</em>, <em>E</em>) as follows. The set <em>V</em> consists of a vertex for each variable, a vertex for the negation of each variable, five vertices for each clause, and three special vertices: <small>TRUE</small>, <small>FALSE</small>, and <small>RED</small>. The edges of the graph are of two types: “literal” edges that are independent of the clauses and “clause” edges that depend on the clauses. As <a href="chapter034.xhtml#Fig_34-20">Figure 34.20</a> shows, the literal edges form a triangle on the three special vertices <small>TRUE</small>, <small>FALSE</small>, and <small>RED</small>, and they also form a triangle on <em>x<sub>i</sub></em>, ¬<em>x<sub>i</sub></em>, and <small>RED</small> for <em>i</em> = 1, 2, … , <em>n</em>.</p>
<p class="nl"><strong><em>d.</em></strong> Consider a graph containing the literal edges. Argue that in any 3-coloring <em>c</em> of such a graph, exactly one of a variable and its negation is colored <em>c</em>(<small>TRUE</small>) and the other is colored <em>c</em>(<small>FALSE</small>). Then argue that for any truth assignment for <em><span class="symbolfont">ϕ</span></em>, there exists a 3-coloring of the graph containing just the literal edges.</p>
<p class="noindent1-top">The gadget shown in <a href="chapter034.xhtml#Fig_34-21">Figure 34.21</a> helps to enforce the condition corresponding to a clause (<em>x</em> ∨ <em>y</em> ∨ <em>z</em>), where <em>x</em>, <em>y</em>, and <em>z</em> are literals. Each clause requires a unique copy of the five blue vertices in the figure. They connect as shown to the literals of the clause and the special vertex <small>TRUE</small>.</p>
<a id="p1102"/>
<p class="nl"><strong><em>e.</em></strong> Argue that if each of <em>x</em>, <em>y</em>, and <em>z</em> is colored <em>c</em>(<small>TRUE</small>) or <em>c</em>(<small>FALSE</small>), then the gadget is 3-colorable if and only if at least one of <em>x</em>, <em>y</em>, or <em>z</em> is colored <em>c</em>(<small>TRUE</small>).</p>
<p class="nl"><strong><em>f.</em></strong> Complete the proof that 3-COLOR is NP-complete.</p>
</section>
<section title="34-4 Scheduling with profits and deadlines">
<p class="level2"><strong><em>34-4     Scheduling with profits and deadlines</em></strong></p>
<p class="noindent">You have one computer and a set of <em>n</em> tasks {<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, … , <em>a<sub>n</sub></em>} requiring time on the computer. Each task <em>a<sub>j</sub></em> requires <em>t<sub>j</sub></em> time units on the computer (its processing time), yields a profit of <em>p<sub>j</sub></em>, and has a deadline <em>d<sub>j</sub></em>. The computer can process only one task at a time, and task <em>a<sub>j</sub></em> must run without interruption for <em>t<sub>j</sub></em> consecutive time units. If task <em>a<sub>j</sub></em> completes by its deadline <em>d<sub>j</sub></em>, you receive a profit <em>p<sub>j</sub></em>. If instead task <em>a<sub>j</sub></em> completes after its deadline, you receive no profit. As an optimization problem, given the processing times, profits, and deadlines for a set of <em>n</em> tasks, you wish to find a schedule that completes all the tasks and returns the greatest amount of profit. The processing times, profits, and deadlines are all nonnegative numbers.</p>
<p class="nl"><strong><em>a.</em></strong> State this problem as a decision problem.</p>
<p class="nl"><strong><em>b.</em></strong> Show that the decision problem is NP-complete.</p>
<p class="nl"><strong><em>c.</em></strong> Give a polynomial-time algorithm for the decision problem, assuming that all processing times are integers from 1 to <em>n</em>. (<em>Hint:</em> Use dynamic programming.)</p>
<p class="nl"><strong><em>d.</em></strong> Give a polynomial-time algorithm for the optimization problem, assuming that all processing times are integers from 1 to <em>n</em>.</p>
</section>
</section>
<p class="line1"/>
<section title="Chapter notes">
<p class="level1" id="h1-205"><strong>Chapter notes</strong></p>
<p class="noindent">The book by Garey and Johnson [<a epub:type="noteref" href="bibliography001.xhtml#endnote_176">176</a>] provides a wonderful guide to NP-completeness, discussing the theory at length and providing a catalogue of many problems that were known to be NP-complete in 1979. The proof of Theorem 34.13 is adapted from their book, and the list of NP-complete problem domains at the beginning of <a href="chapter034.xhtml#Sec_34.5">Section 34.5</a> is drawn from their table of contents. Johnson wrote a series of 23 columns in the <em>Journal of Algorithms</em> between 1981 and 1992 reporting new developments in NP-completeness. Fortnow’s book [<a epub:type="noteref" href="bibliography001.xhtml#endnote_152">152</a>] gives a history of NP-completeness, along with societal implications. Hopcroft, Motwani, and Ullman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_225">225</a>], Lewis and Papadimitriou [<a epub:type="noteref" href="bibliography001.xhtml#endnote_299">299</a>], Papadimitriou [<a epub:type="noteref" href="bibliography001.xhtml#endnote_352">352</a>], and Sipser [<a epub:type="noteref" href="bibliography001.xhtml#endnote_413">413</a>] have good treatments of NP-completeness in the context of complexity theory. NP-completeness and several reductions also appear in books by Aho, Hopcroft, and Ullman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_5">5</a>], Dasgupta, Papadimitriou, and Vazirani [<a epub:type="noteref" href="bibliography001.xhtml#endnote_107">107</a>], Johnsonbaugh and <a id="p1103"/>Schaefer [<a epub:type="noteref" href="bibliography001.xhtml#endnote_239">239</a>], and Kleinberg and Tardos [<a epub:type="noteref" href="bibliography001.xhtml#endnote_257">257</a>]. The book by Hromkovič [<a epub:type="noteref" href="bibliography001.xhtml#endnote_229">229</a>] studies various methods for solving hard problems.</p>
<p>The class P was introduced in 1964 by Cobham [<a epub:type="noteref" href="bibliography001.xhtml#endnote_96">96</a>] and, independently, in 1965 by Edmonds [<a epub:type="noteref" href="bibliography001.xhtml#endnote_130">130</a>], who also introduced the class NP and conjectured that P ≠ NP. The notion of NP-completeness was proposed in 1971 by Cook [<a epub:type="noteref" href="bibliography001.xhtml#endnote_100">100</a>], who gave the first NP-completeness proofs for formula satisfiability and 3-CNF satisfiability. Levin [<a epub:type="noteref" href="bibliography001.xhtml#endnote_297">297</a>] independently discovered the notion, giving an NP-completeness proof for a tiling problem. Karp [<a epub:type="noteref" href="bibliography001.xhtml#endnote_248">248</a>] introduced the methodology of reductions in 1972 and demonstrated the rich variety of NP-complete problems. Karp’s paper included the original NP-completeness proofs of the clique, vertex-cover, and hamiltonian-cycle problems. Since then, thousands of problems have been proven to be NP-complete by many researchers.</p>
<p>Work in complexity theory has shed light on the complexity of computing approximate solutions. This work gives a new definition of NP using “probabilistically checkable proofs.” This new definition implies that for problems such as clique, vertex cover, the traveling-salesperson problem with the triangle inequality, and many others, computing good approximate solutions (see <a href="chapter035.xhtml">Chapter 35</a>) is NP-hard and hence no easier than computing optimal solutions. An introduction to this area can be found in Arora’s thesis [<a epub:type="noteref" href="bibliography001.xhtml#endnote_21">21</a>], a chapter by Arora and Lund in Hochbaum [<a epub:type="noteref" href="bibliography001.xhtml#endnote_221">221</a>], a survey article by Arora [<a epub:type="noteref" href="bibliography001.xhtml#endnote_22">22</a>], a book edited by Mayr, Prömel, and Steger [<a epub:type="noteref" href="bibliography001.xhtml#endnote_319">319</a>], a survey article by Johnson [<a epub:type="noteref" href="bibliography001.xhtml#endnote_237">237</a>], and a chapter in the textbook by Arora and Barak [<a epub:type="noteref" href="bibliography001.xhtml#endnote_24">24</a>].</p>
<p class="footnote" id="footnote_1"><a href="#footnote_ref_1"><sup>1</sup></a> For the Halting Problem and other unsolvable problems, there are proofs that no algorithm can exist that, for every input, eventually produces the correct answer. A procedure attempting to solve an unsolvable problem might always produce an answer but is sometimes incorrect, or all the answers it produces might be correct but for some inputs it never produces an answer.</p>
<p class="footnote1" id="footnote_2"><a href="#footnote_ref_2"><sup>2</sup></a> See the books by Hopcroft and Ullman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_228">228</a>], Lewis and Papadimitriou [<a epub:type="noteref" href="bibliography001.xhtml#endnote_299">299</a>], or Sipser [<a epub:type="noteref" href="bibliography001.xhtml#endnote_413">413</a>] for a thorough treatment of the Turing-machine model.</p>
<p class="footnote1" id="footnote_3"><a href="#footnote_ref_3"><sup>3</sup></a> The codomain of <em>e</em> need not be <em>binary</em> strings: any set of strings over a finite alphabet having at least two symbols will do.</p>
<p class="footnote1" id="footnote_4"><a href="#footnote_ref_4"><sup>4</sup></a> We assume that the algorithm’s output is separate from its input. Because it takes at least one time step to produce each bit of the output and the algorithm takes <em>O</em>(<em>T</em> (<em>n</em>)) time steps, the size of the output is <em>O</em>(<em>T</em> (<em>n</em>)).</p>
<p class="footnote1" id="footnote_5"><a href="#footnote_ref_5"><sup>5</sup></a> The notation {0, 1}* denotes the set of all strings composed of symbols from the set {0, 1}.</p>
<p class="footnote1" id="footnote_6"><a href="#footnote_ref_6"><sup>6</sup></a> Technically, we also require the functions <em>f</em><sub>12</sub> and <em>f</em><sub>21</sub> to “map noninstances to noninstances.” A <strong><em><span class="blue">noninstance</span></em></strong> of an encoding <em>e</em> is a string <em>x</em> ∈ {0, 1}* such that there is no instance <em>i</em> for which <em>e</em>(<em>i</em>) = <em>x</em>. We require that <em>f</em><sub>12</sub>(<em>x</em>) = <em>y</em> for every noninstance <em>x</em> of encoding <em>e</em><sub>1</sub>, where <em>y</em> is some noninstance of <em>e</em><sub>2</sub>, and that <em>f</em><sub>21</sub>(<em>x</em>′) = <em>y</em>′ for every noninstance <em>x</em>′ of <em>e</em><sub>2</sub>, where <em>y</em>′ is some noninstance of <em>e</em><sub>1</sub>.</p>
<p class="footnote1" id="footnote_7"><a href="#footnote_ref_7"><sup>7</sup></a> For more on complexity classes, see the seminal paper by Hartmanis and Stearns [<a epub:type="noteref" href="bibliography001.xhtml#endnote_210">210</a>].</p>
<p class="footnote1" id="footnote_8"><a href="#footnote_ref_8"><sup>8</sup></a> In a letter dated 17 October 1856 to his friend John T. Graves, Hamilton [<a epub:type="noteref" href="bibliography001.xhtml#endnote_206">206</a>, p. 624] wrote, “I have found that some young persons have been much amused by trying a new mathematical game which the Icosion furnishes, one person sticking five pins in any five consecutive points … and the other player then aiming to insert, which by the theory in this letter can always be done, fifteen other pins, in cyclical succession, so as to cover all the other points, and to end in immediate proximity to the pin wherewith his antagonist had begun.”</p>
<p class="footnote1" id="footnote_9"><a href="#footnote_ref_9"><sup>9</sup></a> The name “NP” stands for “nondeterministic polynomial time.” The class NP was originally studied in the context of nondeterminism, but this book uses the somewhat simpler yet equivalent notion of verification. Hopcroft and Ullman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_228">228</a>] give a good presentation of NP-completeness in terms of nondeterministic models of computation.</p>
<p class="footnote1" id="footnote_10"><a href="#footnote_ref_10"><sup>10</sup></a> On the other hand, if the size of the circuit <em>C</em> is Θ(2<sup><em>k</em></sup>), then an algorithm whose running time is <em>O</em>(2<sup><em>k</em></sup>) has a running time that is polynomial in the circuit size. Even if P ≠ NP, this situation would not contradict the NP-completeness of the problem. The existence of a polynomial-time algorithm for a special case does not imply that there is a polynomial-time algorithm for all cases.</p>
<p class="footnote1" id="footnote_11"><a href="#footnote_ref_11"><sup>11</sup></a> Technically, a cycle is defined as a sequence of vertices rather than edges (see <a href="appendix002.xhtml#Sec_B.4">Section B.4</a>). In the interest of clarity, we abuse notation here and define the hamiltonian cycle by its edges.</p>
<p class="footnote1" id="footnote_12"><a href="#footnote_ref_12"><sup>12</sup></a> In fact, any base <em>b</em> ≥ 7 works. The instance at the beginning of this subsection is the set <em>S</em> and target <em>t</em> in <a href="chapter034.xhtml#Fig_34-19">Figure 34.19</a> interpreted in base 7, with <em>S</em> listed in sorted order.</p>
</section>
</section>
</div>
</body>
</html>