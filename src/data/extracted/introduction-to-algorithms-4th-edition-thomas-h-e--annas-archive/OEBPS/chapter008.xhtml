<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"/>
<title>Introduction to Algorithms</title>
<link href="css/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4a9ccac5-f2db-4081-af1f-a5a376b433e1" name="Adept.expected.resource"/>
</head>
<body>
<div class="body"><a id="p205"/>
<p class="line-c"/>
<section epub:type="bodymatter chapter" title="8 Sorting in Linear Time">
<p class="chapter-title"><a href="toc.xhtml#chap-8"><strong><span class="blue1">8          Sorting in Linear Time</span></strong></a></p>
<p class="noindent">We have now seen a handful of algorithms that can sort <em>n</em> numbers in <em>O</em>(<em>n</em> lg <em>n</em>) time. Whereas merge sort and heapsort achieve this upper bound in the worst case, quicksort achieves it on average. Moreover, for each of these algorithms, we can produce a sequence of <em>n</em> input numbers that causes the algorithm to run in Ω(<em>n</em> lg <em>n</em>) time.</p>
<p>These algorithms share an interesting property: <em>the sorted order they determine is based only on comparisons between the input elements</em>. We call such sorting algorithms <strong><em><span class="blue1">comparison sorts</span></em></strong>. All the sorting algorithms introduced thus far are comparison sorts.</p>
<p>In <a href="chapter008.xhtml#Sec_8.1">Section 8.1</a>, we’ll prove that any comparison sort must make Ω(<em>n</em> lg <em>n</em>) comparisons in the worst case to sort <em>n</em> elements. Thus, merge sort and heapsort are asymptotically optimal, and no comparison sort exists that is faster by more than a constant factor.</p>
<p><a href="chapter008.xhtml#Sec_8.2">Sections 8.2</a>, <a href="chapter008.xhtml#Sec_8.3">8.3</a>, and <a href="chapter008.xhtml#Sec_8.4">8.4</a> examine three sorting algorithms—counting sort, radix sort, and bucket sort—that run in linear time on certain types of inputs. Of course, these algorithms use operations other than comparisons to determine the sorted order. Consequently, the Ω(<em>n</em> lg <em>n</em>) lower bound does not apply to them.</p>
<p class="line1"/>
<section title="8.1 Lower bounds for sorting">
<a id="Sec_8.1"/>
<p class="level1" id="h1-45"><a href="toc.xhtml#Rh1-45"><strong>8.1      Lower bounds for sorting</strong></a></p>
<p class="noindent">A comparison sort uses only comparisons between elements to gain order information about an input sequence <span class="font1">〈</span><em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, … , <em>a<sub>n</sub></em><span class="font1">〉</span>. That is, given two elements <em>a<sub>i</sub></em> and <em>a<sub>j</sub></em>, it performs one of the tests <em>a<sub>i</sub></em> &lt; <em>a<sub>j</sub></em>, <em>a<sub>i</sub></em> ≤ <em>a<sub>j</sub></em>, <em>a<sub>i</sub></em> = <em>a<sub>j</sub></em>, <em>a<sub>i</sub></em> ≥ <em>a<sub>j</sub></em>, or <em>a<sub>i</sub></em> &gt; <em>a<sub>j</sub></em> to determine their relative order. It may not inspect the values of the elements or gain order information about them in any other way.</p>
<p>Since we are proving a lower bound, we assume without loss of generality in this section that all the input elements are distinct. After all, a lower bound for distinct elements applies when elements may or may not be distinct. Consequently, <a id="p206"/>comparisons of the form <em>a<sub>i</sub></em> = <em>a<sub>j</sub></em> are useless, which means that we can assume that no comparisons for exact equality occur. Moreover, the comparisons <em>a<sub>i</sub></em> ≤ <em>a<sub>j</sub></em>, <em>a<sub>i</sub></em> ≥ <em>a<sub>j</sub></em>, <em>a<sub>i</sub></em> &gt; <em>a<sub>j</sub></em>, and <em>a<sub>i</sub></em> &lt; <em>a<sub>j</sub></em> are all equivalent in that they yield identical information about the relative order of <em>a<sub>i</sub></em> and <em>a<sub>j</sub></em>. We therefore assume that all comparisons have the form <em>a<sub>i</sub></em> ≤ <em>a<sub>j</sub></em>.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_8-1"><img alt="art" src="images/Art_P323.jpg"/></p>
<p class="caption"><strong>Figure 8.1</strong> The decision tree for insertion sort operating on three elements. An internal node (shown in blue) annotated by <em>i</em> : <em>j</em> indicates a comparison between <em>a<sub>i</sub></em> and <em>a<sub>j</sub></em>. A leaf annotated by the permutation <span class="font1">〈</span><em>π</em>(1), <em>π</em>(2), … , <em>π</em>(<em>n</em>)<span class="font1">〉</span> indicates the ordering <em>a</em><sub><em>π</em>(1)</sub> ≤ <em>a</em><sub><em>π</em>(2)</sub> ≤ <span class="font1">⋯</span> ≤ <em>a</em><sub><em>π</em>(<em>n</em>)</sub>. The highlighted path indicates the decisions made when sorting the input sequence <span class="font1">〈</span><em>a</em><sub>1</sub> = 6, <em>a</em><sub>2</sub> = 8, <em>a</em><sub>3</sub> = 5<span class="font1">〉</span>. Going left from the root node, labeled 1:2, indicates that <em>a</em><sub>1</sub> ≤ <em>a</em><sub>2</sub>. Going right from the node labeled 2:3 indicates that <em>a</em><sub>2</sub> &gt; <em>a</em><sub>3</sub>. Going right from the node labeled 1:3 indicates that <em>a</em><sub>1</sub> &gt; <em>a</em><sub>3</sub>. Therefore, we have the ordering <em>a</em><sub>3</sub> ≤ <em>a</em><sub>1</sub> ≤ <em>a</em><sub>2</sub>, as indicated in the leaf labeled <span class="font1">〈</span>3, 1, 2<span class="font1">〉</span>. Because the three input elements have 3! = 6 possible permutations, the decision tree must have at least 6 leaves.</p>
</div>
<p class="level4"><strong>The decision-tree model</strong></p>
<p class="noindent">We can view comparison sorts abstractly in terms of decision trees. A <strong><em><span class="blue1">decision tree</span></em></strong> is a full binary tree (each node is either a leaf or has both children) that represents the comparisons between elements that are performed by a particular sorting algorithm operating on an input of a given size. Control, data movement, and all other aspects of the algorithm are ignored. <a href="chapter008.xhtml#Fig_8-1">Figure 8.1</a> shows the decision tree corresponding to the insertion sort algorithm from <a href="chapter002.xhtml#Sec_2.1">Section 2.1</a> operating on an input sequence of three elements.</p>
<p>A decision tree has each internal node annotated by <em>i</em> : <em>j</em> for some <em>i</em> and <em>j</em> in the range 1 ≤ <em>i</em>, <em>j</em> ≤ <em>n</em>, where <em>n</em> is the number of elements in the input sequence. We also annotate each leaf by a permutation <span class="font1">〈</span><em>π</em>(1), <em>π</em>(2), … , <em>π</em>(<em>n</em>)<span class="font1">〉</span>. (See <a href="appendix003.xhtml#Sec_C.1">Section C.1</a> for background on permutations.) Indices in the internal nodes and the leaves always refer to the original positions of the array elements at the start of the sorting algorithm. The execution of the comparison sorting algorithm corresponds to tracing a simple path from the root of the decision tree down to a leaf. Each internal node indicates a comparison <em>a<sub>i</sub></em> ≤ <em>a<sub>j</sub></em>. The left subtree then dictates subsequent <a id="p207"/>comparisons once we know that <em>a<sub>i</sub></em> ≤ <em>a<sub>j</sub></em>, and the right subtree dictates subsequent comparisons when <em>a<sub>i</sub></em> &gt; <em>a<sub>j</sub></em>. Arriving at a leaf, the sorting algorithm has established the ordering <em>a</em><sub><em>π</em>(1)</sub> ≤ <em>a</em><sub><em>π</em>(2)</sub> ≤ <span class="font1">⋯</span> ≤ <em>a</em><sub><em>π</em>(<em>n</em>)</sub>. Because any correct sorting algorithm must be able to produce each permutation of its input, each of the <em>n</em>! permutations on <em>n</em> elements must appear as at least one of the leaves of the decision tree for a comparison sort to be correct. Furthermore, each of these leaves must be reachable from the root by a downward path corresponding to an actual execution of the comparison sort. (We call such leaves “reachable.”) Thus, we consider only decision trees in which each permutation appears as a reachable leaf.</p>
<p class="level4"><strong>A lower bound for the worst case</strong></p>
<p class="noindent">The length of the longest simple path from the root of a decision tree to any of its reachable leaves represents the worst-case number of comparisons that the corresponding sorting algorithm performs. Consequently, the worst-case number of comparisons for a given comparison sort algorithm equals the height of its decision tree. A lower bound on the heights of all decision trees in which each permutation appears as a reachable leaf is therefore a lower bound on the running time of any comparison sort algorithm. The following theorem establishes such a lower bound.</p>
<p class="theo"><strong><em>Theorem 8.1</em></strong></p>
<p class="noindent">Any comparison sort algorithm requires Ω(<em>n</em> lg <em>n</em>) comparisons in the worst case.</p>
<p class="proof"><strong><em>Proof</em></strong>   From the preceding discussion, it suffices to determine the height of a decision tree in which each permutation appears as a reachable leaf. Consider a decision tree of height <em>h</em> with <em>l</em> reachable leaves corresponding to a comparison sort on <em>n</em> elements. Because each of the <em>n</em>! permutations of the input appears as one or more leaves, we have <em>n</em>! ≤ <em>l</em>. Since a binary tree of height <em>h</em> has no more than 2<em><sup>h</sup></em> leaves, we have</p>
<p class="eql"><em>n</em>! ≤ <em>l</em> ≤ 2<em><sup>h</sup></em>,</p>
<p class="noindent">which, by taking logarithms, implies</p>
<table class="table2b">
<tr>
<td class="td2"><em>h</em></td>
<td class="td2">≥</td>
<td class="td2">lg(<em>n</em>!)</td>
<td class="td2">(since the lg function is monotonically increasing)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2m">=</td>
<td class="td2">Ω (<em>n</em> lg <em>n</em>)</td>
<td class="td2">(by equation (3.28) on page 67).</td>
</tr>
</table>
<p class="right"><span class="font1">▪</span></p>
<p class="cor"><strong><em>Corollary 8.2</em></strong></p>
<p class="noindent">Heapsort and merge sort are asymptotically optimal comparison sorts.</p>
<p class="proof"><strong><em>Proof</em></strong>   The <em>O</em>(<em>n</em> lg <em>n</em>) upper bounds on the running times for heapsort and merge sort match the Ω(<em>n</em> lg <em>n</em>) worst-case lower bound from Theorem 8.1.</p>
<p class="right"><span class="font1">▪</span></p>
<a id="p208"/>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>8.1-1</em></strong></p>
<p class="noindent">What is the smallest possible depth of a leaf in a decision tree for a comparison sort?</p>
<p class="level3"><strong><em>8.1-2</em></strong></p>
<p class="noindent">Obtain asymptotically tight bounds on lg(<em>n</em>!) without using Stirling’s approximation. Instead, evaluate the summation <img alt="art" src="images/Art_P324.jpg"/> using techniques from <a href="appendix001.xhtml#Sec_A.2">Section A.2</a>.</p>
<p class="level3"><strong><em>8.1-3</em></strong></p>
<p class="noindent">Show that there is no comparison sort whose running time is linear for at least half of the <em>n</em>! inputs of length <em>n</em>. What about a fraction of 1/<em>n</em> of the inputs of length <em>n</em>? What about a fraction 1/2<em><sup>n</sup></em>?</p>
<p class="level3"><strong><em>8.1-4</em></strong></p>
<p class="noindent">You are given an <em>n</em>-element input sequence, and you know in advance that it is partly sorted in the following sense. Each element initially in position <em>i</em> such that <em>i</em> mod 4 = 0 is either already in its correct position, or it is one place away from its correct position. For example, you know that after sorting, the element initially in position 12 belongs in position 11, 12, or 13. You have no advance information about the other elements, in positions <em>i</em> where <em>i</em> mod 4 ≠ 0. Show that an Ω(<em>n</em> lg <em>n</em>) lower bound on comparison-based sorting still holds in this case.</p>
</section>
<p class="line1"/>
<section title="8.2 Counting sort">
<a id="Sec_8.2"/>
<p class="level1" id="h1-46"><a href="toc.xhtml#Rh1-46"><strong>8.2      Counting sort</strong></a></p>
<p class="noindent"><strong><em><span class="blue1">Counting sort</span></em></strong> assumes that each of the <em>n</em> input elements is an integer in the range 0 to <em>k</em>, for some integer <em>k</em>. It runs in Θ(<em>n</em> + <em>k</em>) time, so that when <em>k</em> = <em>O</em>(<em>n</em>), counting sort runs in Θ(<em>n</em>) time.</p>
<p>Counting sort first determines, for each input element <em>x</em>, the number of elements less than or equal to <em>x</em>. It then uses this information to place element <em>x</em> directly into its position in the output array. For example, if 17 elements are less than or equal to <em>x</em>, then <em>x</em> belongs in output position 17. We must modify this scheme slightly to handle the situation in which several elements have the same value, since we do not want them all to end up in the same position.</p>
<p>The C<small>OUNTING</small>-S<small>ORT</small> procedure on the facing page takes as input an array <em>A</em>[1 : <em>n</em>], the size <em>n</em> of this array, and the limit <em>k</em> on the nonnegative integer values in <em>A</em>. It returns its sorted output in the array <em>B</em>[1 : <em>n</em>] and uses an array <em>C</em> [0 : <em>k</em>] for temporary working storage.</p>
<a id="p209"/>
<div class="pull-quote1">
<p class="box-heading">C<small>OUNTING</small>-S<small>ORT</small>(<em>A</em>, <em>n</em>, <em>k</em>)</p>
<table class="table1a1">
<tr>
<td class="td1w"><span class="x-small">  1</span></td>
<td class="td1"><p class="noindent">let <em>B</em>[1 : <em>n</em>] and <em>C</em> [0 : <em>k</em>] be new arrays</p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  2</span></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 0 <strong>to</strong> <em>k</em></p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  3</span></td>
<td class="td1"><p class="p2"><em>C</em> [<em>i</em>] = 0</p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  4</span></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  5</span></td>
<td class="td1"><p class="p2"><em>C</em> [<em>A</em>[<em>j</em>]] = <em>C</em> [<em>A</em>[<em>j</em>]] + 1</p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  6</span></td>
<td class="td1" colspan="2">
<p class="noindent"><span class="red"><strong>//</strong> <em>C</em> [<em>i</em>] now contains the number of elements equal to <em>i</em>.</span></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  7</span></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>k</em></p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  8</span></td>
<td class="td1"><p class="p2"><em>C</em> [<em>i</em>] = <em>C</em> [<em>i</em>] + <em>C</em> [<em>i</em> – 1]</p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">  9</span></td>
<td class="td1" colspan="2">
<p class="noindent"><span class="red"><strong>//</strong> <em>C</em> [<em>i</em>] now contains the number of elements less than or equal to <em>i</em>.</span></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">10</span></td>
<td class="td1" colspan="2">
<p class="noindent"><span class="red"><strong>//</strong> Copy <em>A</em> to <em>B</em>, starting from the end of <em>A</em>.</span></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">11</span></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>j</em> = <em>n</em> <strong>downto</strong> 1</p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">12</span></td>
<td class="td1"><p class="p2"><em>B</em>[<em>C</em> [<em>A</em>[<em>j</em>]]] = <em>A</em>[<em>j</em>]</p></td>
<td class="td1"/>
</tr>
<tr>
<td class="td1"><span class="x-small">13</span></td>
<td class="td1"><p class="p2"><em>C</em> [<em>A</em>[<em>j</em>]] = <em>C</em> [<em>A</em>[<em>j</em>]] – 1</p></td>
<td class="td1"><p class="noindent"><span class="red"><strong>//</strong> to handle duplicate values</span></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">14</span></td>
<td class="td1"><p class="noindent"><strong>return</strong> <em>B</em></p></td>
<td class="td1"/>
</tr>
</table>
</div>
<p><a href="chapter008.xhtml#Fig_8-2">Figure 8.2</a> illustrates counting sort. After the <strong>for</strong> loop of lines 2–3 initializes the array <em>C</em> to all zeros, the <strong>for</strong> loop of lines 4–5 makes a pass over the array <em>A</em> to inspect each input element. Each time it finds an input element whose value is <em>i</em>, it increments <em>C</em> [<em>i</em>]. Thus, after line 5, <em>C</em> [<em>i</em>] holds the number of input elements equal to <em>i</em> for each integer <em>i</em> = 0, 1, … , <em>k</em>. Lines 7–8 determine for each <em>i</em> = 0, 1, … , <em>k</em> how many input elements are less than or equal to <em>i</em> by keeping a running sum of the array <em>C</em>.</p>
<p>Finally, the <strong>for</strong> loop of lines 11–13 makes another pass over <em>A</em>, but in reverse, to place each element <em>A</em>[<em>j</em>] into its correct sorted position in the output array <em>B</em>. If all <em>n</em> elements are distinct, then when line 11 is first entered, for each <em>A</em>[<em>j</em>], the value <em>C</em> [<em>A</em>[<em>j</em>]] is the correct final position of <em>A</em>[<em>j</em>] in the output array, since there are <em>C</em> [<em>A</em>[<em>j</em>]] elements less than or equal to <em>A</em>[<em>j</em>]. Because the elements might not be distinct, the loop decrements <em>C</em> [<em>A</em>[<em>j</em>]] each time it places a value <em>A</em>[<em>j</em>] into <em>B</em>. Decrementing <em>C</em> [<em>A</em>[<em>j</em>]] causes the previous element in <em>A</em> with a value equal to <em>A</em>[<em>j</em>], if one exists, to go to the position immediately before <em>A</em>[<em>j</em>] in the output array <em>B</em>.</p>
<p>How much time does counting sort require? The <strong>for</strong> loop of lines 2–3 takes Θ(<em>k</em>) time, the <strong>for</strong> loop of lines 4–5 takes Θ(<em>n</em>) time, the <strong>for</strong> loop of lines 7–8 takes Θ(<em>k</em>) time, and the <strong>for</strong> loop of lines 11–13 takes Θ(<em>n</em>) time. Thus, the overall time is Θ(<em>k</em> + <em>n</em>). In practice, we usually use counting sort when we have <em>k</em> = <em>O</em>(<em>n</em>), in which case the running time is Θ(<em>n</em>).</p>
<p>Counting sort can beat the lower bound of Ω(<em>n</em> lg <em>n</em>) proved in <a href="chapter008.xhtml#Sec_8.1">Section 8.1</a> because it is not a comparison sort. In fact, no comparisons between input elements occur anywhere in the code. Instead, counting sort uses the actual values of the <a id="p210"/>elements to index into an array. The Ω(<em>n</em> lg <em>n</em>) lower bound for sorting does not apply when we depart from the comparison sort model.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_8-2"><img alt="art" class="width100" src="images/Art_P325.jpg"/></p>
<p class="caption"><strong>Figure 8.2</strong> The operation of C<small>OUNTING</small>-S<small>ORT</small> on an input array <em>A</em>[1 : 8], where each element of <em>A</em> is a nonnegative integer no larger than <em>k</em> = 5. <strong>(a)</strong> The array <em>A</em> and the auxiliary array <em>C</em> after line 5. <strong>(b)</strong> The array <em>C</em> after line 8. <strong>(c)–(e)</strong> The output array <em>B</em> and the auxiliary array <em>C</em> after one, two, and three iterations of the loop in lines 11–13, respectively. Only the tan elements of array <em>B</em> have been filled in. <strong>(f)</strong> The final sorted output array <em>B</em>.</p>
</div>
<p>An important property of counting sort is that it is <strong><em><span class="blue1">stable</span></em></strong>: elements with the same value appear in the output array in the same order as they do in the input array. That is, it breaks ties between two elements by the rule that whichever element appears first in the input array appears first in the output array. Normally, the property of stability is important only when satellite data are carried around with the element being sorted. Counting sort’s stability is important for another reason: counting sort is often used as a subroutine in radix sort. As we shall see in the next section, in order for radix sort to work correctly, counting sort must be stable.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>8.2-1</em></strong></p>
<p class="noindent">Using <a href="chapter008.xhtml#Fig_8-2">Figure 8.2</a> as a model, illustrate the operation of C<small>OUNTING</small>-S<small>ORT</small> on the array <em>A</em> = <span class="font1">〈</span>6, 0, 2, 0, 1, 3, 4, 6, 1, 3, 2<span class="font1">〉</span>.</p>
<p class="level3"><strong><em>8.2-2</em></strong></p>
<p class="noindent">Prove that C<small>OUNTING</small>-S<small>ORT</small> is stable.</p>
<a id="p211"/>
<p class="level3"><strong><em>8.2-3</em></strong></p>
<p class="noindent">Suppose that we were to rewrite the <strong>for</strong> loop header in line 11 of the C<small>OUNTING</small>-S<small>ORT</small> as</p>
<table class="table2b">
<tr>
<td class="td1w">11</td>
<td class="td1"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></td>
</tr>
</table>
<p class="noindent">Show that the algorithm still works properly, but that it is not stable. Then rewrite the pseudocode for counting sort so that elements with the same value are written into the output array in order of increasing index and the algorithm is stable.</p>
<p class="level3"><strong><em>8.2-4</em></strong></p>
<p class="noindent">Prove the following loop invariant for C<small>OUNTING</small>-S<small>ORT</small>:</p>
<div class="pull-quote">
<p class="pq-noindent">At the start of each iteration of the <strong>for</strong> loop of lines 11–13, the last element in <em>A</em> with value <em>i</em> that has not yet been copied into <em>B</em> belongs in <em>B</em>[<em>C</em> [<em>i</em>]].</p>
</div>
<p class="level3"><strong><em>8.2-5</em></strong></p>
<p class="noindent">Suppose that the array being sorted contains only integers in the range 0 to <em>k</em> and that there are no satellite data to move with those keys. Modify counting sort to use just the arrays <em>A</em> and <em>C</em>, putting the sorted result back into array <em>A</em> instead of into a new array <em>B</em>.</p>
<p class="level3"><strong><em>8.2-6</em></strong></p>
<p class="noindent">Describe an algorithm that, given <em>n</em> integers in the range 0 to <em>k</em>, preprocesses its input and then answers any query about how many of the <em>n</em> integers fall into a range [<em>a</em> : <em>b</em>] in <em>O</em>(1) time. Your algorithm should use Θ(<em>n</em> + <em>k</em>) preprocessing time.</p>
<p class="level3"><strong><em>8.2-7</em></strong></p>
<p class="noindent">Counting sort can also work efficiently if the input values have fractional parts, but the number of digits in the fractional part is small. Suppose that you are given <em>n</em> numbers in the range 0 to <em>k</em>, each with at most <em>d</em> decimal (base 10) digits to the right of the decimal point. Modify counting sort to run in Θ(<em>n</em> + 10<em><sup>d</sup> k</em>) time.</p>
</section>
<p class="line1"/>
<section title="8.3 Radix sort">
<a id="Sec_8.3"/>
<p class="level1" id="h1-47"><a href="toc.xhtml#Rh1-47"><strong>8.3      Radix sort</strong></a></p>
<p class="noindent"><strong><em><span class="blue1">Radix sort</span></em></strong> is the algorithm used by the card-sorting machines you now find only in computer museums. The cards have 80 columns, and in each column a machine can punch a hole in one of 12 places. The sorter can be mechanically “programmed” to examine a given column of each card in a deck and distribute the card into one <a id="p212"/>of 12 bins depending on which place has been punched. An operator can then gather the cards bin by bin, so that cards with the first place punched are on top of cards with the second place punched, and so on.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_8-3"><img alt="art" src="images/Art_P326.jpg"/></p>
<p class="caption"><strong>Figure 8.3</strong> The operation of radix sort on seven 3-digit numbers. The leftmost column is the input. The remaining columns show the numbers after successive sorts on increasingly significant digit positions. Tan shading indicates the digit position sorted on to produce each list from the previous one.</p>
</div>
<p>For decimal digits, each column uses only 10 places. (The other two places are reserved for encoding nonnumeric characters.) A <em>d</em>-digit number occupies a field of <em>d</em> columns. Since the card sorter can look at only one column at a time, the problem of sorting <em>n</em> cards on a <em>d</em>-digit number requires a sorting algorithm.</p>
<p>Intuitively, you might sort numbers on their <em>most significant</em> (leftmost) digit, sort each of the resulting bins recursively, and then combine the decks in order. Unfortunately, since the cards in 9 of the 10 bins must be put aside to sort each of the bins, this procedure generates many intermediate piles of cards that you would have to keep track of. (See Exercise 8.3-6.)</p>
<p>Radix sort solves the problem of card sorting—counterintuitively—by sorting on the <em>least significant</em> digit first. The algorithm then combines the cards into a single deck, with the cards in the 0 bin preceding the cards in the 1 bin preceding the cards in the 2 bin, and so on. Then it sorts the entire deck again on the second-least significant digit and recombines the deck in a like manner. The process continues until the cards have been sorted on all <em>d</em> digits. Remarkably, at that point the cards are fully sorted on the <em>d</em>-digit number. Thus, only <em>d</em> passes through the deck are required to sort. <a href="chapter008.xhtml#Fig_8-3">Figure 8.3</a> shows how radix sort operates on a “deck” of seven 3-digit numbers.</p>
<p>In order for radix sort to work correctly, the digit sorts must be stable. The sort performed by a card sorter is stable, but the operator must be careful not to change the order of the cards as they come out of a bin, even though all the cards in a bin have the same digit in the chosen column.</p>
<p>In a typical computer, which is a sequential random-access machine, we sometimes use radix sort to sort records of information that are keyed by multiple fields. For example, we might wish to sort dates by three keys: year, month, and day. We could run a sorting algorithm with a comparison function that, given two dates, <a id="p213"/>compares years, and if there is a tie, compares months, and if another tie occurs, compares days. Alternatively, we could sort the information three times with a stable sort: first on day (the “least significant” part), next on month, and finally on year.</p>
<p>The code for radix sort is straightforward. The R<small>ADIX</small>-S<small>ORT</small> procedure assumes that each element in array <em>A</em>[1 : <em>n</em>] has <em>d</em> digits, where digit 1 is the lowest-order digit and digit <em>d</em> is the highest-order digit.</p>
<div class="pull-quote1">
<p class="box-heading">R<small>ADIX</small>-S<small>ORT</small>(<em>A</em>, <em>n</em>, <em>d</em>)</p>
<table class="table1c">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>d</em></p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="p2">use a stable sort to sort array <em>A</em>[1 : <em>n</em>] on digit <em>i</em></p></td>
</tr>
</table>
</div>
<p>Although the pseudocode for R<small>ADIX</small>-S<small>ORT</small> does not specify which stable sort to use, C<small>OUNTING</small>-S<small>ORT</small> is commonly used. If you use C<small>OUNTING</small>-S<small>ORT</small> as the stable sort, you can make R<small>ADIX</small>-S<small>ORT</small> a little more efficient by revising C<small>OUNTING</small>-S<small>ORT</small> to take a pointer to the output array as a parameter, having R<small>ADIX</small>-S<small>ORT</small> preallocate this array, and alternating input and output between the two arrays in successive iterations of the <strong>for</strong> loop in R<small>ADIX</small>-S<small>ORT</small>.</p>
<p class="lemma"><strong><em>Lemma 8.3</em></strong></p>
<p class="noindent">Given <em>n</em> <em>d</em>-digit numbers in which each digit can take on up to <em>k</em> possible values, R<small>ADIX</small>-S<small>ORT</small> correctly sorts these numbers in Θ(<em>d</em>(<em>n</em> + <em>k</em>)) time if the stable sort it uses takes Θ(<em>n</em> + <em>k</em>) time.</p>
<p class="proof"><strong><em>Proof</em></strong>   The correctness of radix sort follows by induction on the column being sorted (see Exercise 8.3-3). The analysis of the running time depends on the stable sort used as the intermediate sorting algorithm. When each digit lies in the range 0 to <em>k</em> – 1 (so that it can take on <em>k</em> possible values), and <em>k</em> is not too large, counting sort is the obvious choice. Each pass over <em>n d</em>-digit numbers then takes Θ(<em>n</em> + <em>k</em>) time. There are <em>d</em> passes, and so the total time for radix sort is Θ(<em>d</em>(<em>n</em> + <em>k</em>)).</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">When <em>d</em> is constant and <em>k</em> = <em>O</em>(<em>n</em>), we can make radix sort run in linear time. More generally, we have some flexibility in how to break each key into digits.</p>
<p class="lemma"><strong><em>Lemma 8.4</em></strong></p>
<p class="noindent">Given <em>n b</em>-bit numbers and any positive integer <em>r</em> ≤ <em>b</em>, R<small>ADIX</small>-S<small>ORT</small> correctly sorts these numbers in Θ((<em>b</em>/<em>r</em>)(<em>n</em> + 2<em><sup>r</sup></em>)) time if the stable sort it uses takes Θ(<em>n</em> + <em>k</em>) time for inputs in the range 0 to <em>k</em>.</p>
<a id="p214"/>
<p class="proof"><strong><em>Proof</em></strong>   For a value <em>r</em> ≤ <em>b</em>, view each key as having <em>d</em> = <span class="font1">⌈</span><em>b</em>/<em>r</em><span class="font1">⌉</span> digits of <em>r</em> bits each. Each digit is an integer in the range 0 to 2<sup><em>r</em></sup> – 1, so that we can use counting sort with <em>k</em> = 2<sup><em>r</em></sup> – 1. (For example, we can view a 32-bit word as having four 8-bit digits, so that <em>b</em> = 32, <em>r</em> = 8, <em>k</em> = 2<sup><em>r</em></sup> – 1 = 255, and <em>d</em> = <em>b</em>/<em>r</em> = 4.) Each pass of counting sort takes Θ(<em>n</em> + <em>k</em>) = Θ(<em>n</em> + 2<em><sup>r</sup></em>) time and there are <em>d</em> passes, for a total running time of Θ(<em>d</em>(<em>n</em> + 2<em><sup>r</sup></em>)) = Θ((<em>b</em>/<em>r</em>)(<em>n</em> + 2<em><sup>r</sup></em>)).</p>
<p class="right"><span class="font1">▪</span></p>
<p class="space-break">Given <em>n</em> and <em>b</em>, what value of <em>r</em> ≤ <em>b</em> minimizes the expression (<em>b</em>/<em>r</em>)(<em>n</em> + 2<em><sup>r</sup></em>)? As <em>r</em> decreases, the factor <em>b</em>/<em>r</em> increases, but as <em>r</em> increases so does 2<em><sup>r</sup></em>. The answer depends on whether <em>b</em> &lt; <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span>. If <em>b</em> &lt; <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span>, then <em>r</em> ≤ <em>b</em> implies (<em>n</em> + 2<em><sup>r</sup></em>) = Θ(<em>n</em>). Thus, choosing <em>r</em> = <em>b</em> yields a running time of (<em>b</em>/<em>b</em>)(<em>n</em> + 2<em><sup>b</sup></em>) = Θ(<em>n</em>), which is asymptotically optimal. If <em>b</em> ≥ <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span>, then choosing <em>r</em> = <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span> gives the best running time to within a constant factor, which we can see as follows.<sup><a epub:type="footnote" href="#footnote_1" id="footnote_ref_1">1</a></sup> Choosing <em>r</em> = <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span> yields a running time of Θ(<em>bn</em>/lg <em>n</em>). As <em>r</em> increases above <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span>, the 2<sup><em>r</em></sup> term in the numerator increases faster than the <em>r</em> term in the denominator, and so increasing <em>r</em> above <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span> yields a running time of Ω(<em>bn</em> / lg <em>n</em>). If instead <em>r</em> were to decrease below <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span>, then the <em>b</em>/<em>r</em> term increases and the <em>n</em> + 2<sup><em>r</em></sup> term remains at Θ(<em>n</em>).</p>
<p>Is radix sort preferable to a comparison-based sorting algorithm, such as quicksort? If <em>b</em> = <em>O</em>(lg <em>n</em>), as is often the case, and <em>r</em> ≈ lg <em>n</em>, then radix sort’s running time is Θ(<em>n</em>), which appears to be better than quicksort’s expected running time of Θ(<em>n</em> lg <em>n</em>). The constant factors hidden in the Θ-notation differ, however. Although radix sort may make fewer passes than quicksort over the <em>n</em> keys, each pass of radix sort may take significantly longer. Which sorting algorithm to prefer depends on the characteristics of the implementations, of the underlying machine (e.g., quicksort often uses hardware caches more effectively than radix sort), and of the input data. Moreover, the version of radix sort that uses counting sort as the intermediate stable sort does not sort in place, which many of the Θ(<em>n</em> lg <em>n</em>)-time comparison sorts do. Thus, when primary memory storage is at a premium, an in-place algorithm such as quicksort could be the better choice.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>8.3-1</em></strong></p>
<p class="noindent">Using <a href="chapter008.xhtml#Fig_8-3">Figure 8.3</a> as a model, illustrate the operation of R<small>ADIX</small>-S<small>ORT</small> on the following list of English words: COW, DOG, SEA, RUG, ROW, MOB, BOX, TAB, BAR, EAR, TAR, DIG, BIG, TEA, NOW, FOX.</p>
<a id="p215"/>
<p class="level3"><strong><em>8.3-2</em></strong></p>
<p class="noindent">Which of the following sorting algorithms are stable: insertion sort, merge sort, heapsort, and quicksort? Give a simple scheme that makes any comparison sort stable. How much additional time and space does your scheme entail?</p>
<p class="level3"><strong><em>8.3-3</em></strong></p>
<p class="noindent">Use induction to prove that radix sort works. Where does your proof need the assumption that the intermediate sort is stable?</p>
<p class="level3"><strong><em>8.3-4</em></strong></p>
<p class="noindent">Suppose that C<small>OUNTING</small>-S<small>ORT</small> is used as the stable sort within R<small>ADIX</small>-S<small>ORT</small>. If R<small>ADIX</small>-S<small>ORT</small> calls C<small>OUNTING</small>-S<small>ORT</small> <em>d</em> times, then since each call of C<small>OUNTING</small>-S<small>ORT</small> makes two passes over the data (lines 4–5 and 11–13), altogether 2<em>d</em> passes over the data occur. Describe how to reduce the total number of passes to <em>d</em> + 1.</p>
<p class="level3"><strong><em>8.3-5</em></strong></p>
<p class="noindent">Show how to sort <em>n</em> integers in the range 0 to <em>n</em><sup>3</sup> – 1 in <em>O</em>(<em>n</em>) time.</p>
<p class="level3"><span class="font1">★</span> <strong><em>8.3-6</em></strong></p>
<p class="noindent">In the first card-sorting algorithm in this section, which sorts on the most significant digit first, exactly how many sorting passes are needed to sort <em>d</em>-digit decimal numbers in the worst case? How many piles of cards does an operator need to keep track of in the worst case?</p>
</section>
<p class="line1"/>
<section title="8.4 Bucket sort">
<a id="Sec_8.4"/>
<p class="level1" id="h1-48"><a href="toc.xhtml#Rh1-48"><strong>8.4      Bucket sort</strong></a></p>
<p class="noindent"><strong><em><span class="blue1">Bucket sort</span></em></strong> assumes that the input is drawn from a uniform distribution and has an average-case running time of <em>O</em>(<em>n</em>). Like counting sort, bucket sort is fast because it assumes something about the input. Whereas counting sort assumes that the input consists of integers in a small range, bucket sort assumes that the input is generated by a random process that distributes elements uniformly and independently over the interval [0, 1). (See <a href="appendix003.xhtml#Sec_C.2">Section C.2</a> for a definition of a uniform distribution.)</p>
<p>Bucket sort divides the interval [0, 1) into <em>n</em> equal-sized subintervals, or <strong><em><span class="blue1">buckets</span></em></strong>, and then distributes the <em>n</em> input numbers into the buckets. Since the inputs are uniformly and independently distributed over [0, 1), we do not expect many numbers to fall into each bucket. To produce the output, we simply sort the numbers in each bucket and then go through the buckets in order, listing the elements in each.</p>
<p>The B<small>UCKET</small>-S<small>ORT</small> procedure on the next page assumes that the input is an array <em>A</em>[1 : <em>n</em>] and that each element <em>A</em>[<em>i</em>] in the array satisfies 0 ≤ <em>A</em>[<em>i</em>] &lt; 1. The code requires an auxiliary array <em>B</em>[0 : <em>n</em> – 1] of linked lists (buckets) and assumes <a id="p216"/>that there is a mechanism for maintaining such lists. (<a href="chapter010.xhtml#Sec_10.2">Section 10.2</a> describes how to implement basic operations on linked lists.) <a href="chapter008.xhtml#Fig_8-4">Figure 8.4</a> shows the operation of bucket sort on an input array of 10 numbers.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_8-4"><img alt="art" src="images/Art_P327.jpg"/></p>
<p class="caption"><strong>Figure 8.4</strong> The operation of B<small>UCKET</small>-S<small>ORT</small> for <em>n</em> = 10. <strong>(a)</strong> The input array <em>A</em>[1 : 10]. <strong>(b)</strong> The array <em>B</em>[0 : 9] of sorted lists (buckets) after line 7 of the algorithm, with slashes indicating the end of each bucket. Bucket <em>i</em> holds values in the half-open interval [<em>i</em>/10, (<em>i</em> + 1)/10). The sorted output consists of a concatenation of the lists <em>B</em>[0], <em>B</em>[1], … , <em>B</em>[9] in order.</p>
</div>
<div class="pull-quote1">
<p class="box-heading">B<small>UCKET</small>-S<small>ORT</small>(<em>A</em>, <em>n</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent">let <em>B</em>[0 : <em>n</em> – 1] be a new array</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 0 <strong>to</strong> <em>n</em> – 1</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="p2">make <em>B</em>[<em>i</em>] an empty list</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">4</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="p2">insert <em>A</em>[<em>i</em>] into list <em>B</em>[<span class="font1">⌊</span><em>n</em> · <em>A</em>[<em>i</em>]<span class="font1">⌋</span>]</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">6</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 0 <strong>to</strong> <em>n</em> – 1</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">7</span></p></td>
<td class="td1"><p class="p2">sort list <em>B</em>[<em>i</em>] with insertion sort</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">8</span></p></td>
<td class="td1"><p class="noindent">concatenate the lists <em>B</em>[0], <em>B</em>[1], … , <em>B</em>[<em>n</em> – 1] together in order</p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">9</span></p></td>
<td class="td1"><p class="noindent"><strong>return</strong> the concatenated lists</p></td>
</tr>
</table>
</div>
<p>To see that this algorithm works, consider two elements <em>A</em>[<em>i</em>] and <em>A</em>[<em>j</em>]. Assume without loss of generality that <em>A</em>[<em>i</em>] ≤ <em>A</em>[<em>j</em>]. Since <span class="font1">⌊</span><em>n</em> · <em>A</em>[<em>i</em>]<span class="font1">⌋</span> ≤ <span class="font1">⌊</span><em>n</em> · <em>A</em>[<em>j</em>]<span class="font1">⌋</span>, either element <em>A</em>[<em>i</em>] goes into the same bucket as <em>A</em>[<em>j</em>] or it goes into a bucket with a lower index. If <em>A</em>[<em>i</em>] and <em>A</em>[<em>j</em>] go into the same bucket, then the <strong>for</strong> loop of lines 6–7 puts them into the proper order. If <em>A</em>[<em>i</em>] and <em>A</em>[<em>j</em>] go into different buckets, then line 8 puts them into the proper order. Therefore, bucket sort works correctly.</p>
<a id="p217"/>
<p>To analyze the running time, observe that, together, all lines except line 7 take <em>O</em>(<em>n</em>) time in the worst case. We need to analyze the total time taken by the <em>n</em> calls to insertion sort in line 7.</p>
<p>To analyze the cost of the calls to insertion sort, let <em>n<sub>i</sub></em> be the random variable denoting the number of elements placed in bucket <em>B</em>[<em>i</em>]. Since insertion sort runs in quadratic time (see <a href="chapter002.xhtml#Sec_2.2">Section 2.2</a>), the running time of bucket sort is</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P328.jpg"/></p>
<p>We now analyze the average-case running time of bucket sort, by computing the expected value of the running time, where we take the expectation over the input distribution. Taking expectations of both sides and using linearity of expectation (equation (C.24) on page 1192), we have</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P329.jpg"/></p>
<p class="noindent">We claim that</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P330.jpg"/></p>
<p class="noindent">for <em>i</em> = 0, 1, … , <em>n</em> – 1. It is no surprise that each bucket <em>i</em> has the same value of <img alt="art" src="images/Art_P331.jpg"/>, since each value in the input array <em>A</em> is equally likely to fall in any bucket.</p>
<p>To prove equation (8.3), view each random variable <em>n<sub>i</sub></em> as the number of successes in <em>n</em> Bernoulli trials (see <a href="appendix003.xhtml#Sec_C.4">Section C.4</a>). Success in a trial occurs when an element goes into bucket <em>B</em>[<em>i</em>], with a probability <em>p</em> = 1/<em>n</em> of success and <em>q</em> = 1 – 1/<em>n</em> of failure. A binomial distribution counts <em>n<sub>i</sub></em>, the number of successes, in the <em>n</em> trials. By equations (C.41) and (C.44) on pages 1199–1200, we have E [<em>n<sub>i</sub></em>] = <em>np</em> = <em>n</em>(1/<em>n</em>) = 1 and Var [<em>n<sub>i</sub></em>] = <em>npq</em> = 1 – 1/<em>n</em>. Equation (C.31) on page 1194 gives</p>
<table class="table2b">
<tr>
<td class="td2"><img alt="art" src="images/Art_P332.jpg"/></td>
<td class="td2m">=</td>
<td class="td2">Var [<em>n<sub>i</sub></em>] + E<sup>2</sup> [<em>n<sub>i</sub></em>]</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2m">=</td>
<td class="td2">(1 – 1/<em>n</em>) + 1<sup>2</sup></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2m">=</td>
<td class="td2">2 – 1/<em>n</em>,</td>
</tr>
</table>
<a id="p218"/>
<p class="noindent">which proves equation (8.3). Using this expected value in equation (8.2), we get that the average-case running time for bucket sort is Θ(<em>n</em>) + <em>n</em> · <em>O</em>(2 – 1/<em>n</em>) = Θ(<em>n</em>).</p>
<p>Even if the input is not drawn from a uniform distribution, bucket sort may still run in linear time. As long as the input has the property that the sum of the squares of the bucket sizes is linear in the total number of elements, equation (8.1) tells us that bucket sort runs in linear time.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>8.4-1</em></strong></p>
<p class="noindent">Using <a href="chapter008.xhtml#Fig_8-4">Figure 8.4</a> as a model, illustrate the operation of B<small>UCKET</small>-S<small>ORT</small> on the array <em>A</em> = <span class="font1">〈</span>.79, .13, .16, .64, .39, .20, .89, .53, .71, .42<span class="font1">〉</span>.</p>
<p class="level3"><strong><em>8.4-2</em></strong></p>
<p class="noindent">Explain why the worst-case running time for bucket sort is Θ(<em>n</em><sup>2</sup>). What simple change to the algorithm preserves its linear average-case running time and makes its worst-case running time <em>O</em>(<em>n</em> lg <em>n</em>)?</p>
<p class="level3"><strong><em>8.4-3</em></strong></p>
<p class="noindent">Let <em>X</em> be a random variable that is equal to the number of heads in two flips of a fair coin. What is E [<em>X</em><sup>2</sup>]? What is E<sup>2</sup> [<em>X</em>]?</p>
<p class="level3"><strong><em>8.4-4</em></strong></p>
<p class="noindent">An array <em>A</em> of size <em>n</em> &gt; 10 is filled in the following way. For each element <em>A</em>[<em>i</em>], choose two random variables <em>x<sub>i</sub></em> and <em>y<sub>i</sub></em> uniformly and independently from [0, 1). Then set</p>
<p class="eql"><img alt="art" src="images/Art_P333.jpg"/></p>
<p class="noindent">Modify bucket sort so that it sorts the array <em>A</em> in <em>O</em>(<em>n</em>) expected time.</p>
<p class="level3"><span class="font1">★</span> <strong><em>8.4-5</em></strong></p>
<p class="noindent">You are given <em>n</em> points in the unit disk, <em>p<sub>i</sub></em> = (<em>x<sub>i</sub></em>, <em>y<sub>i</sub></em>), such that <img alt="art" src="images/Art_P334.jpg"/> for <em>i</em> = 1, 2, … , <em>n</em>. Suppose that the points are uniformly distributed, that is, the probability of finding a point in any region of the disk is proportional to the area of that region. Design an algorithm with an average-case running time of Θ(<em>n</em>) to sort the <em>n</em> points by their distances <img alt="art" src="images/Art_P335.jpg"/> from the origin. (<em>Hint:</em> Design the bucket sizes in B<small>UCKET</small>-S<small>ORT</small> to reflect the uniform distribution of the points in the unit disk.)</p>
<p class="level3"><span class="font1">★</span> <strong><em>8.4-6</em></strong></p>
<p class="noindent">A <strong><em><span class="blue1">probability distribution function</span></em></strong> <em>P</em>(<em>x</em>) for a random variable <em>X</em> is defined by <em>P</em>(<em>x</em>) = Pr {<em>X</em> ≤ <em>x</em>}. Suppose that you draw a list of <em>n</em> random variables <a id="p219"/><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, … , <em>X<sub>n</sub></em> from a continuous probability distribution function <em>P</em> that is computable in <em>O</em>(1) time (given <em>y</em> you can find <em>x</em> such that <em>P</em>(<em>x</em>) = <em>y</em> in <em>O</em>(1) time). Give an algorithm that sorts these numbers in linear average-case time.</p>
</section>
<p class="line1"/>
<section title="Problems">
<p class="level1" id="h1-49"><strong>Problems</strong></p>
<section title="8-1 Probabilistic lower bounds on comparison sorting">
<p class="level2"><strong><em>8-1     Probabilistic lower bounds on comparison sorting</em></strong></p>
<p class="noindent">In this problem, you will prove a probabilistic Ω(<em>n</em> lg <em>n</em>) lower bound on the running time of any deterministic or randomized comparison sort on <em>n</em> distinct input elements. You’ll begin by examining a deterministic comparison sort <em>A</em> with decision tree <em>T<sub>A</sub></em>. Assume that every permutation of <em>A</em>’s inputs is equally likely.</p>
<p class="nl-top"><strong><em>a.</em></strong> Suppose that each leaf of <em>T<sub>A</sub></em> is labeled with the probability that it is reached given a random input. Prove that exactly <em>n</em>! leaves are labeled 1/<em>n</em>! and that the rest are labeled 0.</p>
<p class="nl"><strong><em>b.</em></strong> Let <em>D</em>(<em>T</em>) denote the external path length of a decision tree <em>T</em>—the sum of the depths of all the leaves of <em>T</em>. Let <em>T</em> be a decision tree with <em>k</em> &gt; 1 leaves, and let <em>LT</em> and <em>RT</em> be the left and right subtrees of <em>T</em>. Show that <em>D</em>(<em>T</em>) = <em>D</em>(<em>LT</em>) + <em>D</em>(<em>RT</em>) + <em>k</em>.</p>
<p class="nl"><strong><em>c.</em></strong> Let <em>d</em>(<em>k</em>) be the minimum value of <em>D</em>(<em>T</em>) over all decision trees <em>T</em> with <em>k</em> &gt; 1 leaves. Show that <em>d</em>(<em>k</em>) = min {<em>d</em>(<em>i</em>) + <em>d</em>(<em>k</em> – <em>i</em>) + <em>k</em> : 1 ≤ <em>i</em> ≤ <em>k</em> – 1}. (<em>Hint:</em> Consider a decision tree <em>T</em> with <em>k</em> leaves that achieves the minimum. Let <em>i</em><sub>0</sub> be the number of leaves in <em>LT</em> and <em>k</em> – <em>i</em><sub>0</sub> the number of leaves in <em>RT</em>.)</p>
<p class="nl"><strong><em>d.</em></strong> Prove that for a given value of <em>k</em> &gt; 1 and <em>i</em> in the range 1 ≤ <em>i</em> ≤ <em>k</em> – 1, the function <em>i</em> lg <em>i</em> + (<em>k</em> – <em>i</em>) lg(<em>k</em> – <em>i</em>) is minimized at <em>i</em> = <em>k</em>/2. Conclude that <em>d</em>(<em>k</em>) = Ω (<em>k</em> lg <em>k</em>).</p>
<p class="nl"><strong><em>e.</em></strong> Prove that <em>D</em>(<em>T<sub>A</sub></em>) = Ω (<em>n</em>! lg(<em>n</em>!)), and conclude that the average-case time to sort <em>n</em> elements is Ω(<em>n</em> lg <em>n</em>).</p>
<p class="noindent1-top">Now consider a <em>randomized</em> comparison sort <em>B</em>. We can extend the decision-tree model to handle randomization by incorporating two kinds of nodes: ordinary comparison nodes and “randomization” nodes. A randomization node models a random choice of the form R<small>ANDOM</small>(1, <em>r</em>) made by algorithm <em>B</em>. The node has <em>r</em> children, each of which is equally likely to be chosen during an execution of the algorithm.</p>
<p class="nl-top"><strong><em>f.</em></strong> Show that for any randomized comparison sort <em>B</em>, there exists a deterministic comparison sort <em>A</em> whose expected number of comparisons is no more than those made by <em>B</em>.</p>
<a id="p220"/>
</section>
<section title="8-2 Sorting in place in linear time">
<p class="level2"><strong><em>8-2     Sorting in place in linear time</em></strong></p>
<p class="noindent">You have an array of <em>n</em> data records to sort, each with a key of 0 or 1. An algorithm for sorting such a set of records might possess some subset of the following three desirable characteristics:</p>
<ol class="olnoindent" epub:type="list">
<li>The algorithm runs in <em>O</em>(<em>n</em>) time.</li>
<li class="litop">The algorithm is stable.</li>
<li class="litop">The algorithm sorts in place, using no more than a constant amount of storage space in addition to the original array.</li>
</ol>
<p class="nl"><strong><em>a.</em></strong> Give an algorithm that satisfies criteria 1 and 2 above.</p>
<p class="nl"><strong><em>b.</em></strong> Give an algorithm that satisfies criteria 1 and 3 above.</p>
<p class="nl"><strong><em>c.</em></strong> Give an algorithm that satisfies criteria 2 and 3 above.</p>
<p class="nl"><strong><em>d.</em></strong> Can you use any of your sorting algorithms from parts (a)–(c) as the sorting method used in line 2 of R<small>ADIX</small>-S<small>ORT</small>, so that R<small>ADIX</small>-S<small>ORT</small> sorts <em>n</em> records with <em>b</em>-bit keys in <em>O</em>(<em>bn</em>) time? Explain how or why not.</p>
<p class="nl"><strong><em>e.</em></strong> Suppose that the <em>n</em> records have keys in the range from 1 to <em>k</em>. Show how to modify counting sort so that it sorts the records in place in <em>O</em>(<em>n</em> + <em>k</em>) time. You may use <em>O</em>(<em>k</em>) storage outside the input array. Is your algorithm stable?</p>
</section>
<section title="8-3 Sorting variable-length items">
<p class="level2"><strong><em>8-3     Sorting variable-length items</em></strong></p>
<p class="nl-nt"><strong><em>a.</em></strong> You are given an array of integers, where different integers may have different numbers of digits, but the total number of digits over <em>all</em> the integers in the array is <em>n</em>. Show how to sort the array in <em>O</em>(<em>n</em>) time.</p>
<p class="nl"><strong><em>b.</em></strong> You are given an array of strings, where different strings may have different numbers of characters, but the total number of characters over all the strings is <em>n</em>. Show how to sort the strings in <em>O</em>(<em>n</em>) time. (The desired order is the standard alphabetical order: for example, <span class="font1">a &lt; ab &lt; b</span>.)</p>
</section>
<section title="8-4 Water jugs">
<p class="level2"><strong><em>8-4     Water jugs</em></strong></p>
<p class="noindent">You are given <em>n</em> red and <em>n</em> blue water jugs, all of different shapes and sizes. All the red jugs hold different amounts of water, as do all the blue jugs, and you cannot tell from the size of a jug how much water it holds. Moreover, for every jug of one color, there is a jug of the other color that holds the same amount of water.</p>
<p>Your task is to group the jugs into pairs of red and blue jugs that hold the same amount of water. To do so, you may perform the following operation: pick a pair <a id="p221"/>of jugs in which one is red and one is blue, fill the red jug with water, and then pour the water into the blue jug. This operation tells you whether the red jug or the blue jug can hold more water, or that they have the same volume. Assume that such a comparison takes one time unit. Your goal is to find an algorithm that makes a minimum number of comparisons to determine the grouping. Remember that you may not directly compare two red jugs or two blue jugs.</p>
<p class="nl-top"><strong><em>a.</em></strong> Describe a deterministic algorithm that uses Θ(<em>n</em><sup>2</sup>) comparisons to group the jugs into pairs.</p>
<p class="nl"><strong><em>b.</em></strong> Prove a lower bound of Ω(<em>n</em> lg <em>n</em>) for the number of comparisons that an algorithm solving this problem must make.</p>
<p class="nl"><strong><em>c.</em></strong> Give a randomized algorithm whose expected number of comparisons is <em>O</em>(<em>n</em> lg <em>n</em>), and prove that this bound is correct. What is the worst-case number of comparisons for your algorithm?</p>
</section>
<section title="8-5 Average sorting">
<p class="level2"><strong><em>8-5     Average sorting</em></strong></p>
<p class="noindent">Suppose that, instead of sorting an array, we just require that the elements increase on average. More precisely, we call an <em>n</em>-element array <em>A</em> <strong><em><span class="blue1">k-sorted</span></em></strong> if, for all <em>i</em> = 1, 2, … , <em>n</em> – <em>k</em>, the following holds:</p>
<p class="eql"><img alt="art" src="images/Art_P336.jpg"/></p>
<p class="nl-top"><strong><em>a.</em></strong> What does it mean for an array to be 1-sorted?</p>
<p class="nl"><strong><em>b.</em></strong> Give a permutation of the numbers 1, 2, … , 10 that is 2-sorted, but not sorted.</p>
<p class="nl"><strong><em>c.</em></strong> Prove that an <em>n</em>-element array is <em>k</em>-sorted if and only if <em>A</em>[<em>i</em>] ≤ <em>A</em>[<em>i</em> + <em>k</em>] for all <em>i</em> = 1, 2, … , <em>n</em> – <em>k</em>.</p>
<p class="nl"><strong><em>d.</em></strong> Give an algorithm that <em>k</em>-sorts an <em>n</em>-element array in <em>O</em>(<em>n</em> lg(<em>n</em>/<em>k</em>)) time.</p>
<p class="noindent">We can also show a lower bound on the time to produce a <em>k</em>-sorted array, when <em>k</em> is a constant.</p>
<p class="nl-top"><strong><em>e.</em></strong> Show how to sort a <em>k</em>-sorted array of length <em>n</em> in <em>O</em>(<em>n</em> lg <em>k</em>) time. (<em>Hint:</em> Use the solution to Exercise 6.5-11.)</p>
<p class="nl"><strong><em>f.</em></strong> Show that when <em>k</em> is a constant, <em>k</em>-sorting an <em>n</em>-element array requires Ω(<em>n</em> lg <em>n</em>) time. (<em>Hint:</em> Use the solution to part (e) along with the lower bound on comparison sorts.)</p>
<a id="p222"/>
</section>
<section title="8-6 Lower bound on merging sorted lists">
<p class="level2"><strong><em>8-6     Lower bound on merging sorted lists</em></strong></p>
<p class="noindent">The problem of merging two sorted lists arises frequently. We have seen a procedure for it as the subroutine M<small>ERGE</small> in <a href="chapter002.xhtml#Sec_2.3.1">Section 2.3.1</a>. In this problem, you will prove a lower bound of 2<em>n</em> – 1 on the worst-case number of comparisons required to merge two sorted lists, each containing <em>n</em> items. First, you will show a lower bound of 2<em>n</em> – <em>o</em>(<em>n</em>) comparisons by using a decision tree.</p>
<p class="nl-top"><strong><em>a.</em></strong> Given 2<em>n</em> numbers, compute the number of possible ways to divide them into two sorted lists, each with <em>n</em> numbers.</p>
<p class="nl"><strong><em>b.</em></strong> Using a decision tree and your answer to part (a), show that any algorithm that correctly merges two sorted lists must perform at least 2<em>n</em> – <em>o</em>(<em>n</em>) comparisons.</p>
<p class="noindent1-top">Now you will show a slightly tighter 2<em>n</em> – 1 bound.</p>
<p class="nl-top"><strong><em>c.</em></strong> Show that if two elements are consecutive in the sorted order and from different lists, then they must be compared.</p>
<p class="nl"><strong><em>d.</em></strong> Use your answer to part (c) to show a lower bound of 2<em>n</em> – 1 comparisons for merging two sorted lists.</p>
</section>
<section title="8-7 The 0-1 sorting lemma and columnsort">
<p class="level2"><strong><em>8-7     The 0-1 sorting lemma and columnsort</em></strong></p>
<p class="noindent">A <strong><em><span class="blue1">compare-exchange</span></em></strong> operation on two array elements <em>A</em>[<em>i</em>] and <em>A</em>[<em>j</em>], where <em>i</em> &lt; <em>j</em>, has the form</p>
<div class="pull-quote1">
<p class="box-heading">C<small>OMPARE</small>-E<small>XCHANGE</small>(<em>A</em>, <em>i</em>, <em>j</em>)</p>
<table class="table1c">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent"><strong>if</strong> <em>A</em>[<em>i</em>] &gt; <em>A</em>[<em>j</em>]</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="p2">exchange <em>A</em>[<em>i</em>] with <em>A</em>[<em>j</em>]</p></td>
</tr>
</table>
</div>
<p class="noindent">After the compare-exchange operation, we know that <em>A</em>[<em>i</em>] ≤ <em>A</em>[<em>j</em>].</p>
<p>An <strong><em><span class="blue1">oblivious compare-exchange algorithm</span></em></strong> operates solely by a sequence of prespecified compare-exchange operations. The indices of the positions compared in the sequence must be determined in advance, and although they can depend on the number of elements being sorted, they cannot depend on the values being sorted, nor can they depend on the result of any prior compare-exchange operation. For example, the C<small>OMPARE</small>-E<small>XCHANGE</small>-I<small>NSERTION</small>-S<small>ORT</small> procedure on the facing page shows a variation of insertion sort as an oblivious compare-exchange algorithm. (Unlike the I<small>NSERTION</small>-S<small>ORT</small> procedure on page 19, the oblivious version runs in Θ(<em>n</em><sup>2</sup>) time in all cases.)</p>
<p>The <strong><em><span class="blue1">0-1 sorting lemma</span></em></strong> provides a powerful way to prove that an oblivious compare-exchange algorithm produces a sorted result. It states that if an oblivious compare-exchange algorithm correctly sorts all input sequences consisting of only 0s and 1s, then it correctly sorts all inputs containing arbitrary values.</p>
<a id="p223"/>
<div class="pull-quote1">
<p class="box-heading">C<small>OMPARE</small>-E<small>XCHANGE</small>-I<small>NSERTION</small>-S<small>ORT</small>(<em>A</em>, <em>n</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 2 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="p2"><strong>for</strong> <em>j</em> = <em>i</em> – 1 <strong>downto</strong> 1</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="p3">C<small>OMPARE</small>-E<small>XCHANGE</small>(<em>A</em>, <em>j</em>, <em>j</em> + 1)</p></td>
</tr>
</table>
</div>
<p>You will prove the 0-1 sorting lemma by proving its contrapositive: if an oblivious compare-exchange algorithm fails to sort an input containing arbitrary values, then it fails to sort some 0-1 input. Assume that an oblivious compare-exchange algorithm X fails to correctly sort the array <em>A</em>[1 : <em>n</em>]. Let <em>A</em>[<em>p</em>] be the smallest value in <em>A</em> that algorithm X puts into the wrong location, and let <em>A</em>[<em>q</em>] be the value that algorithm X moves to the location into which <em>A</em>[<em>p</em>] should have gone. Define an array <em>B</em>[1 : <em>n</em>] of 0s and 1s as follows:</p>
<p class="eql"><img alt="art" src="images/Art_P337.jpg"/></p>
<p class="nl-top"><strong><em>a.</em></strong> Argue that <em>A</em>[<em>q</em>] &gt; <em>A</em>[<em>p</em>], so that <em>B</em>[<em>p</em>] = 0 and <em>B</em>[<em>q</em>] = 1.</p>
<p class="nl"><strong><em>b.</em></strong> To complete the proof of the 0-1 sorting lemma, prove that algorithm X fails to sort array <em>B</em> correctly.</p>
<p class="space-break">Now you will use the 0-1 sorting lemma to prove that a particular sorting algorithm works correctly. The algorithm, <strong><em><span class="blue1">columnsort</span></em></strong>, works on a rectangular array of <em>n</em> elements. The array has <em>r</em> rows and <em>s</em> columns (so that <em>n</em> = <em>rs</em>), subject to three restrictions:</p>
<ul class="ulnoindent" epub:type="list">
<li><em>r</em> must be even,</li>
<li class="litop"><em>s</em> must be a divisor of <em>r</em>, and</li>
<li class="litop"><em>r</em> ≥ 2<em>s</em><sup>2</sup>.</li></ul>
<p class="noindent">When columnsort completes, the array is sorted in <strong><em><span class="blue1">column-major order</span></em></strong>: reading down each column in turn, from left to right, the elements monotonically increase.</p>
<p>Columnsort operates in eight steps, regardless of the value of <em>n</em>. The odd steps are all the same: sort each column individually. Each even step is a fixed permutation. Here are the steps:</p>
<ol class="olnoindent" epub:type="list">
<li>Sort each column.</li>
<li class="litop">Transpose the array, but reshape it back to <em>r</em> rows and <em>s</em> columns. In other words, turn the leftmost column into the top <em>r</em>/<em>s</em> rows, in order; turn the next column into the next <em>r</em>/<em>s</em> rows, in order; and so on.<a id="p224"/></li>
<li class="litop">Sort each column.</li>
<li class="litop">Perform the inverse of the permutation performed in step 2.</li>
<li class="litop">Sort each column.</li>
<li class="litop">Shift the top half of each column into the bottom half of the same column, and shift the bottom half of each column into the top half of the next column to the right. Leave the top half of the leftmost column empty. Shift the bottom half of the last column into the top half of a new rightmost column, and leave the bottom half of this new column empty.</li>
<li class="litop">Sort each column.</li>
<li class="litop">Perform the inverse of the permutation performed in step 6.</li></ol>
<div class="divimage">
<p class="fig-imga" id="Fig_8-5"><img alt="art" class="width100" src="images/Art_P338.jpg"/></p>
<p class="caption"><strong>Figure 8.5</strong> The steps of columnsort. <strong>(a)</strong> The input array with 6 rows and 3 columns. (This example does not obey the <em>r</em> ≥ 2<em>s</em><sup>2</sup> requirement, but it works.) <strong>(b)</strong> After sorting each column in step 1. <strong>(c)</strong> After transposing and reshaping in step 2. <strong>(d)</strong> After sorting each column in step 3. <strong>(e)</strong> After performing step 4, which inverts the permutation from step 2. <strong>(f)</strong> After sorting each column in step 5. <strong>(g)</strong> After shifting by half a column in step 6. <strong>(h)</strong> After sorting each column in step 7. <strong>(i)</strong> After performing step 8, which inverts the permutation from step 6. Steps 6–8 sort the bottom half of each column with the top half of the next column. After step 8, the array is sorted in column-major order.</p>
</div>
<p class="noindent">You can think of steps 6–8 as a single step that sorts the bottom half of each column and the top half of the next column. <a href="chapter008.xhtml#Fig_8-5">Figure 8.5</a> shows an example of the steps of columnsort with <em>r</em> = 6 and <em>s</em> = 3. (Even though this example violates the requirement that <em>r</em> ≥ 2<em>s</em><sup>2</sup>, it happens to work.)</p>
<p class="nl-top"><strong><em>c.</em></strong> Argue that we can treat columnsort as an oblivious compare-exchange algorithm, even if we do not know what sorting method the odd steps use.</p>
<a id="p225"/>
<p class="space-break">Although it might seem hard to believe that columnsort actually sorts, you will use the 0-1 sorting lemma to prove that it does. The 0-1 sorting lemma applies because we can treat columnsort as an oblivious compare-exchange algorithm. A couple of definitions will help you apply the 0-1 sorting lemma. We say that an area of an array is <strong><em><span class="blue1">clean</span></em></strong> if we know that it contains either all 0s or all 1s or if it is empty. Otherwise, the area might contain mixed 0s and 1s, and it is <strong><em><span class="blue1">dirty</span></em></strong>. From here on, assume that the input array contains only 0s and 1s, and that we can treat it as an array with <em>r</em> rows and <em>s</em> columns.</p>
<p class="nl"><strong><em>d.</em></strong> Prove that after steps 1–3, the array consists of clean rows of 0s at the top, clean rows of 1s at the bottom, and at most <em>s</em> dirty rows between them. (One of the clean rows could be empty.)</p>
<p class="nl"><strong><em>e.</em></strong> Prove that after step 4, the array, read in column-major order, starts with a clean area of 0s, ends with a clean area of 1s, and has a dirty area of at most <em>s</em><sup>2</sup> elements in the middle. (Again, one of the clean areas could be empty.)</p>
<p class="nl"><strong><em>f.</em></strong> Prove that steps 5–8 produce a fully sorted 0-1 output. Conclude that columnsort correctly sorts all inputs containing arbitrary values.</p>
<p class="nl"><strong><em>g.</em></strong> Now suppose that <em>s</em> does not divide <em>r</em>. Prove that after steps 1–3, the array consists of clean rows of 0s at the top, clean rows of 1s at the bottom, and at most 2<em>s</em> –1 dirty rows between them. (Once again, one of the clean areas could be empty.) How large must <em>r</em> be, compared with <em>s</em>, for columnsort to correctly sort when <em>s</em> does not divide <em>r</em>?</p>
<p class="nl"><strong><em>h.</em></strong> Suggest a simple change to step 1 that allows us to maintain the requirement that <em>r</em> ≥ 2<em>s</em><sup>2</sup> even when <em>s</em> does not divide <em>r</em>, and prove that with your change, columnsort correctly sorts.</p>
</section>
</section>
<p class="line1"/>
<section title="Chapter notes">
<p class="level1" id="h1-50"><strong>Chapter notes</strong></p>
<p class="noindent">The decision-tree model for studying comparison sorts was introduced by Ford and Johnson [<a epub:type="noteref" href="bibliography001.xhtml#endnote_150">150</a>]. Knuth’s comprehensive treatise on sorting [<a epub:type="noteref" href="bibliography001.xhtml#endnote_261">261</a>] covers many variations on the sorting problem, including the information-theoretic lower bound on the complexity of sorting given here. Ben-Or [<a epub:type="noteref" href="bibliography001.xhtml#endnote_46">46</a>] studied lower bounds for sorting using generalizations of the decision-tree model.</p>
<p>Knuth credits H. H. Seward with inventing counting sort in 1954, as well as with the idea of combining counting sort with radix sort. Radix sorting starting with the least significant digit appears to be a folk algorithm widely used by operators of <a id="p226"/>mechanical card-sorting machines. According to Knuth, the first published reference to the method is a 1929 document by L. J. Comrie describing punched-card equipment. Bucket sorting has been in use since 1956, when the basic idea was proposed by Isaac and Singleton [<a epub:type="noteref" href="bibliography001.xhtml#endnote_235">235</a>].</p>
<p>Munro and Raman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_338">338</a>] give a stable sorting algorithm that performs <em>O</em>(<em>n</em><sup>1+<em><span class="font1">ϵ</span></em></sup>) comparisons in the worst case, where 0 &lt; <em><span class="font1">ϵ</span></em> ≤ 1 is any fixed constant. Although any of the <em>O</em>(<em>n</em> lg <em>n</em>)-time algorithms make fewer comparisons, the algorithm by Munro and Raman moves data only <em>O</em>(<em>n</em>) times and operates in place.</p>
<p>The case of sorting <em>n b</em>-bit integers in <em>o</em>(<em>n</em> lg <em>n</em>) time has been considered by many researchers. Several positive results have been obtained, each under slightly different assumptions about the model of computation and the restrictions placed on the algorithm. All the results assume that the computer memory is divided into addressable <em>b</em>-bit words. Fredman and Willard [<a epub:type="noteref" href="bibliography001.xhtml#endnote_157">157</a>] introduced the fusion tree data structure and used it to sort <em>n</em> integers in <em>O</em>(<em>n</em> lg <em>n</em>/lg lg <em>n</em>) time. This bound was later improved to <img alt="art" src="images/Art_P339.jpg"/> time by Andersson [<a epub:type="noteref" href="bibliography001.xhtml#endnote_17">17</a>]. These algorithms require the use of multiplication and several precomputed constants. Andersson, Hagerup, Nilsson, and Raman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_18">18</a>] have shown how to sort <em>n</em> integers in <em>O</em>(<em>n</em> lg lg <em>n</em>) time without using multiplication, but their method requires storage that can be unbounded in terms of <em>n</em>. Using multiplicative hashing, we can reduce the storage needed to <em>O</em>(<em>n</em>), but then the <em>O</em>(<em>n</em> lg lg <em>n</em>) worst-case bound on the running time becomes an expected-time bound. Generalizing the exponential search trees of Andersson [<a epub:type="noteref" href="bibliography001.xhtml#endnote_17">17</a>], Thorup [<a epub:type="noteref" href="bibliography001.xhtml#endnote_434">434</a>] gave an <em>O</em>(<em>n</em>(lg lg <em>n</em>)<sup>2</sup>)-time sorting algorithm that does not use multiplication or randomization, and it uses linear space. Combining these techniques with some new ideas, Han [<a epub:type="noteref" href="bibliography001.xhtml#endnote_207">207</a>] improved the bound for sorting to <em>O</em>(<em>n</em> lg lg <em>n</em> lg lg lg <em>n</em>) time. Although these algorithms are important theoretical breakthroughs, they are all fairly complicated and at the present time seem unlikely to compete with existing sorting algorithms in practice.</p>
<p>The columnsort algorithm in Problem 8-7 is by Leighton [<a epub:type="noteref" href="bibliography001.xhtml#endnote_286">286</a>].</p>
<p class="footnote" id="footnote_1"><a href="#footnote_ref_1"><sup>1</sup></a> The choice of <em>r</em> = <span class="font1">⌊</span>lg <em>n</em><span class="font1">⌋</span> assumes that <em>n</em> &gt; 1. If <em>n</em> ≤ 1, there is nothing to sort.</p>
</section>
</section>
</div>
</body>
</html>