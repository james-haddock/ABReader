<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"/>
<title>Introduction to Algorithms</title>
<link href="css/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4a9ccac5-f2db-4081-af1f-a5a376b433e1" name="Adept.expected.resource"/>
</head>
<body>
<div class="body"><a id="p448"/>
<p class="line-c"/>
<section epub:type="bodymatter chapter" title="16 Amortized Analysis">
<p class="chapter-title"><a href="toc.xhtml#chap-16"><strong><span class="blue1">16        Amortized Analysis</span></strong></a></p>
<p class="noindent">Imagine that you join Buff’s Gym. Buff charges a membership fee of $60 per month, plus $3 for every time you use the gym. Because you are disciplined, you visit Buff’s Gym every day during the month of November. On top of the $60 monthly charge for November, you pay another 3 × $30 = $90 that month. Although you can think of your fees as a flat fee of $60 and another $90 in daily fees, you can think about it in another way. All together, you pay $150 over 30 days, or an average of $5 per day. When you look at your fees in this way, you are <span class="blue"><strong><em>amortizing</em></strong></span> the monthly fee over the 30 days of the month, spreading it out at $2 per day.</p>
<p>You can do the same thing when you analyze running times. In an <span class="blue"><strong><em>amortized analysis</em></strong></span>, you average the time required to perform a sequence of data-structure operations over all the operations performed. With amortized analysis, you show that if you average over a sequence of operations, then the average cost of an operation is small, even though a single operation within the sequence might be expensive. Amortized analysis differs from average-case analysis in that probability is not involved. An amortized analysis guarantees the <em>average performance of each operation in the worst case</em>.</p>
<p>The first three sections of this chapter cover the three most common techniques used in amortized analysis. <a href="chapter016.xhtml#Sec_16.1">Section 16.1</a> starts with aggregate analysis, in which you determine an upper bound <em>T</em> (<em>n</em>) on the total cost of a sequence of <em>n</em> operations. The average cost per operation is then <em>T</em> (<em>n</em>)/<em>n</em>. You take the average cost as the amortized cost of each operation, so that all operations have the same amortized cost.</p>
<p><a href="chapter016.xhtml#Sec_16.2">Section 16.2</a> covers the accounting method, in which you determine an amortized cost of each operation. When there is more than one type of operation, each type of operation may have a different amortized cost. The accounting method overcharges some operations early in the sequence, storing the overcharge as “prepaid <a id="p449"/>credit” on specific objects in the data structure. Later in the sequence, the credit pays for operations that are charged less than they actually cost.</p>
<p><a href="chapter016.xhtml#Sec_16.3">Section 16.3</a> discusses the potential method, which is like the accounting method in that you determine the amortized cost of each operation and may overcharge operations early on to compensate for undercharges later. The potential method maintains the credit as the “potential energy” of the data structure as a whole instead of associating the credit with individual objects within the data structure.</p>
<p>We’ll use use two examples in this chapter to examine each of these three methods. One is a stack with the additional operation M<small>ULTIPOP</small>, which pops several objects at once. The other is a binary counter that counts up from 0 by means of the single operation I<small>NCREMENT</small>.</p>
<p>While reading this chapter, bear in mind that the charges assigned during an amortized analysis are for analysis purposes only. They need not—and should not—appear in the code. If, for example, you assign a credit to an object <em>x</em> when using the accounting method, you have no need to assign an appropriate amount to some attribute, such as <em>x</em>.<em>credit</em>, in the code.</p>
<p>When you perform an amortized analysis, you often gain insight into a particular data structure, and this insight can help you optimize the design. For example, <a href="chapter016.xhtml#Sec_16.4">Section 16.4</a> will use the potential method to analyze a dynamically expanding and contracting table.</p>
<p class="line1"/>
<section title="16.1 Aggregate analysis">
<a id="Sec_16.1"/>
<p class="level1" id="h1-94"><a href="toc.xhtml#Rh1-94"><strong>16.1    Aggregate analysis</strong></a></p>
<p class="noindent">In <span class="blue"><strong><em>aggregate analysis</em></strong></span>, you show that for all <em>n</em>, a sequence of <em>n</em> operations takes <em>T</em> (<em>n</em>) <em>worst-case</em> time in total. In the worst case, the average cost, or <span class="blue"><strong><em>amortized cost</em></strong></span>, per operation is therefore <em>T</em> (<em>n</em>)/<em>n</em>. This amortized cost applies to each operation, even when there are several types of operations in the sequence. The other two methods we shall study in this chapter, the accounting method and the potential method, may assign different amortized costs to different types of operations.</p>
<p class="level4"><strong>Stack operations</strong></p>
<p class="noindent">As the first example of aggregate analysis, let’s analyze stacks that have been augmented with a new operation. <a href="chapter010.xhtml#Sec_10.1.3">Section 10.1.3</a> presented the two fundamental stack operations, each of which takes <em>O</em>(1) time:</p>
<p class="para-hang1">P<small>USH</small>(<em>S</em>, <em>x</em>) pushes object <em>x</em> onto stack <em>S</em>.</p>
<p class="para-hang1">P<small>OP</small>(<em>S</em>) pops the top of stack <em>S</em> and returns the popped object. Calling P<small>OP</small> on an empty stack generates an error.</p>
<a id="p450"/>
<div class="divimage">
<p class="fig-imga" id="Fig_16-1"><img alt="art" src="images/Art_P506.jpg"/></p>
<p class="caption"><strong>Figure 16.1</strong> The action of M<small>ULTIPOP</small> on a stack <em>S</em>, shown initially in <strong>(a)</strong>. The top 4 objects are popped by M<small>ULTIPOP</small>(<em>S</em>, 4), whose result is shown in <strong>(b)</strong>. The next operation is M<small>ULTIPOP</small>(<em>S</em>, 7), which empties the stack—shown in <strong>(c)</strong>—since fewer than 7 objects remained.</p>
</div>
<p class="noindent">Since each of these operations runs in <em>O</em>(1) time, let us consider the cost of each to be 1. The total cost of a sequence of <em>n</em> P<small>USH</small> and P<small>OP</small> operations is therefore <em>n</em>, and the actual running time for <em>n</em> operations is therefore Θ(<em>n</em>).</p>
<p>Now let’s add the stack operation M<small>ULTIPOP</small>(<em>S</em>, <em>k</em>), which removes the <em>k</em> top objects of stack <em>S</em>, popping the entire stack if the stack contains fewer than <em>k</em> objects. Of course, the procedure assumes that <em>k</em> is positive, and otherwise, the M<small>ULTIPOP</small> operation leaves the stack unchanged. In the pseudocode for M<small>ULTIPOP</small>, the operation S<small>TACK</small>-E<small>MPTY</small> returns T<small>RUE</small> if there are no objects currently on the stack, and <small>FALSE</small> otherwise. <a href="chapter016.xhtml#Fig_16-1">Figure 16.1</a> shows an example of M<small>ULTIPOP</small>.</p>
<div class="pull-quote1">
<p class="box-heading">M<small>ULTIPOP</small>(<em>S</em>, <em>k</em>)</p>
<table class="table1c">
<tr>
<td class="td1w"><span class="x-small">1</span></td>
<td class="td1"><p class="noindent"><strong>while</strong> not S<small>TACK</small>-E<small>MPTY</small>(<em>S</em>) and <em>k</em> &gt; 0</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">2</span></td>
<td class="td1"><p class="p2">P<small>OP</small>(<em>S</em>)</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">3</span></td>
<td class="td1"><p class="p2"><em>k</em> = <em>k</em> − 1</p></td>
</tr>
</table>
</div>
<p class="space-break">What is the running time of M<small>ULTIPOP</small>(<em>S</em>, <em>k</em>) on a stack of <em>s</em> objects? The actual running time is linear in the number of P<small>OP</small> operations actually executed, and thus we can analyze M<small>ULTIPOP</small> in terms of the abstract costs of 1 each for P<small>USH</small> and P<small>OP</small>. The number of iterations of the <strong>while</strong> loop is the number min {<em>s</em>, <em>k</em>} of objects popped off the stack. Each iteration of the loop makes one call to P<small>OP</small> in line 2. Thus, the total cost of M<small>ULTIPOP</small> is min {<em>s</em>, <em>k</em>}, and the actual running time is a linear function of this cost.</p>
<p>Now let’s analyze a sequence of <em>n</em> P<small>USH</small>, P<small>OP</small>, and M<small>ULTIPOP</small> operations on an initially empty stack. The worst-case cost of a M<small>ULTIPOP</small> operation in the sequence is <em>O</em>(<em>n</em>), since the stack size is at most <em>n</em>. The worst-case time of any stack operation is therefore <em>O</em>(<em>n</em>), and hence a sequence of <em>n</em> operations costs <em>O</em>(<em>n</em><sup>2</sup>), since the sequence contains at most <em>n</em> M<small>ULTIPOP</small> operations costing <em>O</em>(<em>n</em>) each. <a id="p451"/>Although this analysis is correct, the <em>O</em>(<em>n</em><sup>2</sup>) result, which came from considering the worst-case cost of each operation individually, is not tight.</p>
<p>Yes, a single M<small>ULTIPOP</small> might be expensive, but an aggregate analysis shows that any sequence of <em>n</em> P<small>USH</small>, P<small>OP</small>, and M<small>ULTIPOP</small> operations on an initially empty stack has an upper bound on its cost of <em>O</em>(<em>n</em>). Why? An object cannot be popped from the stack unless it was first pushed. Therefore, the number of times that P<small>OP</small> can be called on a nonempty stack, including calls within M<small>ULTIPOP</small>, is at most the number of P<small>USH</small> operations, which is at most <em>n</em>. For any value of <em>n</em>, any sequence of <em>n</em> P<small>USH</small>, P<small>OP</small>, and M<small>ULTIPOP</small> operations takes a total of <em>O</em>(<em>n</em>) time. Averaging over the <em>n</em> operations gives an average cost per operation of <em>O</em>(<em>n</em>)/<em>n</em> = <em>O</em>(1). Aggregate analysis assigns the amortized cost of each operation to be the average cost. In this example, therefore, all three stack operations have an amortized cost of <em>O</em>(1).</p>
<p>To recap: although the average cost, and hence the running time, of a stack operation is <em>O</em>(1), the analysis did not rely on probabilistic reasoning. Instead, the analysis yielded a <em>worst-case</em> bound of <em>O</em>(<em>n</em>) on a sequence of <em>n</em> operations. Dividing this total cost by <em>n</em> yielded that the average cost per operation—that is, the amortized cost—is <em>O</em>(1).</p>
<p class="level4"><strong>Incrementing a binary counter</strong></p>
<p class="noindent">As another example of aggregate analysis, consider the problem of implementing a <em>k</em>-bit binary counter that counts upward from 0. An array <em>A</em>[0 : <em>k</em> − 1] of bits represents the counter. A binary number <em>x</em> that is stored in the counter has its lowest-order bit in <em>A</em>[0] and its highest-order bit in <em>A</em>[<em>k</em> − 1], so that <img alt="art" src="images/Art_P507.jpg"/>. Initially, <em>x</em> = 0, and thus <em>A</em>[<em>i</em>] = 0 for <em>i</em> = 0, 1, … , <em>k</em> − 1. To add 1 (modulo 2<em><sup>k</sup></em>) to the value in the counter, call the I<small>NCREMENT</small> procedure.</p>
<div class="pull-quote1">
<p class="box-heading">I<small>NCREMENT</small>(<em>A</em>, <em>k</em>)</p>
<table class="table1c">
<tr>
<td class="td1w"><span class="x-small">1</span></td>
<td class="td1"><p class="noindent"><em>i</em> = 0</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">2</span></td>
<td class="td1"><p class="noindent"><strong>while</strong> <em>i &lt; k</em> and <em>A</em>[<em>i</em>] == 1</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">3</span></td>
<td class="td1"><p class="p2"><em>A</em>[<em>i</em>] = 0</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">4</span></td>
<td class="td1"><p class="p2"><em>i</em> = <em>i</em> + 1</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">5</span></td>
<td class="td1"><p class="noindent"><strong>if</strong> <em>i &lt; k</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">6</span></td>
<td class="td1"><p class="p2"><em>A</em>[<em>i</em>] = 1</p></td>
</tr>
</table>
</div>
<p class="space-break"><a href="chapter016.xhtml#Fig_16-2">Figure 16.2</a> shows what happens to a binary counter when I<small>NCREMENT</small> is called 16 times, starting with the initial value 0 and ending with the value 16. Each iteration of the <strong>while</strong> loop in lines 2–4 adds a 1 into position <em>i</em>. If <em>A</em>[<em>i</em>] = 1, then adding 1 flips the bit to 0 in position <em>i</em> and yields a carry of 1, to be added into <a id="p452"/>position <em>i</em> + 1 during the next iteration of the loop. Otherwise, the loop ends, and then, if <em>i</em> &lt; <em>k</em>, <em>A</em>[<em>i</em>] must be 0, so that line 6 adds a 1 into position <em>i</em>, flipping the 0 to a 1. If the loop ends with <em>i</em> = <em>k</em>, then the call of I<small>NCREMENT</small> flipped all <em>k</em> bits from 1 to 0. The cost of each I<small>NCREMENT</small> operation is linear in the number of bits flipped.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_16-2"><img alt="art" src="images/Art_P508.jpg"/></p>
<p class="caption"><strong>Figure 16.2</strong> An 8-bit binary counter as its value goes from 0 to 16 by a sequence of 16 I<small>NCREMENT</small> operations. Bits that flip to achieve the next value are shaded in blue. The running cost for flipping bits is shown at the right. The total cost is always less than twice the total number of I<small>NCREMENT</small> operations.</p>
</div>
<p>As with the stack example, a cursory analysis yields a bound that is correct but not tight. A single execution of I<small>NCREMENT</small> takes Θ(<em>k</em>) time in the worst case, in which all the bits in array <em>A</em> are 1. Thus, a sequence of <em>n</em> I<small>NCREMENT</small> operations on an initially zero counter takes <em>O</em>(<em>nk</em>) time in the worst case.</p>
<p>Although a single call of I<small>NCREMENT</small> might flip all <em>k</em> bits, not all bits flip upon each call. (Note the similarity to M<small>ULTIPOP</small>, where a single call might pop many objects, but not every call pops many objects.) As <a href="chapter016.xhtml#Fig_16-2">Figure 16.2</a> shows, <em>A</em>[0] does flip each time I<small>NCREMENT</small> is called. The next bit up, <em>A</em>[1], flips only every other time: a sequence of <em>n</em> I<small>NCREMENT</small> operations on an initially zero counter causes <em>A</em>[1] to flip <span class="font1">⌊</span><em>n</em>/2<span class="font1">⌋</span> times. Similarly, bit <em>A</em>[2] flips only every fourth time, or <span class="font1">⌊</span><em>n</em>/4<span class="font1">⌋</span> times in a sequence of <em>n</em> I<small>NCREMENT</small> operations. In general, for <em>i</em> = 0, 1, … , <em>k</em> − 1, bit <em>A</em>[<em>i</em>] flips <span class="font1">⌊</span><em>n</em>/2<sup><em>i</em></sup><span class="font1">⌋</span> times in a sequence of <em>n</em> I<small>NCREMENT</small> operations on an initially zero counter. For <em>i</em> ≥ <em>k</em>, bit <em>A</em>[<em>i</em>] does not exist, and so it cannot flip. The total number <a id="p453"/>of flips in the sequence is thus</p>
<p class="eql"><img alt="art" src="images/Art_P509.jpg"/></p>
<p class="noindent">by equation (A.7) on page 1142. Thus, a sequence of <em>n</em> I<small>NCREMENT</small> operations on an initially zero counter takes <em>O</em>(<em>n</em>) time in the worst case. The average cost of each operation, and therefore the amortized cost per operation, is <em>O</em>(<em>n</em>)/<em>n</em> = <em>O</em>(1).</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>16.1-1</em></strong></p>
<p class="noindent">If the set of stack operations includes a M<small>ULTIPUSH</small> operation, which pushes <em>k</em> items onto the stack, does the <em>O</em>(1) bound on the amortized cost of stack operations continue to hold?</p>
<p class="level3"><strong><em>16.1-2</em></strong></p>
<p class="noindent">Show that if a D<small>ECREMENT</small> operation is included in the <em>k</em>-bit counter example, <em>n</em> operations can cost as much as Θ(<em>nk</em>) time.</p>
<p class="level3"><strong><em>16.1-3</em></strong></p>
<p class="noindent">Use aggregate analysis to determine the amortized cost per operation for a sequence of <em>n</em> operations on a data structure in which the <em>i</em>th operation costs <em>i</em> if <em>i</em> is an exact power of 2, and 1 otherwise.</p>
</section>
<p class="line1"/>
<section title="16.2 The accounting method">
<a id="Sec_16.2"/>
<p class="level1" id="h1-95"><a href="toc.xhtml#Rh1-95"><strong>16.2    The accounting method</strong></a></p>
<p class="noindent">In the <span class="blue"><strong><em>accounting method</em></strong></span> of amortized analysis, you assign differing charges to different operations, with some operations charged more or less than they actually cost. The amount that you charge an operation is its <span class="blue"><strong><em>amortized cost</em></strong></span>. When an operation’s amortized cost exceeds its actual cost, you assign the difference to specific objects in the data structure as <span class="blue"><strong><em>credit</em></strong></span>. Credit can help pay for later operations whose amortized cost is less than their actual cost. Thus, you can view the amortized cost of an operation as being split between its actual cost and credit that is either deposited or used up. Different operations may have different amortized costs. This method differs from aggregate analysis, in which all operations have the same amortized cost.</p>
<p>You must choose the amortized costs of operations carefully. If you want to use amortized costs to show that in the worst case the average cost per operation is <a id="p454"/>small, you must ensure that the total amortized cost of a sequence of operations provides an upper bound on the total actual cost of the sequence. Moreover, as in aggregate analysis, the upper bound must apply to all sequences of operations. Let’s denote the actual cost of the <em>i</em>th operation by <em>c<sub>i</sub></em> and the amortized cost of the <em>i</em>th operation by <em><span class="font1">ĉ</span><sub>i</sub></em>. Then you need to have</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P510.jpg"/></p>
<p class="noindent">for all sequences of <em>n</em> operations. The total credit stored in the data structure is the difference between the total amortized cost and the total actual cost, or <img alt="art" src="images/Art_P511.jpg"/>. By inequality (16.1), the total credit associated with the data structure must be nonnegative at all times. If you ever allowed the total credit to become negative (the result of undercharging early operations with the promise of repaying the account later on), then the total amortized costs incurred at that time would be below the total actual costs incurred. In that case, for the sequence of operations up to that time, the total amortized cost would not be an upper bound on the total actual cost. Thus, you must take care that the total credit in the data structure never becomes negative.</p>
<p class="level4"><strong>Stack operations</strong></p>
<p class="noindent">To illustrate the accounting method of amortized analysis, we return to the stack example. Recall that the actual costs of the operations were</p>
<table class="table3a">
<tr>
<td class="td1">P<small>USH</small></td>
<td class="td1">1,</td>
</tr>
<tr>
<td class="td1">P<small>OP</small></td>
<td class="td1">1,</td>
</tr>
<tr>
<td class="td1">M<small>ULTIPOP</small></td>
<td class="td1">min {<em>s</em>, <em>k</em>},</td>
</tr>
</table>
<p class="noindent">where <em>k</em> is the argument supplied to M<small>ULTIPOP</small> and <em>s</em> is the stack size when it is called. Let us assign the following amortized costs:</p>
<table class="table1a">
<tr>
<td class="td1w2">P<small>USH</small></td>
<td class="td1">2,</td>
</tr>
<tr>
<td class="td1">P<small>OP</small></td>
<td class="td1">0,</td>
</tr>
<tr>
<td class="td1">M<small>ULTIPOP</small></td>
<td class="td1">0.</td>
</tr>
</table>
<p class="noindent">The amortized cost of M<small>ULTIPOP</small> is a constant (0), whereas the actual cost is variable, and thus all three amortized costs are constant. In general, the amortized costs of the operations under consideration may differ from each other, and they may even differ asymptotically.</p>
<p>Now let’s see how to pay for any sequence of stack operations by charging the amortized costs. Let $1 represent each unit of cost. At first, the stack is empty. Recall the analogy of <a href="chapter010.xhtml#Sec_10.1.3">Section 10.1.3</a> between the stack data structure and a stack of plates in a cafeteria. Upon pushing a plate onto the stack, use $1 to pay the <a id="p455"/>actual cost of the push, leaving a credit of $1 (out of the $2 charged). Place that $1 of credit on top of the plate. At any point in time, every plate on the stack has $1 of credit on it.</p>
<p>The $1 stored on the plate serves to prepay the cost of popping the plate from the stack. A P<small>OP</small> operation incurs no charge: pay the actual cost of popping a plate by taking the $1 of credit off the plate. Thus, by charging the P<small>USH</small> operation a little bit more, we can view the P<small>OP</small> operation as free.</p>
<p>Moreover, the M<small>ULTIPOP</small> operation also incurs no charge, since it’s just repeated P<small>OP</small> operations, each of which is free. If a M<small>ULTIPOP</small> operation pops <em>k</em> plates, then the actual cost is paid by the <em>k</em> dollars stored on the <em>k</em> plates. Because each plate on the stack has $1 of credit on it, and the stack always has a nonnegative number of plates, the amount of credit is always nonnegative. Thus, for <em>any</em> sequence of <em>n</em> P<small>USH</small>, P<small>OP</small>, and M<small>ULTIPOP</small> operations, the total amortized cost is an upper bound on the total actual cost. Since the total amortized cost is <em>O</em>(<em>n</em>), so is the total actual cost.</p>
<p class="level4"><strong>Incrementing a binary counter</strong></p>
<p class="noindent">As another illustration of the accounting method, let’s analyze the I<small>NCREMENT</small> operation on a binary counter that starts at 0. Recall that the running time of this operation is proportional to the number of bits flipped, which serves as the cost for this example. Again, we’ll use $1 to represent each unit of cost (the flipping of a bit in this example).</p>
<p>For the amortized analysis, the amortized cost to set a 0-bit to 1 is $2. When a bit is set to 1, $1 of the $2 pays to actually set the bit. The second $1 resides on the bit as credit to be used later if and when the bit is reset to 0. At any point in time, every 1-bit in the counter has $1 of credit on it, and thus resetting a bit to 0 can be viewed as costing nothing, and the $1 on the bit prepays for the reset.</p>
<p>Here is how to determine the amortized cost of I<small>NCREMENT</small>. The cost of resetting the bits to 0 within the <strong>while</strong> loop is paid for by the dollars on the bits that are reset. The I<small>NCREMENT</small> procedure sets at most one bit to 1, in line 6, and therefore the amortized cost of an I<small>NCREMENT</small> operation is at most $2. The number of 1-bits in the counter never becomes negative, and thus the amount of credit stays nonnegative at all times. Thus, for <em>n</em> I<small>NCREMENT</small> operations, the total amortized cost is <em>O</em>(<em>n</em>), which bounds the total actual cost.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>16.2-1</em></strong></p>
<p class="noindent">You perform a sequence of P<small>USH</small> and P<small>OP</small> operations on a stack whose size never exceeds <em>k</em>. After every <em>k</em> operations, a copy of the entire stack is made automatically, <a id="p456"/>for backup purposes. Show that the cost of <em>n</em> stack operations, including copying the stack, is <em>O</em>(<em>n</em>) by assigning suitable amortized costs to the various stack operations.</p>
<p class="level3"><strong><em>16.2-2</em></strong></p>
<p class="noindent">Redo Exercise 16.1-3 using an accounting method of analysis.</p>
<p class="level3"><strong><em>16.2-3</em></strong></p>
<p class="noindent">You wish not only to increment a counter but also to reset it to 0 (i.e., make all bits in it 0). Counting the time to examine or modify a bit as Θ(1), show how to implement a counter as an array of bits so that any sequence of <em>n</em> I<small>NCREMENT</small> and R<small>ESET</small> operations takes <em>O</em>(<em>n</em>) time on an initially zero counter. (<em>Hint</em>: Keep a pointer to the high-order 1.)</p>
</section>
<p class="line1"/>
<section title="16.3 The potential method">
<a id="Sec_16.3"/>
<p class="level1" id="h1-96"><a href="toc.xhtml#Rh1-96"><strong>16.3    The potential method</strong></a></p>
<p class="noindent">Instead of representing prepaid work as credit stored with specific objects in the data structure, the <span class="blue"><strong><em>potential method</em></strong></span> of amortized analysis represents the prepaid work as “potential energy,” or just “potential,” which can be released to pay for future operations. The potential applies to the data structure as a whole rather than to specific objects within the data structure.</p>
<p>The potential method works as follows. Starting with an initial data structure <em>D</em><sub>0</sub>, a sequence of <em>n</em> operations occurs. For each <em>i</em> = 1, 2, … , <em>n</em>, let <em>c<sub>i</sub></em> be the actual cost of the <em>i</em>th operation and <em>D<sub>i</sub></em> be the data structure that results after applying the <em>i</em>th operation to data structure <em>D</em><sub><em>i</em>−1</sub>. A <span class="blue"><strong><em>potential function</em></strong></span> Φ maps each data structure <em>D<sub>i</sub></em> to a real number Φ(<em>D<sub>i</sub></em>), which is the <span class="blue"><strong><em>potential</em></strong></span> associated with <em>D<sub>i</sub></em>. The <span class="blue"><strong><em>amortized cost</em></strong></span> <em><span class="font1">ĉ</span><sub>i</sub></em> of the <em>i</em>th operation with respect to potential function Φ is defined by</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P512.jpg"/></p>
<p class="noindent">The amortized cost of each operation is therefore its actual cost plus the change in potential due to the operation. By equation (16.2), the total amortized cost of the <em>n</em> operations is</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P513.jpg"/></p>
<a id="p457"/>
<p class="noindent">The second equation follows from equation (A.12) on page 1143 because the Φ(<em>D<sub>i</sub></em>) terms telescope.</p>
<p>If you can define a potential function Φ so that Φ(<em>D<sub>n</sub></em>) ≥ Φ(<em>D</em><sub>0</sub>), then the total amortized cost <img alt="art" src="images/Art_P514.jpg"/> gives an upper bound on the total actual cost <img alt="art" src="images/Art_P515.jpg"/>. In practice, you don’t always know how many operations might be performed. Therefore, if you require that Φ(<em>D<sub>i</sub></em>) ≥ Φ(<em>D</em><sub>0</sub>) for all <em>i</em>, then you guarantee, as in the accounting method, that you’ve paid in advance. It’s usually simplest to just define Φ(<em>D</em><sub>0</sub>) to be 0 and then show that Φ(<em>D<sub>i</sub></em>) ≥ 0 for all <em>i</em>. (See Exercise 16.3-1 for an easy way to handle cases in which Φ(<em>D</em><sub>0</sub>) ≠ 0.)</p>
<p>Intuitively, if the potential difference Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>) of the <em>i</em>th operation is positive, then the amortized cost <em><span class="font1">ĉ</span><sub>i</sub></em> represents an overcharge to the <em>i</em>th operation, and the potential of the data structure increases. If the potential difference is negative, then the amortized cost represents an undercharge to the <em>i</em>th operation, and the decrease in the potential pays for the actual cost of the operation.</p>
<p>The amortized costs defined by equations (16.2) and (16.3) depend on the choice of the potential function Φ. Different potential functions may yield different amortized costs, yet still be upper bounds on the actual costs. You will often find trade-offs that you can make in choosing a potential function. The best potential function to use depends on the desired time bounds.</p>
<p class="level4"><strong>Stack operations</strong></p>
<p class="noindent">To illustrate the potential method, we return once again to the example of the stack operations P<small>USH</small>, P<small>OP</small>, and M<small>ULTIPOP</small>. We define the potential function Φ on a stack to be the number of objects in the stack. The potential of the empty initial stack <em>D</em><sub>0</sub> is Φ(<em>D</em><sub>0</sub>) = 0. Since the number of objects in the stack is never negative, the stack <em>D<sub>i</sub></em> that results after the <em>i</em>th operation has nonnegative potential, and thus</p>
<table class="table2b">
<tr>
<td class="td2">Φ(<em>D<sub>i</sub></em>)</td>
<td class="td2">≥</td>
<td class="td2">0</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">Φ(<em>D</em><sub>0</sub>).</td>
</tr>
</table>
<p class="noindent">The total amortized cost of <em>n</em> operations with respect to Φ therefore represents an upper bound on the actual cost.</p>
<p>Now let’s compute the amortized costs of the various stack operations. If the <em>i</em>th operation on a stack containing <em>s</em> objects is a P<small>USH</small> operation, then the potential difference is</p>
<table class="table2b">
<tr>
<td class="td2">Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>)</td>
<td class="td2">=</td>
<td class="td2">(<em>s</em> + 1) − <em>s</em></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">1.</td>
</tr>
</table>
<p class="noindent">By equation (16.2), the amortized cost of this P<small>USH</small> operation is</p>
<a id="p458"/>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">1 + 1</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">2.</td>
</tr>
</table>
<p class="noindent">Suppose that the <em>i</em>th operation on the stack of <em>s</em> objects is M<small>ULTIPOP</small>(<em>S</em>, <em>k</em>), which causes <em>k</em>′ = min {<em>s</em>, <em>k</em>} objects to be popped off the stack. The actual cost of the operation is <em>k</em>′, and the potential difference is</p>
<p class="eql">Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>) = −<em>k</em>′.</p>
<p class="noindent">Thus, the amortized cost of the M<small>ULTIPOP</small> operation is</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>k</em>′ − <em>k</em>′</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">0.</td>
</tr>
</table>
<p class="noindent">Similarly, the amortized cost of an ordinary P<small>OP</small> operation is 0.</p>
<p>The amortized cost of each of the three operations is <em>O</em>(1), and thus the total amortized cost of a sequence of <em>n</em> operations is <em>O</em>(<em>n</em>). Since Φ(<em>D<sub>i</sub></em>) ≥ Φ(<em>D</em><sub>0</sub>), the total amortized cost of <em>n</em> operations is an upper bound on the total actual cost. The worst-case cost of <em>n</em> operations is therefore <em>O</em>(<em>n</em>).</p>
<p class="level4"><strong>Incrementing a binary counter</strong></p>
<p class="noindent">As another example of the potential method, we revisit incrementing a <em>k</em>-bit binary counter. This time, the potential of the counter after the <em>i</em>th I<small>NCREMENT</small> operation is defined to be the number of 1-bits in the counter after the <em>i</em>th operation, which we’ll denote by <em>b<sub>i</sub></em>.</p>
<p>Here is how to compute the amortized cost of an I<small>NCREMENT</small> operation. Suppose that the <em>i</em>th I<small>NCREMENT</small> operation resets <em>t<sub>i</sub></em> bits to 0. The actual cost <em>c<sub>i</sub></em> of the operation is therefore at most <em>t<sub>i</sub></em> + 1, since in addition to resetting <em>t<sub>i</sub></em> bits, it sets at most one bit to 1. If <em>b<sub>i</sub></em> = 0, then the <em>i</em>th operation had reset all <em>k</em> bits to 0, and so <em>b</em><sub><em>i</em>−1</sub> = <em>t<sub>i</sub></em> = <em>k</em>. If <em>b<sub>i</sub> &gt;</em> 0, then <em>b<sub>i</sub></em> = <em>b</em><sub><em>i</em>−1</sub> −<em>t<sub>i</sub></em> +1. In either case, <em>b<sub>i</sub></em> ≤ <em>b</em><sub><em>i</em>−1</sub> − <em>t<sub>i</sub></em> + 1, and the potential difference is</p>
<table class="table2b">
<tr>
<td class="td2">Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>)</td>
<td class="td2">≤</td>
<td class="td2">(<em>b</em><sub><em>i</em>−1</sub> − <em>t<sub>i</sub></em> + 1) − <em>b</em><sub><em>i</em>−1</sub></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">1 − <em>t<sub>i</sub></em>.</td>
</tr>
</table>
<p class="noindent">The amortized cost is therefore</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + Φ(<em>D<sub>i</sub></em>) − Φ(<em>D</em><sub><em>i</em>−1</sub>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">≤</td>
<td class="td2">(<em>t<sub>i</sub></em> + 1) + (1 − <em>t<sub>i</sub></em>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">2.</td>
</tr>
</table>
<a id="p459"/>
<p class="noindent">If the counter starts at 0, then Φ(<em>D</em><sub>0</sub>) = 0. Since Φ(<em>D<sub>i</sub></em>) ≥ 0 for all <em>i</em>, the total amortized cost of a sequence of <em>n</em> I<small>NCREMENT</small> operations is an upper bound on the total actual cost, and so the worst-case cost of <em>n</em> I<small>NCREMENT</small> operations is <em>O</em>(<em>n</em>).</p>
<p>The potential method provides a simple and clever way to analyze the counter even when it does not start at 0. The counter starts with <em>b</em><sub>0</sub> 1-bits, and after <em>n</em> I<small>NCREMENT</small> operations it has <em>b<sub>n</sub></em> 1-bits, where 0 ≤ <em>b</em><sub>0</sub>, <em>b<sub>n</sub></em> ≤ <em>k</em>. Rewrite equation (16.3) as</p>
<p class="eql"><img alt="art" src="images/Art_P516.jpg"/></p>
<p class="noindent">Since Φ(<em>D</em><sub>0</sub>) = <em>b</em><sub>0</sub>, Φ(<em>D<sub>n</sub></em>) = <em>b<sub>n</sub></em>, and <em><span class="font1">ĉ</span><sub>i</sub></em> ≤ 2 for all 1 ≤ <em>i</em> ≤ <em>n</em>, the total actual cost of <em>n</em> I<small>NCREMENT</small> operations is</p>
<p class="eql"><img alt="art" src="images/Art_P517.jpg"/></p>
<p class="noindent">In particular, <em>b</em><sub>0</sub> ≤ <em>k</em> means that as long as <em>k</em> = <em>O</em>(<em>n</em>), the total actual cost is <em>O</em>(<em>n</em>). In other words, if at least <em>n</em> = Ω(<em>k</em>) I<small>NCREMENT</small> operations occur, the total actual cost is <em>O</em>(<em>n</em>), no matter what initial value the counter contains.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>16.3-1</em></strong></p>
<p class="noindent">Suppose you have a potential function Φ such that Φ(<em>D<sub>i</sub></em>) ≥ Φ(<em>D</em><sub>0</sub>) for all <em>i</em>, but Φ(<em>D</em><sub>0</sub>) ≠ 0. Show that there exists a potential function Φ′ such that Φ′(<em>D</em><sub>0</sub>) = 0, Φ′(<em>D<sub>i</sub></em>) ≥ 0 for all <em>i</em> ≥ 1, and the amortized costs using Φ′ are the same as the amortized costs using Φ.</p>
<p class="level3"><strong><em>16.3-2</em></strong></p>
<p class="noindent">Redo Exercise 16.1-3 using a potential method of analysis.</p>
<p class="level3"><strong><em>16.3-3</em></strong></p>
<p class="noindent">Consider an ordinary binary min-heap data structure supporting the instructions I<small>NSERT</small> and E<small>XTRACT</small>-M<small>IN</small> that, when there are <em>n</em> items in the heap, implements each operation in <em>O</em>(lg <em>n</em>) worst-case time. Give a potential function Φ such that the amortized cost of I<small>NSERT</small> is <em>O</em>(lg <em>n</em>) and the amortized cost of E<small>XTRACT</small>-M<small>IN</small> is <em>O</em>(1), and show that your potential function yields these amortized time bounds. Note that in the analysis, <em>n</em> is the number of items currently in the heap, and you do not know a bound on the maximum number of items that can ever be stored in the heap.</p>
<a id="p460"/>
<p class="level3"><strong><em>16.3-4</em></strong></p>
<p class="noindent">What is the total cost of executing <em>n</em> of the stack operations P<small>USH</small>, P<small>OP</small>, and M<small>ULTIPOP</small>, assuming that the stack begins with <em>s</em><sub>0</sub> objects and finishes with <em>s<sub>n</sub></em> objects?</p>
<p class="level3"><strong><em>16.3-5</em></strong></p>
<p class="noindent">Show how to implement a queue with two ordinary stacks (Exercise 10.1-7) so that the amortized cost of each E<small>NQUEUE</small> and each D<small>EQUEUE</small> operation is <em>O</em>(1).</p>
<p class="level3"><strong><em>16.3-6</em></strong></p>
<p class="noindent">Design a data structure to support the following two operations for a dynamic multiset <em>S</em> of integers, which allows duplicate values:</p>
<p class="para-hang1">I<small>NSERT</small>(<em>S</em>, <em>x</em>) inserts <em>x</em> into <em>S</em>.</p>
<p class="para-hang1">D<small>ELETE</small>-LA<small>RGER</small>-H<small>ALF</small>(<em>S</em>) deletes the largest <span class="font1">⌈</span>|<em>S</em>|/2<span class="font1">⌉</span> elements from <em>S</em>.</p>
<p class="noindent1-top">Explain how to implement this data structure so that any sequence of <em>m</em> I<small>NSERT</small> and D<small>ELETE</small>-L<small>ARGER</small>-H<small>ALF</small> operations runs in <em>O</em>(<em>m</em>) time. Your implementation should also include a way to output the elements of <em>S</em> in <em>O</em>(|<em>S</em>|) time.</p>
</section>
<p class="line1"/>
<section title="16.4 Dynamic tables">
<a id="Sec_16.4"/>
<p class="level1" id="h1-97"><a href="toc.xhtml#Rh1-97"><strong>16.4    Dynamic tables</strong></a></p>
<p class="noindent">When you design an application that uses a table, you do not always know in advance how many items the table will hold. You might allocate space for the table, only to find out later that it is not enough. The program must then reallocate the table with a larger size and copy all items stored in the original table over into the new, larger table. Similarly, if many items have been deleted from the table, it might be worthwhile to reallocate the table with a smaller size. This section studies this problem of dynamically expanding and contracting a table. Amortized analyses will show that the amortized cost of insertion and deletion is only <em>O</em>(1), even though the actual cost of an operation is large when it triggers an expansion or a contraction. Moreover, you’ll see how to guarantee that the unused space in a dynamic table never exceeds a constant fraction of the total space.</p>
<p>Let’s assume that the dynamic table supports the operations T<small>ABLE</small>-I<small>NSERT</small> and T<small>ABLE</small>-D<small>ELETE</small>. T<small>ABLE</small>-I<small>NSERT</small> inserts into the table an item that occupies a single <span class="blue"><strong><em>slot</em></strong></span>, that is, a space for one item. Likewise, T<small>ABLE</small>-D<small>ELETE</small> removes an item from the table, thereby freeing a slot. The details of the data-structuring method used to organize the table are unimportant: it could be a stack (<a href="chapter010.xhtml#Sec_10.1.3">Section 10.1.3</a>), a heap (<a href="chapter006.xhtml">Chapter 6</a>), a hash table (<a href="chapter011.xhtml">Chapter 11</a>), or something else.</p>
<a id="p461"/>
<p>It is convenient to use a concept introduced in <a href="chapter011.xhtml#Sec_11.2">Section 11.2</a>, where we analyzed hashing. The <span class="blue"><strong><em>load factor</em></strong></span> <em>α</em>(<em>T</em>) of a nonempty table <em>T</em> is defined as the number of items stored in the table divided by the size (number of slots) of the table. An empty table (one with no slots) has size 0, and its load factor is defined to be 1. If the load factor of a dynamic table is bounded below by a constant, the unused space in the table is never more than a constant fraction of the total amount of space.</p>
<p>We start by analyzing a dynamic table that allows only insertion and then move on to the more general case that supports both insertion and deletion.</p>
<section title="16.4.1 Table expansion">
<p class="level2" id="Sec_16.4.1"><strong>16.4.1    Table expansion</strong></p>
<p class="noindent">Let’s assume that storage for a table is allocated as an array of slots. A table fills up when all slots have been used or, equivalently, when its load factor is 1.<sup><a epub:type="footnote" href="#footnote_1" id="footnote_ref_1">1</a></sup> In some software environments, upon an attempt to insert an item into a full table, the only alternative is to abort with an error. The scenario in this section assumes, however, that the software environment, like many modern ones, provides a memory-management system that can allocate and free blocks of storage on request. Thus, upon inserting an item into a full table, the system can <span class="blue"><strong><em>expand</em></strong></span> the table by allocating a new table with more slots than the old table had. Because the table must always reside in contiguous memory, the system must allocate a new array for the larger table and then copy items from the old table into the new table.</p>
<p>A common heuristic allocates a new table with twice as many slots as the old one. If the only table operations are insertions, then the load factor of the table is always at least 1/2, and thus the amount of wasted space never exceeds half the total space in the table.</p>
<p>The T<small>ABLE</small>-I<small>NSERT</small> procedure on the following page assumes that <em>T</em> is an object representing the table. The attribute <em>T</em>.<em>table</em> contains a pointer to the block of storage representing the table, <em>T</em>.<em>num</em> contains the number of items in the table, and <em>T</em>.<em>size</em> gives the total number of slots in the table. Initially, the table is empty: <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em> = 0.</p>
<p>There are two types of insertion here: the T<small>ABLE</small>-I<small>NSERT</small> procedure itself and the <span class="blue"><strong><em>elementary insertion</em></strong></span> into a table in lines 6 and 10. We can analyze the running time of T<small>ABLE</small>-I<small>NSERT</small> in terms of the number of elementary insertions by assigning a cost of 1 to each elementary insertion. In most computing environments, the overhead for allocating an initial table in line 2 is constant and the overhead for allocating and freeing storage in lines 5 and 7 is dominated by the cost of transfer-ring <a id="p462"/>items in line 6. Thus, the actual running time of T<small>ABLE</small>-I<small>NSERT</small> is linear in the number of elementary insertions. An <span class="blue"><strong><em>expansion</em></strong></span> occurs when lines 5–9 execute.</p>
<div class="pull-quote1">
<p class="box-heading">T<small>ABLE</small>-I<small>NSERT</small>(<em>T</em>, <em>x</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><span class="x-small">  1</span></td>
<td class="td1"><p class="noindent"><strong>if</strong> <em>T</em>.<em>size</em> == 0</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  2</span></td>
<td class="td1"><p class="p2">allocate <em>T</em>.<em>table</em> with 1 slot</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  3</span></td>
<td class="td1"><p class="p2"><em>T</em>.<em>size</em> = 1</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  4</span></td>
<td class="td1"><p class="noindent"><strong>if</strong> <em>T</em>.<em>num</em> == <em>T</em>.<em>size</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  5</span></td>
<td class="td1"><p class="p2">allocate <em>new</em>-<em>table</em> with 2 <em>· T</em>.<em>size</em> slots</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  6</span></td>
<td class="td1"><p class="p2">insert all items in <em>T</em>.<em>table</em> into <em>new</em>-<em>table</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  7</span></td>
<td class="td1"><p class="p2">free <em>T</em>.<em>table</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  8</span></td>
<td class="td1"><p class="p2"><em>T</em>.<em>table</em> = <em>new</em>-<em>table</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  9</span></td>
<td class="td1"><p class="p2"><em>T</em>.<em>size</em> = 2 · <em>T</em>.<em>size</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">10</span></td>
<td class="td1"><p class="noindent">insert <em>x</em> into <em>T</em>.<em>table</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">11</span></td>
<td class="td1"><p class="noindent"><em>T</em>.<em>num</em> = <em>T</em>.<em>num</em> + 1</p></td>
</tr>
</table>
</div>
<p>Now, we’ll use all three amortized analysis techniques to analyze a sequence of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> operations on an initially empty table. First, we need to determine the actual cost <em>c<sub>i</sub></em> of the <em>i</em>th operation. If the current table has room for the new item (or if this is the first operation), then <em>c<sub>i</sub></em> = 1, since the only elementary insertion performed is the one in line 10. If the current table is full, however, and an expansion occurs, then <em>c<sub>i</sub></em> = <em>i</em>: the cost is 1 for the elementary insertion in line 10 plus <em>i</em> − 1 for the items copied from the old table to the new table in line 6. For <em>n</em> operations, the worst-case cost of an operation is <em>O</em>(<em>n</em>), which leads to an upper bound of <em>O</em>(<em>n</em><sup>2</sup>) on the total running time for <em>n</em> operations.</p>
<p>This bound is not tight, because the table rarely expands in the course of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> operations. Specifically, the <em>i</em>th operation causes an expansion only when <em>i</em> − 1 is an exact power of 2. The amortized cost of an operation is in fact <em>O</em>(1), as an aggregate analysis shows. The cost of the <em>i</em>th operation is</p>
<p class="eql"><img alt="art" src="images/Art_P518.jpg"/></p>
<p class="noindent">The total cost of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> operations is therefore</p>
<p class="eql"><img alt="art" src="images/Art_P519.jpg"/></p>
<p class="noindent">because at most <em>n</em> operations cost 1 each and the costs of the remaining operations form a geometric series. Since the total cost of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> operations is bounded by 3<em>n</em>, the amortized cost of a single operation is at most 3.</p>
<a id="p463"/>
<div class="divimage">
<p class="fig-imga" id="Fig_16-3"><img alt="art" src="images/Art_P520.jpg"/></p>
<p class="caption"><strong>Figure 16.3</strong> Analysis of table expansion by the accounting method. Each call of T<small>ABLE</small>-I<small>NSERT</small> charges $3 as follows: $1 to pay for the elementary insertion, $1 on the item inserted as prepayment for it to be reinserted later, and $1 on an item that was already in the table, also as prepayment for reinsertion. <strong>(a)</strong> The table immediately after an expansion, with 8 slots, 4 items (tan slots), and no stored credit. <strong>(b)–(e)</strong> After each of 4 calls to T<small>ABLE</small>-I<small>NSERT</small>, the table has one more item, with $1 stored on the new item and $1 stored on one of the 4 items that were present immediately after the expansion. Slots with these new items are blue. <strong>(f)</strong> Upon the next call to T<small>ABLE</small>-I<small>NSERT</small>, the table is full, and so it expands again. Each item had $1 to pay for it to be reinserted. Now the table looks as it did in part (a), with no stored credit but 16 slots and 8 items.</p>
</div>
<p>The accounting method can provide some intuition for why the amortized cost of a T<small>ABLE</small>-I<small>NSERT</small> operation should be 3. You can think of each item paying for three elementary insertions: inserting itself into the current table, moving itself the next time that the table expands, and moving some other item that was already in the table the next time that the table expands. For example, suppose that the size of the table is <em>m</em> immediately after an expansion, as shown in <a href="chapter016.xhtml#Fig_16-3">Figure 16.3</a> for <em>m</em> = 8. Then the table holds <em>m</em>/2 items, and it contains no credit. Each call of T<small>ABLE</small>-I<small>NSERT</small> charges $3. The elementary insertion that occurs immediately costs $1. Another $1 resides on the item inserted as credit. The third $1 resides as credit on one of the <em>m</em>/2 items already in the table. The table will not fill again until another <em>m</em>/2 − 1 items have been inserted, and thus, by the time the table contains <em>m</em> items and is full, each item has $1 on it to pay for it to be reinserted it during the expansion.</p>
<p>Now, let’s see how to use the potential method. We’ll use it again in <a href="chapter016.xhtml#Sec_16.4.2">Section 16.4.2</a> to design a T<small>ABLE</small>-D<small>ELETE</small> operation that has an <em>O</em>(1) amortized cost <a id="p464"/>as well. Just as the accounting method had no stored credit immediately after an expansion—that is, when <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>/2—let’s define the potential to be 0 when <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>/2. As elementary insertions occur, the potential needs to increase enough to pay for all the reinsertions that will happen when the table next expands. The table fills after another <em>T</em>.<em>size</em>/2 calls of T<small>ABLE</small>-I<small>NSERT</small>, when <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>. The next call of T<small>ABLE</small>-I<small>NSERT</small> after these <em>T</em>.<em>size</em>/2 calls triggers an expansion with a cost of <em>T</em>.<em>size</em> to reinsert all the items. Therefore, over the course of <em>T</em>.<em>size</em>/2 calls of T<small>ABLE</small>-I<small>NSERT</small>, the potential must increase from 0 to <em>T</em>.<em>size</em>. To achieve this increase, let’s design the potential so that each call of T<small>ABLE</small>-I<small>NSERT</small> increases it by</p>
<p class="eql"><img alt="art" src="images/Art_P521.jpg"/></p>
<p class="noindent">until the table expands. You can see that the potential function</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P522.jpg"/></p>
<p class="noindent">equals 0 immediately after the table expands, when <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>/2, and it increases by 2 upon each insertion until the table fills. Once the table fills, that is, when <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>, the potential Φ(<em>T</em>) equals <em>T</em>.<em>size</em>. The initial value of the potential is 0, and since the table is always at least half full, <em>T</em>.<em>num</em> ≥ <em>T</em>.<em>size</em>/2, which implies that Φ(<em>T</em>) is always nonnegative. Thus, the sum of the amortized costs of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> operations gives an upper bound on the sum of the actual costs.</p>
<p>To analyze the amortized costs of table operations, it is convenient to think in terms of the change in potential due to each operation. Letting Φ<em><sub>i</sub></em> denote the potential after the <em>i</em>th operation, we can rewrite equation (16.2) as</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + Φ<em><sub>i</sub></em> − Φ<sub><em>i</em>−1</sub></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em>,</td>
</tr>
</table>
<p class="noindent">where ΔΦ<em><sub>i</sub></em> is the change in potential due to the <em>i</em>th operation. First, consider the case when the <em>i</em>th insertion does not cause the table to expand. In this case, ΔΦ<em><sub>i</sub></em> is 2. Since the actual cost <em>c<sub>i</sub></em> is 1, the amortized cost is</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">1 + 2</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">3.</td>
</tr>
</table>
<p class="noindent">Now, consider the change in potential when the table does expand during the <em>i</em>th insertion because it was full immediately before the insertion. Let <em>num<sub>i</sub></em> denote the number of items stored in the table after the <em>i</em>th operation and <em>size<sub>i</sub></em> denote the total size of the table after the <em>i</em>th operation, so that <em>size</em><sub><em>i</em>−1</sub> = <em>num</em><sub><em>i</em>−1</sub> = <em>i</em> − 1 <a id="p465"/>and therefore Φ<sub><em>i</em>−1</sub> = 2(<em>size</em><sub><em>i</em>−1</sub> − <em>size</em><sub><em>i</em>−1</sub>/2) = <em>size</em><sub><em>i</em>−1</sub> = <em>i</em> − 1. Immediately after the expansion, the potential goes down to 0, and then the new item is inserted, causing the potential to increase to Φ<em><sub>i</sub></em> = 2. Thus, when the <em>i</em>th insertion triggers an expansion, ΔΦ<em><sub>i</sub></em> = 2 − (<em>i</em> − 1) = 3 − <em>i</em>. When the table expands in the <em>i</em>th T<small>ABLE</small>-I<small>NSERT</small> operation, the actual cost <em>c<sub>i</sub></em> equals <em>i</em> (to reinsert <em>i</em> − 1 items and insert the <em>i</em>th item), giving an amortized cost of</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>i</em> + (3 − <em>i</em>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">3.</td>
</tr>
</table>
<p class="noindent"><a href="chapter016.xhtml#Fig_16-4">Figure 16.4</a> plots the values of <em>num<sub>i</sub></em>, <em>size<sub>i</sub></em>, and Φ<em><sub>i</sub></em> against <em>i</em>. Notice how the potential builds to pay for expanding the table.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_16-4"><img alt="art" src="images/Art_P523.jpg"/></p>
<p class="caption"><strong>Figure 16.4</strong> The effect of a sequence of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> operations on the number <em>num<sub>i</sub></em> of items in the table (the brown line), the number <em>size<sub>i</sub></em> of slots in the table (the blue line), and the potential Φ<em><sub>i</sub></em> = 2(<em>num<sub>i</sub></em> − <em>size<sub>i</sub></em>/2) (the red line), each being measured after the <em>i</em>th operation. Immediately before an expansion, the potential has built up to the number of items in the table, and therefore it can pay for moving all the items to the new table. Afterward, the potential drops to 0, but it immediately increases by 2 upon insertion of the item that caused the expansion.</p>
</div>
</section>
<section title="16.4.2 Table expansion and contraction">
<p class="level2" id="Sec_16.4.2"><strong>16.4.2    Table expansion and contraction</strong></p>
<p class="noindent">To implement a T<small>ABLE</small>-D<small>ELETE</small> operation, it is simple enough to remove the specified item from the table. In order to limit the amount of wasted space, however, you might want to <span class="blue"><strong><em>contract</em></strong></span> the table when the load factor becomes too small. Table <a id="p466"/>contraction is analogous to table expansion: when the number of items in the table drops too low, allocate a new, smaller table and then copy the items from the old table into the new one. You can then free the storage for the old table by returning it to the memory-management system. In order to not waste space, yet keep the amortized costs low, the insertion and deletion procedures should preserve two properties:</p>
<ul class="ulnoindent" epub:type="list">
<li>the load factor of the dynamic table is bounded below by a positive constant, as well as above by 1, and</li>
<li class="litop">the amortized cost of a table operation is bounded above by a constant.</li></ul>
<p class="noindent">The actual cost of each operation equals the number of elementary insertions or deletions.</p>
<p>You might think that if you double the table size upon inserting an item into a full table, then you should halve the size when deleting an item that would cause the table to become less than half full. This strategy does indeed guarantee that the load factor of the table never drops below 1/2. Unfortunately, it can also cause the amortized cost of an operation to be quite large. Consider the following scenario. Perform <em>n</em> operations on a table <em>T</em> of size <em>n</em>/2, where <em>n</em> is an exact power of 2. The first <em>n</em>/2 operations are insertions, which by our previous analysis cost a total of Θ(<em>n</em>). At the end of this sequence of insertions, <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em> = <em>n</em>/2. For the second <em>n</em>/2 operations, perform the following sequence:</p>
<div class="pull-quote">
<p class="pq-noindent">insert, delete, delete, insert, insert, delete, delete, insert, insert, ….</p>
</div>
<p class="noindent">The first insertion causes the table to expand to size <em>n</em>. The two deletions that follow cause the table to contract back to size <em>n</em>/2. Two further insertions cause another expansion, and so forth. The cost of each expansion and contraction is Θ(<em>n</em>), and there are Θ(<em>n</em>) of them. Thus, the total cost of the <em>n</em> operations is Θ(<em>n</em><sup>2</sup>), making the amortized cost of an operation Θ(<em>n</em>).</p>
<p>The problem with this strategy is that after the table expands, not enough deletions occur to pay for a contraction. Likewise, after the table contracts, not enough insertions take place to pay for an expansion.</p>
<p>How can we solve this problem? Allow the load factor of the table to drop below 1/2. Specifically, continue to double the table size upon inserting an item into a full table, but halve the table size when deleting an item causes the table to become less than 1/4 full, rather than 1/2 full as before. The load factor of the table is therefore bounded below by the constant 1/4, and the load factor is 1/2 immediately after a contraction.</p>
<p>An expansion or contraction should exhaust all the built-up potential, so that immediately after expansion or contraction, when the load factor is 1/2, the table’s potential is 0. <a href="chapter016.xhtml#Fig_16-5">Figure 16.5</a> shows the idea. As the load factor deviates from 1/2, the <a id="p467"/>potential increases so that by the time an expansion or contraction occurs, the table has garnered sufficient potential to pay for copying all the items into the newly allocated table. Thus, the potential function should grow to <em>T</em>.<em>num</em> by the time that the load factor has either increased to 1 or decreased to 1/4. Immediately after either expanding or contracting the table, the load factor goes back to 1/2 and the table’s potential reduces back to 0.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_16-5"><img alt="art" src="images/Art_P524.jpg"/></p>
<p class="caption"><strong>Figure 16.5</strong> How to think about the potential function Φ for table insertion and deletion. When the load factor <em>α</em> is 1/2, the potential is 0. In order to accumulate sufficient potential to pay for reinserting all <em>T</em>.<em>size</em> items when the table fills, the potential needs to increase by 2 upon each insertion when <em>α</em> ≥ 1/2. Correspondingly, the potential decreases by 2 upon each deletion that leaves <em>α</em> ≥ 1/2. In order to accrue enough potential to cover the cost of reinserting all <em>T</em>.<em>size</em>/4 items when the table contracts, the potential needs to increase by 1 upon each deletion when <em>α</em> &lt; 1/2, and correspondingly the potential decreases by 1 upon each insertion that leaves <em>α</em> &lt; 1/2. The red area represents load factors less than 1/4, which are not allowed.</p>
</div>
<p>We omit the code for T<small>ABLE</small>-D<small>ELETE</small>, since it is analogous to T<small>ABLE</small>-I<small>NSERT</small>. We assume that if a contraction occurs during T<small>ABLE</small>-D<small>ELETE</small>, it occurs after the item is deleted from the table. The analysis assumes that whenever the number of items in the table drops to 0, the table occupies no storage. That is, if <em>T</em>.<em>num</em> = 0, then <em>T</em>.<em>size</em> = 0.</p>
<p>How do we design a potential function that gives constant amortized time for both insertion and deletion? When the load factor is at least 1/2, the same potential function, Φ(<em>T</em>) = 2(<em>T</em>.<em>num</em> − <em>T</em>.<em>size</em>/2), that we used for insertion still works. When the table is at least half full, each insertion increases the potential by 2 if the table does not expand, and each deletion reduces the potential by 2 if it does not cause the load factor to drop below 1/2.</p>
<p>What about when the load factor is less than 1/2, that is, when 1/4 ≤ <em>α</em>(<em>T</em>) &lt; 1/2? As before, when <em>α</em>(<em>T</em>) = 1/2, so that <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>/2, the potential Φ(<em>T</em>) should be 0. To get the load factor from 1/2 down to 1/4, <em>T</em>.<em>size</em>/4 deletions need <a id="p468"/>to occur, at which time <em>T</em>.<em>num</em> = <em>T</em>.<em>size</em>/4. To pay for all the reinsertions, the potential must increase from 0 to <em>T</em>.<em>size</em>/4 over these <em>T</em>.<em>size</em>/4 deletions. Therefore, for each call of T<small>ABLE</small>-D<small>ELETE</small> until the table contracts, the potential should increase by</p>
<p class="eql"><img alt="art" src="images/Art_P525.jpg"/></p>
<p class="noindent">Likewise, when <em>α</em> &lt; 1/2, each call of T<small>ABLE</small>-I<small>NSERT</small> should decrease the potential by 1. When 1/4 ≤ <em>α</em>(<em>T</em>) &lt; 1/2, the potential function</p>
<p class="eql">Φ(<em>T</em>) = <em>T</em>.<em>size</em>/2 − <em>T</em>.<em>num</em></p>
<p class="noindent">produces this desired behavior.</p>
<p>Putting the two cases together, we get the potential function</p>
<p class="eqr"><img alt="art" class="width100" src="images/Art_P526.jpg"/></p>
<p class="noindent">The potential of an empty table is 0 and the potential is never negative. Thus, the total amortized cost of a sequence of operations with respect to Φ provides an upper bound on the actual cost of the sequence. <a href="chapter016.xhtml#Fig_16-6">Figure 16.6</a> illustrates how the potential function behaves over a sequence of insertions and deletions.</p>
<p>Now, let’s determine the amortized costs of each operation. As before, let <em>num<sub>i</sub></em> denote the number of items stored in the table after the <em>i</em>th operation, <em>size<sub>i</sub></em> denote the total size of the table after the <em>i</em>th operation, <em>α<sub>i</sub></em> = <em>num<sub>i</sub></em>/<em>size<sub>i</sub></em> denote the load factor after the <em>i</em>th operation, Φ<em><sub>i</sub></em> denote the potential after the <em>i</em>th operation, and ΔΦ<em><sub>i</sub></em> denote the change in potential due to the <em>i</em>th operation. Initially, <em>num</em><sub>0</sub> = 0, <em>size</em><sub>0</sub> = 0, and Φ<sub>0</sub> = 0.</p>
<p>The cases in which the table does not expand or contract and the load factor does not cross <em>α</em> = 1/2 are straightforward. As we have seen, if <em>α</em><sub><em>i</em>−1</sub> ≥ 1/2 and the <em>i</em>th operation is an insertion that does not cause the table to expand, then ΔΦ<em><sub>i</sub></em> = 2. Likewise, if the <em>i</em>th operation is a deletion and <em>α<sub>i</sub></em> ≥ 1/2, then ΔΦ<em><sub>i</sub></em> = −2. Furthermore, if <em>α</em><sub><em>i</em>−1</sub> &lt; 1/2 and the <em>i</em>th operation is a deletion that does not trigger a contraction, then ΔΦ<em><sub>i</sub></em> = 1, and if the <em>i</em>th operation is an insertion and <em>α<sub>i</sub></em> &lt; 1/2, then ΔΦ<em><sub>i</sub></em> = −1. In other words, if no expansion or contraction occurs and the load factor does not cross <em>α</em> = 1/2, then</p>
<ul class="ulnoindent" epub:type="list">
<li>if the load factor stays at or above 1/2, then the potential increases by 2 for an insertion and decreases by 2 for a deletion, and</li>
<li class="litop">if the load factor stays below 1/2, then the potential increases by 1 for a deletion and decreases by 1 for an insertion.</li></ul>
<p class="noindent">In each of these cases, the actual cost <em>c<sub>i</sub></em> of the <em>i</em>th operation is just 1, and so</p>
<a id="p469"/>
<div class="divimage">
<p class="fig-imga" id="Fig_16-6"><img alt="art" src="images/Art_P527.jpg"/></p>
<p class="caption"><strong>Figure 16.6</strong> The effect of a sequence of <em>n</em> T<small>ABLE</small>-I<small>NSERT</small> and T<small>ABLE</small>-D<small>ELETE</small> operations on the number <em>num<sub>i</sub></em> of items in the table (the brown line), the number <em>size<sub>i</sub></em> of slots in the table (the blue line), and the potential (the red line)</p>
<p class="eql"><img alt="art" src="images/Art_P528.jpg"/></p>
<p class="noindent">where <em>α<sub>i</sub></em> = <em>num<sub>i</sub></em>/<em>size<sub>i</sub></em>, each measured after the <em>i</em>th operation. Immediately before an expansion or contraction, the potential has built up to the number of items in the table, and therefore it can pay for moving all the items to the new table.</p>
</div>
<ul class="ulnoindent1" epub:type="list">
<li>if the <em>i</em>th operation is an insertion, its amortized cost <em><span class="font1">ĉ</span><sub>i</sub></em> is <em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em>, which is 1 + 2 = 3 if the load factor stays at or above 1/2, and 1 + (−1) = 0 if the load factor stays below 1/2, and</li>
<li class="litop">if the <em>i</em>th operation is a deletion, its amortized cost <em><span class="font1">ĉ</span><sub>i</sub></em> is <em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em>, which is 1 + (−2) = −1 if the load factor stays at or above 1/2, and 1 + 1 = 2 if the load factor stays below 1/2.</li></ul>
<p class="space-break">Four cases remain: an insertion that takes the load factor from below 1/2 to 1/2, a deletion that takes the load factor from 1/2 to below 1/2, a deletion that causes the table to contract, and an insertion that causes the table to expand. We analyzed that last case at the end of <a href="chapter016.xhtml#Sec_16.4.1">Section 16.4.1</a> to show that its amortized cost is 3.</p>
<p>When the <em>i</em>th operation is a deletion that causes the table to contract, we have <em>num</em><sub><em>i</em>−1</sub> = <em>size</em><sub><em>i</em>−1</sub>/4 before the contraction, then the item is deleted, and finally <em>num<sub>i</sub></em> = <em>size<sub>i</sub></em>/2 − 1 after the contraction. Thus, by equation (16.5) we have</p>
<a id="p470"/>
<table class="table2b">
<tr>
<td class="td2">Φ<sub><em>i</em>−1</sub></td>
<td class="td2">=</td>
<td class="td2"><em>size</em><sub><em>i</em>−1</sub>/2 − <em>num</em><sub><em>i</em>−1</sub></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>size</em><sub><em>i</em>−1</sub>/2 − <em>size</em><sub><em>i</em>−1</sub>/4</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>size</em><sub><em>i</em>−1</sub>/4,</td>
</tr>
</table>
<p class="noindent">which also equals the actual cost <em>c<sub>i</sub></em> of deleting one item and copying <em>size</em><sub><em>i</em>−1</sub>/4 − 1 items into the new, smaller table. Since <em>num<sub>i</sub></em> = <em>size<sub>i</sub></em>/2 − 1 after the operation has completed, <em>α<sub>i</sub></em> &lt; 1/2, and so</p>
<table class="table2b">
<tr>
<td class="td2">Φ<em><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>size<sub>i</sub></em>/2 − <em>num<sub>i</sub></em></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">1,</td>
</tr>
</table>
<p class="noindent">giving ΔΦ<em><sub>i</sub></em> = 1 − <em>size</em><sub><em>i</em>−1</sub>/4. Therefore, when the <em>i</em>th operation is a deletion that triggers a contraction, its amortized cost is</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ĉ</span><sub>i</sub></em></td>
<td class="td2">=</td>
<td class="td2"><em>c<sub>i</sub></em> + ΔΦ<sub><em>i</em></sub></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>size</em><sub><em>i</em>−1</sub>/4 + (1 − <em>size</em><sub><em>i</em>−1</sub>/4)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2">1.</td>
</tr>
</table>
<p>Finally, we handle the cases where the load factor fits one case of equation (16.5) before the operation and the other case afterward. We start with deletion, where we have <em>num</em><sub><em>i</em>−1</sub> = <em>size</em><sub><em>i</em>−1</sub>/2, so that <em>α</em><sub><em>i</em>−1</sub> = 1/2, beforehand, and <em>num<sub>i</sub></em> = <em>size<sub>i</sub></em>/2−1, so that <em>α<sub>i</sub></em> &lt; 1/2 afterward. Because <em>α</em><sub><em>i</em>−1</sub> = 1/2, we have Φ<sub><em>i</em>−1</sub> = 0, and because <em>α<sub>i</sub></em> &lt; 1/2, we have Φ<em><sub>i</sub></em> = <em>size<sub>i</sub></em>/2 − <em>num<sub>i</sub></em> = 1. Thus we get that ΔΦ<em><sub>i</sub></em> = 1 − 0 = 1. Since the <em>i</em>th operation is a deletion that does not cause a contraction, the actual cost <em>c<sub>i</sub></em> equals 1, and the amortized cost <em><span class="font1">ĉ</span><sub>i</sub></em> is <em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em> = 1 + 1 = 2.</p>
<p>Conversely, if the <em>i</em>th operation is an insertion that takes the load factor from below 1/2 to equaling 1/2, the change in potential ΔΦ<em><sub>i</sub></em> equals −1. Again, the actual cost <em>c<sub>i</sub></em> is 1, and now the amortized cost <em><span class="font1">ĉ</span><sub>i</sub></em> is <em>c<sub>i</sub></em> + ΔΦ<em><sub>i</sub></em> = 1 + (−1) = 0.</p>
<p>In summary, since the amortized cost of each operation is bounded above by a constant, the actual time for any sequence of <em>n</em> operations on a dynamic table is <em>O</em>(<em>n</em>).</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>16.4-1</em></strong></p>
<p class="noindent">Using the potential method, analyze the amortized cost of the first table insertion.</p>
<p class="level3"><strong><em>16.4-2</em></strong></p>
<p class="noindent">You wish to implement a dynamic, open-address hash table. Why might you consider the table to be full when its load factor reaches some value <em>α</em> that is strictly less than 1? Describe briefly how to make insertion into a dynamic, open-address hash table run in such a way that the expected value of the amortized cost per <a id="p471"/>insertion is <em>O</em>(1). Why is the expected value of the actual cost per insertion not necessarily <em>O</em>(1) for all insertions?</p>
<p class="level3"><strong><em>16.4-3</em></strong></p>
<p class="noindent">Discuss how to use the accounting method to analyze both the insertion and deletion operations, assuming that the table doubles in size when its load factor exceeds 1 and the table halves in size when its load factor goes below 1/4.</p>
<p class="level3"><strong><em>16.4-4</em></strong></p>
<p class="noindent">Suppose that instead of contracting a table by halving its size when its load factor drops below 1/4, you contract the table by multiplying its size by 2/3 when its load factor drops below 1/3. Using the potential function</p>
<p class="eql">Φ(<em>T</em>) = |2(<em>T</em>.<em>num</em> − <em>T</em>.<em>size</em>/2)|,</p>
<p class="noindent">show that the amortized cost of a T<small>ABLE</small>-D<small>ELETE</small> that uses this strategy is bounded above by a constant.</p>
</section>
</section>
<p class="line1"/>
<section title="Problems">
<p class="level1" id="h1-98"><strong>Problems</strong></p>
<section title="16-1 Binary reflected Gray code">
<p class="level2"><strong><em>16-1     Binary reflected Gray code</em></strong></p>
<p class="noindent">A <span class="blue"><strong><em>binary Gray code</em></strong></span> represents a sequence of nonnegative integers in binary such that to go from one integer to the next, exactly one bit flips every time. The <span class="blue"><strong><em>binary reflected Gray code</em></strong></span> represents a sequence of the integers 0 to 2<em><sup>k</sup></em> − 1 for some positive integer <em>k</em> according to the following recursive method:</p>
<ul class="ulnoindent" epub:type="list">
<li>For <em>k</em> = 1, the binary reflected Gray code is <span class="font1">〈</span>0, 1<span class="font1">〉</span>.</li>
<li class="litop">For <em>k</em> ≥ 2, first form the binary reflected Gray code for <em>k</em> − 1, giving the 2<sup><em>k</em>−1</sup> integers 0 to 2<sup><em>k</em>−1</sup> − 1. Then form the reflection of this sequence, which is just the sequence in reverse. (That is, the <em>j</em> th integer in the sequence becomes the (2<sup><em>k</em>−1</sup> − <em>j</em> − 1)st integer in the reflection). Next, add 2<sup><em>k</em>−1</sup> to each of the 2<sup><em>k</em>−1</sup> integers in the reflected sequence. Finally, concatenate the two sequences.</li></ul>
<p>For example, for <em>k</em> = 2, first form the binary reflected Gray code <span class="font1">〈</span>0, 1<span class="font1">〉</span> for <em>k</em> = 1. Its reflection is the sequence <span class="font1">〈</span>1, 0<span class="font1">〉</span>. Adding 2<sup><em>k</em>−1</sup> = 2 to each integer in the reflection gives the sequence <span class="font1">〈</span>3, 2<span class="font1">〉</span>. Concatenating the two sequences gives <span class="font1">〈</span>0, 1, 3, 2<span class="font1">〉</span> or, in binary, <span class="font1">〈</span>00, 01, 11, 10<span class="font1">〉</span>, so that each integer differs from its predecessor by exactly one bit. For <em>k</em> = 3, the reflection of the binary reflected Gray code for <em>k</em> = 2 is <span class="font1">〈</span>2, 3, 1, 0<span class="font1">〉</span> and adding 2<sup><em>k</em>−1</sup> = 4 gives <span class="font1">〈</span>6, 7, 5, 4<span class="font1">〉</span>. Concatenating produces the sequence <span class="font1">〈</span>0, 1, 3, 2, 6, 7, 5, 4<span class="font1">〉</span>, which in binary is <span class="font1">〈</span>000, 001, 011, 010, 110, 111, 101,100<span class="font1">〉</span>. In the binary reflected Gray code, only one bit flips even when wrapping around from the last integer to the first.</p>
<a id="p472"/>
<p class="nl"><strong><em>a.</em></strong> Index the integers in a binary reflected Gray code from 0 to 2<sup><em>k</em></sup> − 1, and consider the <em>i</em>th integer in the binary reflected Gray code. To go from the (<em>i</em> −1)st integer to the <em>i</em>th integer in the binary reflected Gray code, exactly one bit flips. Show how to determine which bit flips, given the index <em>i</em>.</p>
<p class="nl"><strong><em>b.</em></strong> Assuming that given a bit number <em>j</em>, you can flip bit <em>j</em> of an integer in constant time, show how to compute the entire binary reflected Gray code sequence of 2<sup><em>k</em></sup> numbers in Θ(2<sup><em>k</em></sup>) time.</p>
</section>
<section title="16-2 Making binary search dynamic">
<p class="level2"><strong><em>16-2     Making binary search dynamic</em></strong></p>
<p class="noindent">Binary search of a sorted array takes logarithmic search time, but the time to insert a new element is linear in the size of the array. You can improve the time for insertion by keeping several sorted arrays.</p>
<p>Specifically, suppose that you wish to support S<small>EARCH</small> and I<small>NSERT</small> on a set of <em>n</em> elements. Let <em>k</em> = <span class="font1">⌈</span>lg(<em>n</em> + 1)<span class="font1">⌉</span>, and let the binary representation of <em>n</em> be <span class="font1">〈</span><em>n</em><sub><em>k</em>−1</sub>, <em>n</em><sub><em>k</em>−2</sub>, … , <em>n</em><sub>0</sub><span class="font1">〉</span>. Maintain <em>k</em> sorted arrays <em>A</em><sub>0</sub>, <em>A</em><sub>1</sub>, … , <em>A</em><sub><em>k</em>−1</sub>, where for <em>i</em> = 0, 1, … , <em>k</em> − 1, the length of array <em>A<sub>i</sub></em> is 2<sup><em>i</em></sup>. Each array is either full or empty, depending on whether <em>n<sub>i</sub></em> = 1 or <em>n<sub>i</sub></em> = 0, respectively. The total number of elements held in all <em>k</em> arrays is therefore <img alt="art" src="images/Art_P529.jpg"/>. Although each individual array is sorted, elements in different arrays bear no particular relationship to each other.</p>
<p class="nl"><strong><em>a.</em></strong> Describe how to perform the S<small>EARCH</small> operation for this data structure. Analyze its worst-case running time.</p>
<p class="nl"><strong><em>b.</em></strong> Describe how to perform the I<small>NSERT</small> operation. Analyze its worst-case and amortized running times, assuming that the only operations are I<small>NSERT</small> and S<small>EARCH</small>.</p>
<p class="nl"><strong><em>c.</em></strong> Describe how to implement D<small>ELETE</small>. Analyze its worst-case and amortized running times, assuming that there can be D<small>ELETE</small>, I<small>NSERT</small>, and S<small>EARCH</small> operations.</p>
</section>
<section title="16-3 Amortized weight-balanced trees">
<p class="level2"><strong><em>16-3     Amortized weight-balanced trees</em></strong></p>
<p class="noindent">Consider an ordinary binary search tree augmented by adding to each node <em>x</em> the attribute <em>x</em>.<em>size</em>, which gives the number of keys stored in the subtree rooted at <em>x</em>. Let <em>α</em> be a constant in the range 1/2 ≤ <em>α</em> &lt; 1. We say that a given node <em>x</em> is <span class="blue"><strong><em>α-balanced</em></strong></span> if <em>x</em>.<em>left</em>.<em>size</em> ≤ <em>α</em> · <em>x</em>.<em>size</em> and <em>x</em>.<em>right</em>.<em>size</em> ≤ <em>α</em> · <em>x</em>.<em>size</em>. The tree as a whole is <span class="blue"><strong><em>α-balanced</em></strong></span> if every node in the tree is <em>α</em>-balanced. The following amortized approach to maintaining weight-balanced trees was suggested by G. Varghese.</p>
<a id="p473"/>
<p class="nl"><strong><em>a.</em></strong> A 1/2-balanced tree is, in a sense, as balanced as it can be. Given a node <em>x</em> in an arbitrary binary search tree, show how to rebuild the subtree rooted at <em>x</em> so that it becomes 1/2-balanced. Your algorithm should run in Θ(<em>x</em>.<em>size</em>) time, and it can use <em>O</em>(<em>x</em>.<em>size</em>) auxiliary storage.</p>
<p class="nl"><strong><em>b.</em></strong> Show that performing a search in an <em>n</em>-node <em>α</em>-balanced binary search tree takes <em>O</em>(lg <em>n</em>) worst-case time.</p>
<p class="noindent1-top">For the remainder of this problem, assume that the constant <em>α</em> is strictly greater than 1/2. Suppose that you implement I<small>NSERT</small> and D<small>ELETE</small> as usual for an <em>n</em>-node binary search tree, except that after every such operation, if any node in the tree is no longer <em>α</em>-balanced, then you “rebuild” the subtree rooted at the highest such node in the tree so that it becomes 1/2-balanced.</p>
<p>We’ll analyze this rebuilding scheme using the potential method. For a node <em>x</em> in a binary search tree <em>T</em>, define</p>
<p class="eql">Δ(<em>x</em>) = |<em>x</em>.<em>left</em>.<em>size</em> − <em>x</em>.<em>right</em>.<em>size</em>|.</p>
<p class="noindent">Define the potential of <em>T</em> as</p>
<p class="eql"><img alt="art" src="images/Art_P530.jpg"/></p>
<p class="noindent">where <em>c</em> is a sufficiently large constant that depends on <em>α</em>.</p>
<p class="nl"><strong><em>c.</em></strong> Argue that any binary search tree has nonnegative potential and also that a 1/2-balanced tree has potential 0.</p>
<p class="nl"><strong><em>d.</em></strong> Suppose that <em>m</em> units of potential can pay for rebuilding an <em>m</em>-node subtree. How large must <em>c</em> be in terms of <em>α</em> in order for it to take <em>O</em>(1) amortized time to rebuild a subtree that is not <em>α</em>-balanced?</p>
<p class="nl"><strong><em>e.</em></strong> Show that inserting a node into or deleting a node from an <em>n</em>-node <em>α</em>-balanced tree costs <em>O</em>(lg <em>n</em>) amortized time.</p>
</section>
<section title="16-4 The cost of restructuring red-black trees">
<p class="level2"><strong><em>16-4     The cost of restructuring red-black trees</em></strong></p>
<p class="noindent">There are four basic operations on red-black trees that perform <span class="blue"><strong><em>structural modifications</em></strong></span>: node insertions, node deletions, rotations, and color changes. We have seen that RB-I<small>NSERT</small> and RB-D<small>ELETE</small> use only <em>O</em>(1) rotations, node insertions, and node deletions to maintain the red-black properties, but they may make many more color changes.</p>
<p class="nl"><strong><em>a.</em></strong> Describe a legal red-black tree with <em>n</em> nodes such that calling RB-I<small>NSERT</small> to add the (<em>n</em> + 1)st node causes Ω(lg <em>n</em>) color changes. Then describe a legal <a id="p474"/>red-black tree with <em>n</em> nodes for which calling RB-D<small>ELETE</small> on a particular node causes Ω(lg <em>n</em>) color changes.</p>
<p class="noindent1-top">Although the worst-case number of color changes per operation can be logarithmic, you will prove that any sequence of <em>m</em> RB-I<small>NSERT</small> and RB-D<small>ELETE</small> operations on an initially empty red-black tree causes <em>O</em>(<em>m</em>) structural modifications in the worst case.</p>
<p class="nl"><strong><em>b.</em></strong> Some of the cases handled by the main loop of the code of both RB-I<small>NSERT</small>-F<small>IXUP</small> and RB-D<small>ELETE</small>-F<small>IXUP</small> are <span class="blue"><strong><em>terminating</em></strong></span>: once encountered, they cause the loop to terminate after a constant number of additional operations. For each of the cases of RB-I<small>NSERT</small>-F<small>IXUP</small> and RB-D<small>ELETE</small>-F<small>IXUP</small>, specify which are terminating and which are not. (<em>Hint</em>: Look at <a href="chapter013.xhtml#Fig_13-1">Figures 13.5</a>, <a href="chapter013.xhtml#Fig_13-6">13.6</a>, and <a href="chapter013.xhtml#Fig_13-7">13.7</a> in <a href="chapter013.xhtml#Sec_13.3">Sections 13.3</a> and <a href="chapter013.xhtml#Sec_13.4">13.4</a>.)</p>
<p class="noindent1-top">You will first analyze the structural modifications when only insertions are performed. Let <em>T</em> be a red-black tree, and define Φ(<em>T</em>) to be the number of red nodes in <em>T</em>. Assume that one unit of potential can pay for the structural modifications performed by any of the three cases of RB-I<small>NSERT</small>-F<small>IXUP</small>.</p>
<p class="nl"><strong><em>c.</em></strong> Let <em>T</em>′ be the result of applying Case 1 of RB-I<small>NSERT</small>-F<small>IXUP</small> to <em>T</em>. Argue that Φ(<em>T</em>′) = Φ(<em>T</em>) − 1.</p>
<p class="nl"><strong><em>d.</em></strong> We can break the operation of the RB-I<small>NSERT</small> procedure into three parts. List the structural modifications and potential changes resulting from lines 1–16 of RB-I<small>NSERT</small>, from nonterminating cases of RB-I<small>NSERT</small>-F<small>IXUP</small>, and from terminating cases of RB-I<small>NSERT</small>-F<small>IXUP</small>.</p>
<p class="nl"><strong><em>e.</em></strong> Using part (d), argue that the amortized number of structural modifications performed by any call of RB-I<small>NSERT</small> is <em>O</em>(1).</p>
<p class="noindent1-top">Next you will prove that there are <em>O</em>(<em>m</em>) structural modifications when both insertions and deletions occur. Define, for each node <em>x</em>,</p>
<p class="eql"><img alt="art" src="images/Art_P531.jpg"/></p>
<p class="noindent">Now redefine the potential of a red-black tree <em>T</em> as</p>
<p class="eql"><img alt="art" src="images/Art_P532.jpg"/></p>
<a id="p475"/>
<p class="noindent">and let <em>T</em>′ be the tree that results from applying any nonterminating case of RB-I<small>NSERT</small>-F<small>IXUP</small> or RB-D<small>ELETE</small>-F<small>IXUP</small> to <em>T</em>.</p>
<p class="nl"><strong><em>f.</em></strong> Show that Φ(<em>T</em>′) ≤ Φ(<em>T</em>) − 1 for all nonterminating cases of RB-I<small>NSERT</small>-F<small>IXUP</small>. Argue that the amortized number of structural modifications performed by any call of RB-I<small>NSERT</small>-F<small>IXUP</small> is <em>O</em>(1).</p>
<p class="nl"><strong><em>g.</em></strong> Show that Φ(<em>T</em>′) ≤ Φ(<em>T</em>) − 1 for all nonterminating cases of RB-D<small>ELETE</small>-F<small>IXUP</small>. Argue that the amortized number of structural modifications performed by any call of RB-D<small>ELETE</small>-F<small>IXUP</small> is <em>O</em>(1).</p>
<p class="nl"><strong><em>h.</em></strong> Complete the proof that in the worst case, any sequence of <em>m</em> RB-I<small>NSERT</small> and RB-D<small>ELETE</small> operations performs <em>O</em>(<em>m</em>) structural modifications.</p>
</section>
</section>
<p class="line1"/>
<section title="Chapter notes">
<p class="level1" id="h1-99"><strong>Chapter notes</strong></p>
<p class="noindent">Aho, Hopcroft, and Ullman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_5">5</a>] used aggregate analysis to determine the running time of operations on a disjoint-set forest. We’ll analyze this data structure using the potential method in <a href="chapter019.xhtml">Chapter 19</a>. Tarjan [<a epub:type="noteref" href="bibliography001.xhtml#endnote_430">430</a>] surveys the accounting and potential methods of amortized analysis and presents several applications. He attributes the accounting method to several authors, including M. R. Brown, R. E. Tarjan, S. Huddleston, and K. Mehlhorn. He attributes the potential method to D. D. Sleator. The term “amortized” is due to D. D. Sleator and R. E. Tarjan.</p>
<p>Potential functions are also useful for proving lower bounds for certain types of problems. For each configuration of the problem, define a potential function that maps the configuration to a real number. Then determine the potential Φ<sub>init</sub> of the initial configuration, the potential Φ<sub>final</sub> of the final configuration, and the maximum change in potential ΔΦ<sub>max</sub> due to any step. The number of steps must therefore be at least |Φ<sub>final</sub> − Φ<sub>init</sub>| / | ΔΦ<sub>max</sub>|. Examples of potential functions to prove lower bounds in I/O complexity appear in works by Cormen, Sundquist, and Wisniewski [<a epub:type="noteref" href="bibliography001.xhtml#endnote_105">105</a>], Floyd [<a epub:type="noteref" href="bibliography001.xhtml#endnote_146">146</a>], and Aggarwal and Vitter [<a epub:type="noteref" href="bibliography001.xhtml#endnote_3">3</a>]. Krumme, Cybenko, and Venkataraman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_271">271</a>] applied potential functions to prove lower bounds on <span class="blue"><strong><em>gossiping</em></strong></span>: communicating a unique item from each vertex in a graph to every other vertex.</p>
<p class="footnote" id="footnote_1"><a href="#footnote_ref_1"><sup>1</sup></a> In some situations, such as an open-address hash table, it’s better to consider a table to be full if its load factor equals some constant strictly less than 1. (See Exercise 16.4-2.)</p>
</section>
</section>
</div>
</body>
</html>