<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"/>
<title>Introduction to Algorithms</title>
<link href="css/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:4a9ccac5-f2db-4081-af1f-a5a376b433e1" name="Adept.expected.resource"/>
</head>
<body>
<div class="body"><a id="p646"/>
<p class="line-c"/>
<section epub:type="bodymatter chapter" title="23 All-Pairs Shortest Paths">
<p class="chapter-title"><a href="toc.xhtml#chap-23"><strong><span class="blue1">23        All-Pairs Shortest Paths</span></strong></a></p>
<p class="noindent">In this chapter, we turn to the problem of finding shortest paths between all pairs of vertices in a graph. A classic application of this problem occurs in computing a table of distances between all pairs of cities for a road atlas. Classic perhaps, but not a true application of finding shortest paths between <em>all</em> pairs of vertices. After all, a road map modeled as a graph has one vertex for <em>every</em> road intersection and one edge wherever a road connects intersections. A table of intercity distances in an atlas might include distances for 100 cities, but the United States has approximately 300,000 signal-controlled intersections<sup><a epub:type="footnote" href="#footnote_1" id="footnote_ref_1">1</a></sup> and many more uncontrolled intersections.</p>
<p>A legitimate application of all-pairs shortest paths is to determine the <span class="blue"><strong><em>diameter</em></strong></span> of a network: the longest of all shortest paths. If a directed graph models a communication network, with the weight of an edge indicating the time required for a message to traverse a communication link, then the diameter gives the longest possible transit time for a message in the network.</p>
<p>As in <a href="chapter022.xhtml">Chapter 22</a>, the input is a weighted, directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with a weight function <em>w</em> : <em>E</em> → <span class="font1">ℝ</span> that maps edges to real-valued weights. Now the goal is to find, for every pair of vertices <em>u, v</em> ∈ <em>V</em>, a shortest (least-weight) path from <em>u</em> to <em>v</em>, where the weight of a path is the sum of the weights of its constituent edges. For the all-pairs problem, the output typically takes a tabular form in which the entry in <em>u</em>’s row and <em>v</em>’s column is the weight of a shortest path from <em>u</em> to <em>v</em>.</p>
<p>You can solve an all-pairs shortest-paths problem by running a single-source shortest-paths algorithm |<em>V</em>| times, once with each vertex as the source. If all edge weights are nonnegative, you can use Dijkstra’s algorithm. If you implement the min-priority queue with a linear array, the running time is <em>O</em>(<em>V</em><sup>3</sup> + <em>VE</em>) which is <em>O</em>(<em>V</em><sup>3</sup>). The binary min-heap implementation of the min-priority queue <a id="p647"/>yields a running time of <em>O</em>(<em>V</em>(<em>V</em> + <em>E</em>) lg <em>V</em>). If |<em>E</em>| = Ω(<em>V</em>), the running time becomes <em>O</em>(<em>VE</em> lg <em>V</em>), which is faster than <em>O</em>(<em>V</em><sup>3</sup>) if the graph is sparse. Alternatively, you can implement the min-priority queue with a Fibonacci heap, yielding a running time of <em>O</em>(<em>V</em><sup>2</sup> lg <em>V</em> + <em>VE</em>).</p>
<p>If the graph contains negative-weight edges, Dijkstra’s algorithm doesn’t work, but you can run the slower Bellman-Ford algorithm once from each vertex. The resulting running time is <em>O</em>(<em>V</em><sup>2</sup><em>E</em>), which on a dense graph is <em>O</em>(<em>V</em><sup>4</sup>). This chapter shows how to guarantee a much better asymptotic running time. It also investigates the relation of the all-pairs shortest-paths problem to matrix multiplication.</p>
<p>Unlike the single-source algorithms, which assume an adjacency-list representation of the graph, most of the algorithms in this chapter represent the graph by an adjacency matrix. (Johnson’s algorithm for sparse graphs, in <a href="chapter023.xhtml#Sec_23.3">Section 23.3</a>, uses adjacency lists.) For convenience, we assume that the vertices are numbered 1, 2, … , |<em>V</em>|, so that the input is an <em>n</em> × <em>n</em> matrix <em>W</em> = (<em>w<sub>ij</sub></em>) representing the edge weights of an <em>n</em>-vertex directed graph <em>G</em> = (<em>V</em>, <em>E</em>), where</p>
<p class="eqr"><img alt="art" src="images/Art_P679.jpg"/></p>
<p class="noindent">The graph may contain negative-weight edges, but we assume for the time being that the input graph contains no negative-weight cycles.</p>
<p>The tabular output of each of the all-pairs shortest-paths algorithms presented in this chapter is an <em>n</em> × <em>n</em> matrix. The (<em>i</em>, <em>j</em>) entry of the output matrix contains δ(<em>i</em>, <em>j), the shortest-path weight from vertex i</em> to vertex <em>j</em>, as in <a href="chapter022.xhtml">Chapter 22</a>.</p>
<p>A full solution to the all-pairs shortest-paths problem includes not only the shortest-path weights but also a <span class="blue"><strong><em>predecessor matrix</em></strong></span> Π = (π<sub><em>ij</em></sub>), where π<sub><em>ij</em></sub> is <small>NIL</small> if either <em>i</em> = <em>j</em> or there is no path from <em>i</em> to <em>j</em>, and otherwise π<sub><em>ij</em></sub> is the predecessor of <em>j</em> on some shortest path from <em>i</em>. Just as the predecessor subgraph <em>G</em><sub>π</sub> from <a href="chapter022.xhtml">Chapter 22</a> is a shortest-paths tree for a given source vertex, the subgraph induced by the <em>i</em>th row of the Π matrix should be a shortest-paths tree with root <em>i</em>. For each vertex <em>i</em> ∈ <em>V</em>, the <span class="blue"><strong><em>predecessor subgraph</em></strong></span> of <em>G</em> for <em>i</em> is <em>G</em><sub>π,<em>i</em></sub> = (<em>V</em><sub>π,<em>i</em></sub>, <em>E</em><sub>π,<em>i</em></sub>), where</p>
<table class="table2b">
<tr>
<td class="td2"><em>V</em><sub>π,<em>i</em></sub></td>
<td class="td2">=</td>
<td class="td2">{<em>j</em> ∈ <em>V</em> : π<sub><em>ij</em></sub> ≠ <small>NIL</small>} ∪ {<em>i</em>},</td>
</tr>
<tr>
<td class="td2"><em>E</em><sub>π,<em>i</em></sub></td>
<td class="td2">=</td>
<td class="td2">{(π<sub><em>ij</em></sub>, <em>j</em>) : <em>j</em> ∈ <em>V</em><sub>π,<em>i</em></sub> − {<em>i</em>}}.</td>
</tr>
</table>
<p class="noindent">If <em>G</em><sub>π,<em>i</em></sub> is a shortest-paths tree, then P<small>RINT</small>-A<small>LL</small>-P<small>AIRS</small>-S<small>HORTEST</small>-P<small>ATH</small> on the following page, which is a modified version of the P<small>RINT</small>-P<small>ATH</small> procedure from <a href="chapter020.xhtml">Chapter 20</a>, prints a shortest path from vertex <em>i</em> to vertex <em>j</em>.</p>
<p>In order to highlight the essential features of the all-pairs algorithms in this chapter, we won’t cover how to compute predecessor matrices and their properties as extensively as we dealt with predecessor subgraphs in <a href="chapter022.xhtml">Chapter 22</a>. Some of the exercises cover the basics.</p>
<a id="p648"/>
<div class="pull-quote1">
<p class="box-heading">P<small>RINT</small>-A<small>LL</small>-P<small>AIRS</small>-S<small>HORTEST</small>-P<small>ATH</small>(Π, <em>i</em>, <em>j</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent"><strong>if</strong> <em>i</em> == <em>j</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="p2">print <em>i</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="noindent"><strong>elseif</strong> π<sub><em>ij</em></sub> == <small>NIL</small></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">4</span></p></td>
<td class="td1"><p class="p2">print “no path from” <em>i</em> “to” <em>j</em> “exists”</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="noindent"><strong>else</strong> P<small>RINT</small>-A<small>LL</small>-P<small>AIRS</small>-S<small>HORTEST</small>-P<small>ATH</small>(Π, <em>i</em>, π<sub><em>ij</em></sub>)</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">6</span></p></td>
<td class="td1"><p class="p2">print <em>j</em></p></td>
</tr>
</table>
</div>
<p class="level4"><strong>Chapter outline</strong></p>
<p class="noindent"><a href="chapter023.xhtml#Sec_23.1">Section 23.1</a> presents a dynamic-programming algorithm based on matrix multiplication to solve the all-pairs shortest-paths problem. The technique of “repeated squaring” yields a running time of Θ(<em>V</em><sup>3</sup> lg <em>V</em>). <a href="chapter023.xhtml#Sec_23.2">Section 23.2</a> gives another dynamic-programming algorithm, the Floyd-Warshall algorithm, which runs in Θ(<em>V</em><sup>3</sup>) time. <a href="chapter023.xhtml#Sec_23.2">Section 23.2</a> also covers the problem of finding the transitive closure of a directed graph, which is related to the all-pairs shortest-paths problem. Finally, <a href="chapter023.xhtml#Sec_23.3">Section 23.3</a> presents Johnson’s algorithm, which solves the all-pairs shortest-paths problem in <em>O</em>(<em>V</em><sup>2</sup> lg <em>V</em> + <em>VE</em>) time and is a good choice for large, sparse graphs.</p>
<p>Before proceeding, we need to establish some conventions for adjacency-matrix representations. First, we generally assume that the input graph <em>G</em> = (<em>V</em>, <em>E</em>) has <em>n</em> vertices, so that <em>n</em> = |<em>V</em>|. Second, we use the convention of denoting matrices by uppercase letters, such as <em>W</em>, <em>L</em>, or <em>D</em>, and their individual elements by subscripted lowercase letters, such as<em> w<sub>ij</sub></em>, <em>l<sub>ij</sub></em>, or <em>d<sub>ij</sub></em>. Finally, some matrices have parenthesized superscripts, as in <img alt="art" src="images/Art_P680.jpg"/> or <img alt="art" src="images/Art_P680a.jpg"/>, to indicate iterates.</p>
<p class="line1"/>
<section title="23.1 Shortest paths and matrix multiplication">
<a id="Sec_23.1"/>
<p class="level1" id="h1-136"><a href="toc.xhtml#Rh1-136"><strong>23.1    Shortest paths and matrix multiplication</strong></a></p>
<p class="noindent">This section presents a dynamic-programming algorithm for the all-pairs shortest-paths problem on a directed graph <em>G</em> = (<em>V</em>, <em>E</em>). Each major loop of the dynamic program invokes an operation similar to matrix multiplication, so that the algorithm looks like repeated matrix multiplication. We’ll start by developing a Θ(<em>V</em><sup>4</sup>)-time algorithm for the all-pairs shortest-paths problem, and then we’ll improve its running time to Θ(<em>V</em><sup>3</sup> lg <em>V</em>).</p>
<p>Before proceeding, let’s briefly recap the steps given in <a href="chapter014.xhtml">Chapter 14</a> for developing a dynamic-programming algorithm:</p>
<ol class="olnoindent" epub:type="list">
<li>Characterize the structure of an optimal solution.</li>
<li class="litop">Recursively define the value of an optimal solution.</li>
<li class="litop">Compute the value of an optimal solution in a bottom-up fashion.</li></ol>
<a id="p649"/>
<p class="noindent">We reserve the fourth step—constructing an optimal solution from computed information—for the exercises.</p>
<p class="level4"><strong>The structure of a shortest path</strong></p>
<p class="noindent">Let’s start by characterizing the structure of an optimal solution. Lemma 22.1 tells us that all subpaths of a shortest path are shortest paths. Consider a shortest path <em>p</em> from vertex <em>i</em> to vertex <em>j</em>, and suppose that <em>p</em> contains at most <em>r</em> edges. Assuming that there are no negative-weight cycles, <em>r</em> is finite. If <em>i = j</em>, then <em>p</em> has weight 0 and no edges. If vertices <em>i</em> and <em>j</em> are distinct, then decompose path <em>p</em> into <img alt="art" src="images/Art_P681.jpg"/>, where path <em>p</em>′ now contains at most <em>r</em> − 1 edges. Lemma 22.1 says that <em>p</em>′ is a shortest path from <em>i</em> to <em>k</em>, and so δ(<em>i</em>, <em>j</em>) = δ(<em>i</em>, <em>k</em>) + <em>w<sub>kj</sub></em>.</p>
<p class="level4"><strong>A recursive solution to the all-pairs shortest-paths problem</strong></p>
<p class="noindent">Now, let <img alt="art" src="images/Art_P682.jpg"/> be the minimum weight of any path from vertex <em>i</em> to vertex <em>j</em> that contains at most <em>r</em> edges. When <em>r</em> = 0, there is a shortest path from <em>i</em> to <em>j</em> with no edges if and only if <em>i</em> = <em>j</em>, yielding</p>
<p class="eqr"><img alt="art" src="images/Art_P683.jpg"/></p>
<p class="noindent">For <em>r</em> ≥ 1, one way to achieve a minimum-weight path from <em>i</em> to <em>j</em> with at most <em>r</em> edges is by taking a path containing at most <em>r</em> − 1 edges, so that <img alt="art" src="images/Art_P684.jpg"/>. Another way is by taking a path of at most <em>r</em> − 1 edges from <em>i</em> to some vertex <em>k</em> and then taking the edge (<em>k</em>, <em>j</em>), so that <img alt="art" src="images/Art_P685.jpg"/>. Therefore, to examine paths from <em>i</em> to <em>j</em> consisting of at most <em>r</em> edges, try all possible predecessors <em>k</em> of <em>j</em>, giving the recursive definition</p>
<p class="eqr"><img alt="art" src="images/Art_P686.jpg"/></p>
<p class="noindent">The last equality follows from the observation that <em>w<sub>jj</sub></em> = 0 for all <em>j</em>.</p>
<p>What are the actual shortest-path weights δ(<em>i</em>, <em>j</em>)? If the graph contains no negative-weight cycles, then whenever δ(<em>i</em>, <em>j</em>) &lt; ∞, there is a shortest path from vertex <em>i</em> to vertex <em>j</em> that is simple. (A path <em>p</em> from <em>i</em> to <em>j</em> that is not simple contains a cycle. Since each cycle’s weight is nonnegative, removing all cycles from the path leaves a simple path with weight no greater than <em>p</em>’s weight.) Because any simple path contains at most <em>n</em> − 1 edges, a path from vertex <em>i</em> to vertex <em>j</em> with more than <em>n</em> − 1 edges cannot have lower weight than a shortest path from <em>i</em> to <em>j</em>. The actual shortest-path weights are therefore given by</p>
<a id="p650"/>
<p class="eqr"><img alt="art" src="images/Art_P687.jpg"/></p>
<p class="level4"><strong>Computing the shortest-path weights bottom up</strong></p>
<p class="noindent">Taking as input the matrix <em>W</em> = (<em>w<sub>ij</sub></em>), let’s see how to compute a series of matrices <em>L</em><sup>(0)</sup>, <em>L</em><sup>(1)</sup>, … , <em>L</em><sup>(<em>n</em>−1)</sup>, where <img alt="art" src="images/Art_P688.jpg"/> for <em>r</em> = 0, 1, … , <em>n</em> − 1. The initial matrix is <em>L</em><sup>(0)</sup> given by equation (23.2). The final matrix <em>L</em><sup>(<em>n</em>−1)</sup> contains the actual shortest-path weights.</p>
<p>The heart of the algorithm is the procedure E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>, which implements equation (23.3) for all <em>i</em> and <em>j</em>. The four inputs are the matrix <em>L</em><sup>(<em>r</em>−1)</sup> computed so far; the edge-weight matrix <em>W</em>; the output matrix <em>L</em><sup>(<em>r</em>)</sup>, which will hold the computed result and whose elements are all initialized to ∞ before invoking the procedure; and the number <em>n</em> of vertices. The superscripts <em>r</em> and <em>r</em> − 1 help to make the correspondence of the pseudocode with equation (23.3) plain, but they play no actual role in the pseudocode. The procedure extends the shortest paths computed so far by one more edge, producing the matrix <em>L</em><sup>(<em>r</em>)</sup> of shortest-path weights from the matrix <em>L</em><sup>(<em>r</em>−1)</sup> computed so far. Its running time is Θ(<em>n</em><sup>3</sup>) due to the three nested <strong>for</strong> loops.</p>
<div class="pull-quote1">
<p class="box-heading">E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>(<em>L</em><sup>(<em>r</em>−1)</sup>, <em>W</em>, <em>L</em><sup>(<em>r</em>)</sup>, <em>n</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent"><span class="red">// Assume that the elements of <em>L</em><sup>(<em>r</em>)</sup> are initialized to ∞.</span></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="p2"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">4</span></p></td>
<td class="td1"><p class="p3"><strong>for</strong> <em>k</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="p4"><img alt="art" src="images/Art_P689.jpg"/></p></td>
</tr>
</table>
</div>
<p>Let’s now understand the relation of this computation to matrix multiplication. Consider how to compute the matrix product <em>C</em> = <em>A</em> · <em>B</em> of two <em>n</em> × <em>n</em> matrices <em>A</em> and <em>B</em>. The straightforward method used by M<small>ATRIX</small>-M<small>ULTIPLY</small> on page 81 uses a triply nested loop to implement equation (4.1), which we repeat here for convenience:</p>
<p class="eqr"><img alt="art" src="images/Art_P690.jpg"/></p>
<p class="noindent">for <em>i</em>, <em>j</em> = 1, 2, … , <em>n</em>. Now make the substitutions</p>
<a id="p651"/>
<table class="table2b">
<tr>
<td class="td1"><p class="right"><em>l</em><sup>(<em>r</em>−1)</sup></p></td>
<td class="td1"><p class="center"> → </p></td>
<td class="td1"><p class="noindent"><em>a</em>,</p></td>
</tr>
<tr>
<td class="td1"><p class="right"><em>w</em></p></td>
<td class="td1"><p class="center"> → </p></td>
<td class="td1"><p class="noindent"><em>b</em>,</p></td>
</tr>
<tr>
<td class="td1"><p class="right"><em>l</em><sup>(<em>r</em>)</sup></p></td>
<td class="td1"><p class="center"> → </p></td>
<td class="td1"><p class="noindent"><em>c</em>,</p></td>
</tr>
<tr>
<td class="td1"><p class="right">min</p></td>
<td class="td1"><p class="center"> → </p></td>
<td class="td1"><p class="noindent">+,</p></td>
</tr>
<tr>
<td class="td1"><p class="right">+</p></td>
<td class="td1"><p class="center"> → </p></td>
<td class="td1"><p class="noindent">.</p></td>
</tr>
</table>
<p class="noindent">in equation (23.3). You get equation (23.5)! Making these changes to E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>, and also replacing ∞ (the identity for min) by 0 (the identity for +), yields the procedure M<small>ATRIX</small>-M<small>ULTIPLY</small>. We can see that the procedure E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>(<em>L</em><sup>(<em>r</em>−1)</sup>, <em>W</em>, <em>L</em><sup>(<em>r</em>)</sup>, <em>n</em>) computes the matrix “product” <em>L</em><sup>(<em>r</em>)</sup> = <em>L</em><sup>(<em>r</em>−1)</sup>. <em>W</em> using this unusual definition of matrix multiplication.<sup><a epub:type="footnote" href="#footnote_2" id="footnote_ref_2">2</a></sup></p>
<p>Thus, we can solve the all-pairs shortest-paths problem by repeatedly multiplying matrices. Each step extends the shortest-path weights computed so far by one more edge using E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>(<em>L</em><sup>(<em>r</em>−1)</sup>, <em>W</em>, <em>L</em><sup>(<em>r</em>)</sup>, <em>n</em>) to perform the matrix multiplication. Starting with the matrix <em>L</em><sup>(0)</sup>, we produce the following sequence of <em>n</em> − 1 matrices corresponding to powers of <em>W</em>:</p>
<table class="table2b">
<tr>
<td class="td2"><p class="right"><em>L</em><sup>(1)</sup></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="center"><em>L</em><sup>(0)</sup> · <em>W</em></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="noindent"><em>W</em><sup>1</sup>,</p></td>
</tr>
<tr>
<td class="td2"><p class="right"><em>L</em><sup>(2)</sup></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="center"><em>L</em><sup>(1)</sup> · <em>W</em></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="noindent"><em>W</em><sup>2</sup>,</p></td>
</tr>
<tr>
<td class="td2"><p class="right"><em>L</em><sup>(3)</sup></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="center"><em>L</em><sup>(2)</sup> · <em>W</em></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="noindent"><em>W</em><sup>3</sup>,</p></td>
</tr>
<tr>
<td class="td2"/>
<td class="td2"><p class="center"/></td>
<td class="td2"><p class="center"><span class="font1">⋮</span></p></td>
<td class="td2"><p class="center"/></td>
<td class="td2"><p class="noindent"/></td>
</tr>
<tr>
<td class="td2"><p class="right"><em>L</em><sup>(<em>n</em>−1)</sup></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="center"><em>L</em><sup>(<em>n</em>−2)</sup> · <em>W</em></p></td>
<td class="td2"><p class="center">=</p></td>
<td class="td2"><p class="noindent"><em>W</em><sup><em>n</em>−1</sup>.</p></td>
</tr>
</table>
<p class="noindent">At the end, the matrix <em>L</em><sup>(<em>n</em>−1)</sup> = <em>W</em><sup><em>n</em>−1</sup> contains the shortest-path weights.</p>
<p>The procedure S<small>LOW</small>-APSP on the next page computes this sequence in Θ(<em>n</em><sup>4</sup>) time. The procedure takes the <em>n</em> × <em>n</em> matrices <em>W</em> and <em>L</em><sup>(0)</sup> as inputs, along with <em>n</em>. <a href="chapter023.xhtml#Fig_23-1">Figure 23.1</a> illustrates its operation. The pseudocode uses two <em>n</em> × <em>n</em> matrices <em>L</em> and <em>M</em> to store powers of <em>W</em>, computing <em>M</em> = <em>L</em> · <em>W</em> on each iteration. Line 2 initializes <em>L</em> = <em>L</em><sup>(0)</sup>. For each iteration <em>r</em>, line 4 initializes <em>M</em> = ∞, where ∞ in this context is a matrix of scalar ∞ values. The <em>r</em>th iteration starts with the invariant <em>L</em> = <em>L</em><sup>(<em>r</em>−1)</sup> = <em>W</em><sup><em>r</em>−1</sup>. Line 6 computes <em>M</em> = <em>L</em> · <em>W</em> = <em>L</em><sup>(<em>r</em>−1)</sup> · <em>W</em> = <em>W</em><sup><em>r</em>−1</sup> · <em>W</em> = <em>W</em><sup><em>r</em></sup> = <em>L</em><sup>(<em>r</em>)</sup> so that the invariant can be restored for the next iteration by line 7, which sets <em>L</em> = <em>M</em>. At the end, the matrix <em>L</em> = <em>L</em><sup>(<em>n</em>−1)</sup> = <em>W</em><sup><em>n</em>−1</sup> of shortest-path weights is returned. The assignments to <em>n</em> × <em>n</em> matrices in lines 2, 4, and 7 implicitly run doubly nested loops that take Θ(<em>n</em><sup>2</sup>) time for each assignment. <a id="p652"/>The <em>n</em> − 1 invocations of E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>, each of which takes Θ(<em>n</em><sup>3</sup>) time, dominate the computation, yielding a total running time of Θ(<em>n</em><sup>4</sup>).</p>
<div class="divimage">
<p class="fig-imga" id="Fig_23-1"><img alt="art" src="images/Art_P691.jpg"/></p>
<p class="caption"><strong>Figure 23.1</strong> A directed graph and the sequence of matrices <em>L</em><sup>(<em>r</em>)</sup> computed by S<small>LOW</small>-APSP. You might want to verify that <em>L</em><sup>(5)</sup>, defined as <em>L</em><sup>(4)</sup> · <em>W</em>, equals <em>L</em><sup>(4)</sup>, and thus <em>L</em><sup>(<em>r</em>)</sup> = <em>L</em><sup>(4)</sup> for all <em>r</em> ≥ 4.</p>
</div>
<div class="pull-quote1">
<p class="box-heading">S<small>LOW</small>-APSP(<em>W</em>, <em>L</em><sup>(0)</sup>, <em>n</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent">let <em>L</em> = (<em>l<sub>ij</sub></em>) and <em>M</em> = (<em>m<sub>ij</sub></em>) be new <em>n</em> × <em>n</em> matrices</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="noindent"><em>L</em> = <em>L</em><sup>(0)</sup></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>r</em> = 1 <strong>to</strong> <em>n</em> − 1</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">4</span></p></td>
<td class="td1"><p class="p2"><em>M</em> = ∞       <span class="red">// initialize <em>M</em></span></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="p2"><span class="red">// Compute the matrix “product” <em>M</em> = <em>L</em> · <em>W</em>.</span></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">6</span></p></td>
<td class="td1"><p class="p2">E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>(<em>L</em>, <em>W</em>, <em>M</em>, <em>n</em>)</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">7</span></p></td>
<td class="td1"><p class="p2"><em>L</em> = <em>M</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">8</span></p></td>
<td class="td1"><p class="noindent"><strong>return</strong> <em>L</em></p></td>
</tr>
</table>
</div>
<p class="level4"><strong>Improving the running time</strong></p>
<p class="noindent">Bear in mind that the goal is not to compute <em>all</em> the <em>L</em><sup>(<em>r</em>)</sup> matrices: only the matrix <em>L</em><sup>(<em>n</em>−1)</sup> matters. Recall that in the absence of negative-weight cycles, equation (23.4) implies <em>L</em><sup>(<em>r</em>)</sup> = <em>L</em><sup>(<em>n</em>−1)</sup> for all integers <em>r</em> ≥ <em>n</em> − 1. Just as traditional matrix multiplication is associative, so is matrix multiplication defined by the E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small> procedure (see Exercise 23.1-4). In fact, we can compute <em>L</em><sup>(<em>n</em>−1)</sup> with only <span class="font1">⌈</span>lg(<em>n</em> – 1)<span class="font1">⌉</span> matrix products by using the technique of <span class="blue"><strong><em>repeated squaring</em></strong>:</span></p>
<a id="p653"/>
<p class="eql"><img alt="art" src="images/Art_P693.jpg"/></p>
<p class="noindent">Since 2<sup><span class="font1">⌈</span>lg(<em>n</em> – 1)<span class="font1">⌉</span></sup> ≥ <em>n</em> – 1, the final product is <img alt="art" src="images/Art_P695.jpg"/>.</p>
<p>The procedure F<small>ASTER</small>-APSP implements this idea. It takes just the <em>n</em> × <em>n</em> matrix <em>W</em> and the size <em>n</em> as inputs. Each iteration of the <strong>while</strong> loop of lines 4–8 starts with the invariant <em>L</em> = <em>W<sup>r</sup></em>, which it squares using E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small> to obtain the matrix <em>M</em> = <em>L</em><sup>2</sup> = (<em>W<sup>r</sup></em>)<sup>2</sup> = <em>W</em><sup>2<em>r</em></sup>. At the end of each iteration, the value of <em>r</em> doubles, and <em>L</em> for the next iteration becomes <em>M</em>, restoring the invariant. Upon exiting the loop when <em>r</em> ≥ <em>n</em> − 1, the procedure returns <em>L</em> = <em>W</em><sup>r</sup> = <em>L</em><sup>(<em>r</em>)</sup> = <em>L</em><sup>(<em>n</em>−1)</sup> by equation (23.4). As in S<small>LOW</small>-APSP, the assignments to <em>n</em> × <em>n</em> matrices in lines 2, 5, and 8 implicitly run doubly nested loops, taking Θ(<em>n</em><sup>2</sup>) time for each assignment.</p>
<div class="pull-quote1">
<p class="box-heading">F<small>ASTER</small>-APSP(<em>W</em>, <em>n</em>)</p>
<table class="table1a1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1" colspan="3"><p class="noindent">let <em>L</em> and <em>M</em> be new <em>n</em> × <em>n</em> matrices</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1" colspan="3"><p class="noindent"><em>L</em> = <em>W</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1" colspan="3"><p class="noindent"><em>r</em> = 1</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">4</span></p></td>
<td class="td1" colspan="3"><p class="noindent"><strong>while</strong> <em>r</em> &lt; <em>n</em> − 1</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="p2"><em>M</em> = ∞</p></td>
<td class="td1" colspan="2"><p class="noindent"><span class="red">// initialize M</span></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">6</span></p></td>
<td class="td1" colspan="2">
<p class="p2">E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small>(<em>L</em>, <em>L</em>, <em>M</em>, <em>n</em>)</p></td>
<td class="td1"><p class="noindent"><span class="red">// compute <em>M</em> = <em>L</em><sup>2</sup></span></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">7</span></p></td>
<td class="td1" colspan="3"><p class="p2"><em>r</em> = 2<em>r</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">8</span></p></td>
<td class="td1"><p class="p2"><em>L</em> = <em>M</em></p></td>
<td class="td1" colspan="2"><p class="noindent"><span class="red">// ready for the next iteration</span></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">9</span></p></td>
<td class="td1" colspan="3"><p class="noindent"><strong>return</strong> <em>L</em></p></td>
</tr>
</table>
</div>
<p>Because each of the <span class="font1">⌈</span>lg(<em>n</em> – 1)<span class="font1">⌉</span> matrix products takes Θ(<em>n</em><sup>3</sup>) time, F<small>ASTER</small>-APSP runs in Θ(<em>n</em><sup>3</sup> lg <em>n</em>) time. The code is tight, containing no elaborate data structures, and the constant hidden in the Θ-notation is therefore small.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>23.1-1</em></strong></p>
<p class="noindent">Run S<small>LOW</small>-APSP on the weighted, directed graph of <a href="chapter023.xhtml#Fig_23-2">Figure 23.2</a>, showing the matrices that result for each iteration of the loop. Then do the same for F<small>ASTER</small>-APSP.</p>
<a id="p654"/>
<div class="divimage">
<p class="fig-imga" id="Fig_23-2"><img alt="art" src="images/Art_P697.jpg"/></p>
<p class="caption"><strong>Figure 23.2</strong> A weighted, directed graph for use in Exercises 23.1-1, 23.2-1, and 23.3-1.</p>
</div>
<p class="level3"><strong><em>23.1-2</em></strong></p>
<p class="noindent">Why is it convenient for both S<small>LOW</small>-APSP and F<small>ASTER</small>-APSP that <em>w<sub>ii</sub></em> = 0 for <em>i</em> = 1, 2, … , <em>n</em>?</p>
<p class="level3"><strong><em>23.1-3</em></strong></p>
<p class="noindent">What does the matrix</p>
<p class="eql"><img alt="art" src="images/Art_P698.jpg"/></p>
<p class="noindent">used in the shortest-paths algorithms correspond to in regular matrix multiplication?</p>
<p class="level3"><strong><em>23.1-4</em></strong></p>
<p class="noindent">Show that matrix multiplication defined by E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small> is associative.</p>
<p class="level3"><strong><em>23.1-5</em></strong></p>
<p class="noindent">Show how to express the single-source shortest-paths problem as a product of matrices and a vector. Describe how evaluating this product corresponds to a Bellman-Ford-like algorithm (see <a href="chapter022.xhtml#Sec_22.1">Section 22.1</a>).</p>
<p class="level3"><strong><em>23.1-6</em></strong></p>
<p class="noindent">Argue that we don’t need the matrix <em>M</em> in S<small>LOW</small>-APSP because by substituting <em>L</em> for <em>M</em> and leaving out the initialization of <em>M</em>, the code still works correctly. (<em>Hint:</em> Relate line 5 of E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small> to R<small>ELAX</small> on page 610.) Do we need the matrix <em>M</em> in F<small>ASTER</small>-APSP?</p>
<a id="p655"/>
<p class="level3"><strong><em>23.1-7</em></strong></p>
<p class="noindent">Suppose that you also want to compute the vertices on shortest paths in the algorithms of this section. Show how to compute the predecessor matrix Π from the completed matrix <em>L</em> of shortest-path weights in <em>O</em>(<em>n</em><sup>3</sup>) time.</p>
<p class="level3"><strong><em>23.1-8</em></strong></p>
<p class="noindent">You can also compute the vertices on shortest paths along with computing the shortest-path weights. Define <img alt="art" src="images/Art_P699.jpg"/> as the predecessor of vertex <em>j</em> on any minimum-weight path from vertex <em>i</em> to vertex <em>j</em> that contains at most <em>r</em> edges. Modify the E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small> and S<small>LOW</small>-APSP procedures to compute the matrices Π<sup>(1)</sup>, Π<sup>(2)</sup>, … , Π<sup>(<em>n</em>−1)</sup> as they compute the matrices <em>L</em><sup>(1)</sup>, <em>L</em><sup>(2)</sup>, … , <em>L</em><sup>(<em>n</em>−1)</sup>.</p>
<p class="level3"><strong><em>23.1-9</em></strong></p>
<p class="noindent">Modify F<small>ASTER</small>-APSP so that it can determine whether the graph contains a negative-weight cycle.</p>
<p class="level3"><strong><em>23.1-10</em></strong></p>
<p class="noindent">Give an efficient algorithm to find the length (number of edges) of a minimum-length negative-weight cycle in a graph.</p>
</section>
<p class="line1"/>
<section title="23.2 The Floyd-Warshall algorithm">
<a id="Sec_23.2"/>
<p class="level1" id="h1-137"><a href="toc.xhtml#Rh1-137"><strong>23.2    The Floyd-Warshall algorithm</strong></a></p>
<p class="noindent">Having already seen one dynamic-programming solution to the all-pairs shortest-paths problem, in this section we’ll see another: the <span class="blue"><strong><em>Floyd-Warshall algorithm</em></strong></span>, which runs in Θ(<em>V</em><sup>3</sup>) time. As before, negative-weight edges may be present, but not negative-weight cycles. As in <a href="chapter023.xhtml#Sec_23.1">Section 23.1</a>, we develop the algorithm by following the dynamic-programming process. After studying the resulting algorithm, we present a similar method for finding the transitive closure of a directed graph.</p>
<p class="level4"><strong>The structure of a shortest path</strong></p>
<p class="noindent">In the Floyd-Warshall algorithm, we characterize the structure of a shortest path differently from how we characterized it in <a href="chapter023.xhtml#Sec_23.1">Section 23.1</a>. The Floyd-Warshall algorithm considers the intermediate vertices of a shortest path, where an <span class="blue"><strong><em>intermediate</em></strong></span> vertex of a simple path <em>p</em> = <span class="font1">〈</span><em>v</em><sub>1</sub>, <em>v</em><sub>2</sub>, … , <em>v<sub>l</sub></em><span class="font1">〉</span> is any vertex of <em>p</em> other than <em>v</em><sub>1</sub> or <em>v<sub>l</sub></em>, that is, any vertex in the set {<em>v</em><sub>2</sub>, <em>v</em><sub>3</sub>, … , <em>v</em><sub><em>l</em>−1</sub>}.</p>
<p>The Floyd-Warshall algorithm relies on the following observation. Numbering the vertices of <em>G</em> by <em>V</em> = {1, 2, … , <em>n</em>}, take a subset {1, 2, … , <em>k</em>} of vertices for some 1 ≤ <em>k</em> ≤ <em>n</em>. For any pair of vertices <em>i</em>, <em>j</em> ∈ <em>V</em>, consider all paths from <em>i</em> to <em>j</em> whose intermediate vertices are all drawn from {1, 2, … , <em>k</em>}, and let <em>p</em> be a <a id="p656"/>minimum-weight path from among them. (Path <em>p</em> is simple.) The Floyd-Warshall algorithm exploits a relationship between path <em>p</em> and shortest paths from <em>i</em> to <em>j</em> with all intermediate vertices in the set {1, 2, … , <em>k</em> − 1}. The details of the relationship depend on whether <em>k</em> is an intermediate vertex of path <em>p</em> or not.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_23-3"><img alt="art" src="images/Art_P700.jpg"/></p>
<p class="caption"><strong>Figure 23.3</strong> Optimal substructure used by the Floyd-Warshall algorithm. Path <em>p</em> is a shortest path from vertex <em>i</em> to vertex <em>j</em>, and <em>k</em> is the highest-numbered intermediate vertex of <em>p</em>. Path <em>p</em><sub>1</sub>, the portion of path <em>p</em> from vertex <em>i</em> to vertex <em>k</em>, has all intermediate vertices in the set {1, 2, … , <em>k</em> − 1}. The same holds for path <em>p</em><sub>2</sub> from vertex <em>k</em> to vertex <em>j</em>.</p>
</div>
<ul class="ulnoindent" epub:type="list">
<li>If <em>k</em> is not an intermediate vertex of path <em>p</em>, then all intermediate vertices of path <em>p</em> belong to the set {1, 2, … , <em>k</em> − 1}. Thus a shortest path from vertex <em>i</em> to vertex <em>j</em> with all intermediate vertices in the set {1, 2, … , <em>k</em> − 1} is also a shortest path from <em>i</em> to <em>j</em> with all intermediate vertices in the set {1, 2, … , <em>k</em>}.</li>
<li class="litop">If <em>k</em> is an intermediate vertex of path <em>p</em>, then decompose <em>p</em> into <img alt="art" src="images/Art_P701.jpg"/>, as <a href="chapter023.xhtml#Fig_23-3">Figure 23.3</a> illustrates. By Lemma 22.1, <em>p</em><sub>1</sub> is a shortest path from <em>i</em> to <em>k</em> with all intermediate vertices in the set {1, 2, … , <em>k</em>}. In fact, we can make a slightly stronger statement. Because vertex <em>k</em> is not an <em>intermediate</em> vertex of path <em>p</em><sub>1</sub>, all intermediate vertices of <em>p</em><sub>1</sub> belong to the set {1, 2, … , <em>k</em> − 1}. Therefore <em>p</em><sub>1</sub> is a shortest path from <em>i</em> to <em>k</em> with all intermediate vertices in the set {1, 2, … , <em>k</em> − 1}. Likewise, <em>p</em><sub>2</sub> is a shortest path from vertex <em>k</em> to vertex <em>j</em> with all intermediate vertices in the set {1, 2, … , <em>k</em> − 1}.</li></ul>
<p class="level4"><strong>A recursive solution to the all-pairs shortest-paths problem</strong></p>
<p class="noindent">The above observations suggest a recursive formulation of shortest-path estimates that differs from the one in <a href="chapter023.xhtml#Sec_23.1">Section 23.1</a>. Let <img alt="art" src="images/Art_P702.jpg"/> be the weight of a shortest path from vertex <em>i</em> to vertex <em>j</em> for which all intermediate vertices belong to the set {1, 2, … , <em>k</em>}. When <em>k</em> = 0, a path from vertex <em>i</em> to vertex <em>j</em> with no intermediate vertex numbered higher than 0 has no intermediate vertices at all. Such a path has at most one edge, and hence <img alt="art" src="images/Art_P703.jpg"/>. Following the above discussion, define <img alt="art" src="images/Art_P704.jpg"/> recursively by</p>
<a id="p657"/>
<p class="eqr"><img alt="art" src="images/Art_P705.jpg"/></p>
<p class="noindent">Because for any path, all intermediate vertices belong to the set {1, 2, … , <em>n</em>}, the matrix <img alt="art" src="images/Art_P706.jpg"/> gives the final answer: <img alt="art" src="images/Art_P707.jpg"/> for all <em>i</em>, <em>j</em> ∈ <em>V</em>.</p>
<p class="level4"><strong>Computing the shortest-path weights bottom up</strong></p>
<p class="noindent">Based on recurrence (23.6), the bottom-up procedure F<small>LOYD</small>-W<small>ARSHALL</small> computes the values <img alt="art" src="images/Art_P708.jpg"/> in order of increasing values of <em>k</em>. Its input is an <em>n</em> × <em>n</em> matrix <em>W</em> defined as in equation (23.1). The procedure returns the matrix <em>D</em><sup>(<em>n</em>)</sup> of shortest-path weights. <a href="chapter023.xhtml#Fig_23-4">Figure 23.4</a> shows the matrices <em>D</em><sup>(<em>k</em>)</sup> computed by the Floyd-Warshall algorithm for the graph in <a href="chapter023.xhtml#Fig_23-1">Figure 23.1</a>.</p>
<div class="pull-quote1">
<p class="box-heading">F<small>LOYD</small>-W<small>ARSHALL</small>(<em>W</em>, <em>n</em>)</p>
<table class="table1a1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent">D<sup>(0)</sup> = <em>W</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>k</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="p2">let <img alt="art" src="images/Art_P709.jpg"/> be a new <em>n</em> × <em>n</em> matrix</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">4</span></td>
<td class="td1"><p class="p2"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> n</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="p3"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">6</span></td>
<td class="td1"><p class="p4"><img alt="art" src="images/Art_P710.jpg"/></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">7</span></p></td>
<td class="td1"><p class="noindent"><strong>return</strong> <em>D</em><sup>(<em>n</em>)</sup></p></td>
</tr>
</table>
</div>
<p>The running time of the Floyd-Warshall algorithm is determined by the triply nested <strong>for</strong> loops of lines 2–6. Because each execution of line 6 takes <em>O</em>(1) time, the algorithm runs in Θ(<em>n</em><sup>3</sup>) time. As in the final algorithm in <a href="chapter023.xhtml#Sec_23.1">Section 23.1</a>, the code is tight, with no elaborate data structures, and so the constant hidden in the Θ-notation is small. Thus, the Floyd-Warshall algorithm is quite practical for even moderate-sized input graphs.</p>
<p class="level4"><strong>Constructing a shortest path</strong></p>
<p class="noindent">There are a variety of different methods for constructing shortest paths in the Floyd-Warshall algorithm. One way is to compute the matrix <em>D</em> of shortest-path weights and then construct the predecessor matrix Π from the <em>D</em> matrix. Exercise 23.1-7 asks you to implement this method so that it runs in <em>O</em>(<em>n</em><sup>3</sup>) time. Given the predecessor matrix Π, the P<small>RINT</small>-A<small>LL</small>-P<small>AIRS</small>-S<small>HORTEST</small>-P<small>ATH</small> procedure prints the vertices on a given shortest path.</p>
<p>Alternatively, the predecessor matrix … can be computed while the algorithm computes the matrices <em>D</em><sup>(0)</sup>, <em>D</em><sup>(1)</sup>, … , <em>D</em><sup>(<em>n</em>)</sup>. Specifically, compute a sequence of <a id="p658"/>matrices Π<sup>(0)</sup>, Π<sup>(1)</sup>, … , Π<sup>(<em>n</em>)</sup>, where Π = Π<sup>(<em>n</em>)</sup> and <img alt="art" src="images/Art_P711.jpg"/> is the predecessor of vertex <em>j</em> on a shortest path from vertex <em>i</em> with all intermediate vertices in the set {1, 2, … , <em>k</em>}.</p>
<div class="divimage">
<p class="fig-imga" id="Fig_23-4"><img alt="art" src="images/Art_P712.jpg"/></p>
<p class="caption"><strong>Figure 23.4</strong> The sequence of matrices <em>D</em><sup>(<em>k</em>)</sup> and Π<sup>(<em>k</em>)</sup> computed by the Floyd-Warshall algorithm for the graph in <a href="chapter023.xhtml#Fig_23-1">Figure 23.1</a>.</p>
</div>
<p>Here’s a recursive formulation of <img alt="art" src="images/Art_P713.jpg"/>. When <em>k</em> = 0, a shortest path from <em>i</em> to <em>j</em> has no intermediate vertices at all, and so</p>
<a id="p659"/>
<p class="eqr"><img alt="art" src="images/Art_P714.jpg"/></p>
<p class="noindent">For <em>k</em> ≥ 1, if the path has <em>k</em> as an intermediate vertex, so that it is <em>i</em> <span class="font1">⇝</span> <em>k</em> <span class="font1">⇝</span> <em>j</em> where <em>k</em> ≠ <em>j</em>, then choose as the predecessor of <em>j</em> on this path the same vertex as the predecessor of <em>j</em> chosen on a shortest path from <em>k</em> with all intermediate vertices in the set {1, 2, … , <em>k</em> − 1}. Otherwise, when the path from <em>i</em> to <em>j</em> does not have <em>k</em> as an intermediate vertex, choose the same predecessor of <em>j</em> as on a shortest path from <em>i</em> with all intermediate vertices in the set {1, 2, … , <em>k</em> − 1}. Formally, for <em>k</em> ≥ 1,</p>
<p class="eqr"><img alt="art" src="images/Art_P715.jpg"/></p>
<p>Exercise 23.2-3 asks you to show how to incorporate the Π<sup>(<em>k</em>)</sup> matrix computations into the F<small>LOYD</small>-W<small>ARSHALL</small> procedure. <a href="chapter023.xhtml#Fig_23-4">Figure 23.4</a> shows the sequence of Π<sup>(<em>k</em>)</sup> matrices that the resulting algorithm computes for the graph of <a href="chapter023.xhtml#Fig_23-1">Figure 23.1</a>. The exercise also asks for the more difficult task of proving that the predecessor subgraph <em>G</em><sub>π,<em>i</em></sub> is a shortest-paths tree with root <em>i</em>. Exercise 23.2-7 asks for yet another way to reconstruct shortest paths.</p>
<p class="level4"><strong>Transitive closure of a directed graph</strong></p>
<p class="noindent">Given a directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with vertex set <em>V</em> = {1, 2, … , <em>n</em>}, you might wish to determine simply whether <em>G</em> contains a path from <em>i</em> to <em>j</em> for all vertex pairs <em>i</em>, <em>j</em> ∈ <em>V</em>, without regard to edge weights. We define the <span class="blue"><strong><em>transitive closure</em></strong></span> of <em>G</em> as the graph <em>G</em>* = (<em>V</em>, <em>E</em>*), where</p>
<p class="eql"><em>E</em>* = {(<em>i</em>, <em>j</em>) : there is a path from vertex <em>i</em> to vertex <em>j</em> in <em>G</em>}.</p>
<p>One way to compute the transitive closure of a graph in Θ(<em>n</em><sup>3</sup>) time is to assign a weight of 1 to each edge of <em>E</em> and run the Floyd-Warshall algorithm. If there is a path from vertex <em>i</em> to vertex <em>j</em>, you get <em>d<sub>ij</sub></em> &lt; <em>n</em>. Otherwise, you get <em>d<sub>ij</sub></em> = ∞.</p>
<p>There is another, similar way to compute the transitive closure of <em>G</em> in Θ(<em>n</em><sup>3</sup>) time, which can save time and space in practice. This method substitutes the logical operations ∨ (logical OR) and ∧ (logical AND) for the arithmetic operations min and + in the Floyd-Warshall algorithm. For <em>i</em>, <em>j</em>, <em>k</em> = 1, 2, … , <em>n</em>, define <img alt="art" src="images/Art_P716.jpg"/> to be 1 if there exists a path in graph <em>G</em> from vertex <em>i</em> to vertex <em>j</em> with all intermediate vertices in the set {1, 2, … , <em>k</em>}, and 0 otherwise. To construct the transitive closure <em>G</em>* = (<em>V</em>, <em>E</em>*), put edge (<em>i</em>, <em>j</em>) into <em>E</em>* if and only if <img alt="art" src="images/Art_P717.jpg"/>. A recursive definition of <img alt="art" src="images/Art_P718.jpg"/>, analogous to recurrence (23.6), is</p>
<a id="p660"/>
<div class="divimage">
<p class="fig-imga" id="Fig_23-5"><img alt="art" src="images/Art_P719.jpg"/></p>
<p class="caption"><strong>Figure 23.5</strong> A directed graph and the matrices <em>T</em><sup>(<em>k</em>)</sup> computed by the transitive-closure algorithm.</p>
</div>
<p class="eql"><img alt="art" src="images/Art_P720.jpg"/></p>
<p class="noindent">and for <em>k</em> ≥ 1,</p>
<p class="eqr"><img alt="art" src="images/Art_P721.jpg"/></p>
<p class="noindent">As in the Floyd-Warshall algorithm, the T<small>RANSITIVE</small>-C<small>LOSURE</small> procedure computes the matrices <img alt="art" src="images/Art_P722.jpg"/> in order of increasing <em>k</em>.</p>
<div class="pull-quote1">
<p class="box-heading">T<small>RANSITIVE</small>-C<small>LOSURE</small>(<em>G</em>, <em>n</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  1</span></p></td>
<td class="td1"><p class="noindent">let <img alt="art" src="images/Art_P723.jpg"/> be a new <em>n</em> × <em>n</em> matrix</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  2</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  3</span></p></td>
<td class="td1"><p class="p2"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  4</span></p></td>
<td class="td1"><p class="p3"><strong>if</strong> <em>i</em> == <em>j</em> or (<em>i</em>, <em>j</em>) ∈ <em>G.E</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  5</span></p></td>
<td class="td1"><p class="p4"><img alt="art" src="images/Art_P724.jpg"/></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  6</span></p></td>
<td class="td1"><p class="p3"><strong>else</strong> <img alt="art" src="images/Art_P725.jpg"/></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  7</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>k</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  8</span></p></td>
<td class="td1"><p class="p2">let <img alt="art" src="images/Art_P726.jpg"/> be a new <em>n</em> × <em>n</em> matrix</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  9</span></p></td>
<td class="td1"><p class="p2"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">10</span></p></td>
<td class="td1"><p class="p3"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">11</span></p></td>
<td class="td1"><p class="p4"><img alt="art" src="images/Art_P727.jpg"/></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">12</span></p></td>
<td class="td1"><p class="noindent"><strong>return</strong> <em>T</em><sup>(<em>n</em>)</sup></p></td>
</tr>
</table>
</div>
<p><a href="chapter023.xhtml#Fig_23-5">Figure 23.5</a> shows the matrices <em>T</em><sup>(<em>k</em>)</sup> computed by the T<small>RANSITIVE</small>-C<small>LOSURE</small> procedure on a sample graph. The T<small>RANSITIVE</small>-C<small>LOSURE</small> procedure, like the Floyd-Warshall algorithm, runs in Θ(<em>n</em><sup>3</sup>) time. On some computers, though, logical operations on single-bit values execute faster than arithmetic operations on integer words of data. Moreover, because the direct transitive-closure algorithm <a id="p661"/>uses only boolean values rather than integer values, its space requirement is less than the Floyd-Warshall algorithm’s by a factor corresponding to the size of a word of computer storage.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>23.2-1</em></strong></p>
<p class="noindent">Run the Floyd-Warshall algorithm on the weighted, directed graph of <a href="chapter023.xhtml#Fig_23-2">Figure 23.2</a>. Show the matrix <em>D</em><sup>(<em>k</em>)</sup> that results for each iteration of the outer loop.</p>
<p class="level3"><strong><em>23.2-2</em></strong></p>
<p class="noindent">Show how to compute the transitive closure using the technique of <a href="chapter023.xhtml#Sec_23.1">Section 23.1</a>.</p>
<p class="level3"><strong><em>23.2-3</em></strong></p>
<p class="noindent">Modify the F<small>LOYD</small>-W<small>ARSHALL</small> procedure to compute the Π<sup>(<em>k</em>)</sup> matrices according to equations (23.7) and (23.8). Prove rigorously that for all <em>i</em> ∈ <em>V</em>, the predecessor subgraph <em>G</em><sub>π,<em>i</em></sub> is a shortest-paths tree with root <em>i</em>. (<em>Hint:</em> To show that <em>G</em><sub>π,<em>i</em></sub> is acyclic, first show that <img alt="art" src="images/Art_P728.jpg"/> implies <img alt="art" src="images/Art_P729.jpg"/>, according to the definition of <img alt="art" src="images/Art_P730.jpg"/>. Then adapt the proof of Lemma 22.16.)</p>
<p class="level3"><strong><em>23.2-4</em></strong></p>
<p class="noindent">As it appears on page 657, the Floyd-Warshall algorithm requires Θ(<em>n</em><sup>3</sup>) space, since it creates <img alt="art" src="images/Art_P731.jpg"/> for <em>i</em>, <em>j</em>, <em>k</em> = 1, 2, … , <em>n</em>. Show that the procedure F<small>LOYD</small>-W<small>ARSHALL</small>′, which simply drops all the superscripts, is correct, and thus only Θ(<em>n</em><sup>2</sup>) space is required.</p>
<div class="pull-quote1">
<p class="box-heading">F<small>LOYD</small>-W<small>ARSHALL</small>′(<em>W</em>, <em>n</em>)</p>
<table class="table1a1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">1</span></p></td>
<td class="td1"><p class="noindent"><em>D</em> = <em>W</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">2</span></p></td>
<td class="td1"><p class="noindent"><strong>for</strong> <em>k</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">3</span></p></td>
<td class="td1"><p class="p2"><strong>for</strong> <em>i</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">4</span></p></td>
<td class="td1"><p class="p3"><strong>for</strong> <em>j</em> = 1 <strong>to</strong> <em>n</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">5</span></p></td>
<td class="td1"><p class="p4"><em>d<sub>ij</sub></em> = min {<em>d<sub>ij</sub></em>, <em>d<sub>ik</sub></em> + <em>d<sub>kj</sub></em>}</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">6</span></p></td>
<td class="td1"><strong>return</strong> <em>D</em></td>
</tr>
</table>
</div>
<p class="level3"><strong><em>23.2-5</em></strong></p>
<p class="noindent">Consider the following change to how equation (23.8) handles equality:</p>
<p class="eql"><img alt="art" src="images/Art_P732.jpg"/></p>
<p class="noindent">Is this alternative definition of the predecessor matrix Π correct?</p>
<a id="p662"/>
<p class="level3"><strong><em>23.2-6</em></strong></p>
<p class="noindent">Show how to use the output of the Floyd-Warshall algorithm to detect the presence of a negative-weight cycle.</p>
<p class="level3"><strong><em>23.2-7</em></strong></p>
<p class="noindent">Another way to reconstruct shortest paths in the Floyd-Warshall algorithm uses values <img alt="art" src="images/Art_P733.jpg"/> for <em>i</em>,<em>j</em>,<em>k</em> = 1, 2, … , <em>n</em>, where <img alt="art" src="images/Art_P734.jpg"/> is the highest-numbered intermediate vertex of a shortest path from <em>i</em> to <em>j</em> in which all intermediate vertices lie in the set {1, 2, … , <em>k</em>}. Give a recursive formulation for <img alt="art" src="images/Art_P735.jpg"/>, modify the F<small>LOYD</small>-W<small>ARSHALL</small> procedure to compute the <img alt="art" src="images/Art_P736.jpg"/> values, and rewrite the P<small>RINT</small>-A<small>LL</small>-P<small>AIRS</small>-S<small>HORTEST</small>-P<small>ATH</small> procedure to take the matrix <img alt="art" src="images/Art_P737.jpg"/> as an input. How is the matrix Φ like the <em>s</em> table in the matrix-chain multiplication problem of <a href="chapter014.xhtml#Sec_14.2">Section 14.2</a>?</p>
<p class="level3"><strong><em>23.2-8</em></strong></p>
<p class="noindent">Give an <em>O</em>(<em>VE</em>)-time algorithm for computing the transitive closure of a directed graph <em>G</em> = (<em>V</em>, <em>E</em>). Assume that |<em>V</em>| = <em>O</em>(<em>E</em>) and that the graph is represented with adjacency lists.</p>
<p class="level3"><strong><em>23.2-9</em></strong></p>
<p class="noindent">Suppose that it takes <em>f</em>(|<em>V</em>|, |<em>E</em>|) time to compute the transitive closure of a directed acyclic graph, where <em>f</em> is a monotonically increasing function of both |<em>V</em>| and |<em>E</em>|. Show that the time to compute the transitive closure <em>G</em>* = (<em>V</em>, <em>E</em>*) of a general directed graph <em>G</em> = (<em>V</em>, <em>E</em>) is then <em>f</em>(|<em>V</em>|, |<em>E</em>|) + <em>O</em>(<em>V</em> + <em>E</em>*).</p>
</section>
<p class="line1"/>
<section title="23.3 Johnson’s algorithm for sparse graphs">
<a id="Sec_23.3"/>
<p class="level1" id="h1-138"><a href="toc.xhtml#Rh1-138"><strong>23.3    Johnson’s algorithm for sparse graphs</strong></a></p>
<p class="noindent">Johnson’s algorithm finds shortest paths between all pairs in <em>O</em>(<em>V</em><sup>2</sup> lg <em>V</em> + <em>VE</em>) time. For sparse graphs, it is asymptotically faster than either repeated squaring of matrices or the Floyd-Warshall algorithm. The algorithm either returns a matrix of shortest-path weights for all pairs of vertices or reports that the input graph contains a negative-weight cycle. Johnson’s algorithm uses as subroutines both Dijkstra’s algorithm and the Bellman-Ford algorithm, which <a href="chapter022.xhtml">Chapter 22</a> describes.</p>
<p>Johnson’s algorithm uses the technique of <span class="blue"><strong><em>reweighting</em></strong></span>, which works as follows. If all edge weights <em>w</em> in a graph <em>G</em> = (<em>V</em>, <em>E</em>) are nonnegative, Dijkstra’s algorithm can find shortest paths between all pairs of vertices by running it once from each vertex. With the Fibonacci-heap min-priority queue, the running time of this all-pairs algorithm is <em>O</em>(<em>V</em><sup>2</sup> lg <em>V</em> + <em>VE</em>). If <em>G</em> has negative-weight edges but no negative-weight cycles, first compute a new set of nonnegative edge weights so <a id="p663"/>that Dijkstra’s algorithm applies. The new set of edge weights <em><span class="font1">ŵ</span></em> must satisfy two important properties:</p>
<ol class="olnoindent" epub:type="list">
<li>For all pairs of vertices <em>u, v</em> ∈ <em>V</em>, a path <em>p</em> is a shortest path from <em>u</em> to <em>v</em> using weight function <em>w</em> if and only if <em>p</em> is also a shortest path from <em>u</em> to <em>v</em> using weight function <em><span class="font1">ŵ</span></em>.</li>
<li class="litop">For all edges (<em>u</em>, <em>v</em>), the new weight <em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) is nonnegative.</li></ol>
<p class="noindent">As we’ll see in a moment, preprocessing <em>G</em> to determine the new weight function <em><span class="font1">ŵ</span></em> takes <em>O</em>(<em>VE</em>) time.</p>
<p class="level4"><strong>Preserving shortest paths by reweighting</strong></p>
<p class="noindent">The following lemma shows how to reweight the edges to satisfy the first property above. We use δ to denote shortest-path weights derived from weight function <em>w</em> and <img alt="art" src="images/Art_P738.jpg"/> to denote shortest-path weights derived from weight function <em><span class="font1">ŵ</span></em>.</p>
<p class="lem"><strong><em>Lemma 23.1 (Reweighting does not change shortest paths)</em></strong></p>
<p class="noindent">Given a weighted, directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with weight function <em>w</em> : <em>E</em> → <span class="font1">ℝ</span>, let <em>h</em> : <em>V</em> → <span class="font1">ℝ</span> be any function mapping vertices to real numbers. For each edge (<em>u</em>, <em>v</em>) ∈ <em>E</em>, define</p>
<p class="eqr"><img alt="art" src="images/Art_P739.jpg"/></p>
<p class="noindent">Let <em>p</em> = <span class="font1">〈</span><em>v</em><sub>0</sub>, <em>v</em><sub>1</sub>, … , <em>v<sub>k</sub></em><span class="font1">〉</span> be any path from vertex <em>v</em><sub>0</sub> to vertex <em>v<sub>k</sub></em>. Then <em>p</em> is a shortest path from <em>v</em><sub>0</sub> to <em>v<sub>k</sub></em> with weight function <em>w</em> if and only if it is a shortest path with weight function <em><span class="font1">ŵ</span></em>. That is, <em>w</em>(<em>p</em>) = δ(<em>v</em><sub>0</sub>, <em>v<sub>k</sub></em>) if and only if <img alt="art" src="images/Art_P740.jpg"/>. Furthermore, <em>G</em> has a negative-weight cycle using weight function <em>w</em> if and only if <em>G</em> has a negative-weight cycle using weight function <em><span class="font1">ŵ</span></em>.</p>
<p class="prof"><strong><em>Proof</em></strong>   We start by showing that</p>
<p class="eqr"><img alt="art" src="images/Art_P741.jpg"/></p>
<p class="noindent">We have</p>
<p class="eql"><img alt="art" src="images/Art_P742.jpg"/></p>
<a id="p664"/>
<p class="noindent">Therefore, any path <em>p</em> from <em>v</em><sub>0</sub> to <em>v<sub>k</sub></em> has <em><span class="font1">ŵ</span></em>(<em>p</em>) = <em>w</em>(<em>p</em>) + <em>h</em>(<em>v</em><sub>0</sub>) − <em>h</em>(<em>v<sub>k</sub></em>). Because <em>h</em>(<em>v</em><sub>0</sub>) and <em>h</em>(<em>v<sub>k</sub></em>) do not depend on the path, if one path from <em>v</em><sub>0</sub> to <em>v<sub>k</sub></em> is shorter than another using weight function <em>w</em>, then it is also shorter using <em><span class="font1">ŵ</span></em>. Thus, <em>w</em>(<em>p</em>) = δ(<em>v</em><sub>0</sub>, <em>v<sub>k</sub></em>) if and only if <img alt="art" src="images/Art_P743.jpg"/>.</p>
<p>Finally, we show that <em>G</em> has a negative-weight cycle using weight function <em>w</em> if and only if <em>G</em> has a negative-weight cycle using weight function <em><span class="font1">ŵ</span></em>. Consider any cycle <em>c</em> = <span class="font1">〈</span><em>v</em><sub>0</sub>, <em>v</em><sub>1</sub>, … , <em>v<sub>k</sub></em><span class="font1">〉</span>, where <em>v</em><sub>0</sub> = <em>v<sub>k</sub></em>. By equation (23.11),</p>
<table class="table2b">
<tr>
<td class="td2"><em><span class="font1">ŵ</span></em>(<em>c</em>)</td>
<td class="td2">=</td>
<td class="td2"><em>w</em>(<em>c</em>) + <em>h</em>(<em>v</em><sub>0</sub>) + <em>h</em>(<em>v<sub>k</sub></em>)</td>
</tr>
<tr>
<td class="td2"/>
<td class="td2">=</td>
<td class="td2"><em>w</em>(<em>c</em>),</td>
</tr>
</table>
<p class="noindent">and thus <em>c</em> has negative weight using <em>w</em> if and only if it has negative weight using <em><span class="font1">ŵ</span></em>.</p>
<p class="right"><span class="font1">▪</span></p>
<p class="level4"><strong>Producing nonnegative weights by reweighting</strong></p>
<p class="noindent">Our next goal is to ensure that the second property holds: <em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) must be nonnegative for all edges (<em>u</em>, <em>v</em>) = <em>E</em>. Given a weighted, directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with weight function <em>w</em> : <em>E</em> → <span class="font1">ℝ</span>, we’ll see how to make a new graph <em>G</em>′ = (<em>V</em>′, <em>E</em>′), where <em>V</em>′ = <em>V</em> ∪ {<em>s</em>} for some new vertex <em>s</em> ∉ <em>V</em> and <em>E</em>′ = <em>E</em> ∪ {(<em>s</em>, <em>v</em>) : <em>v</em> = <em>V</em> }. To incorporate the new vertex <em>s</em>, extend the weight function <em>w</em> so that <em>w</em>(<em>s</em>, <em>v</em>) = 0 for all <em>v</em> ∈ <em>V</em>. Since no edges enter <em>s</em>, no shortest paths in <em>G</em>′, other than those with source <em>s</em>, contain <em>s</em>. Moreover, <em>G</em>′ has no negative-weight cycles if and only if <em>G</em> has no negative-weight cycles. <a href="chapter023.xhtml#Fig_23-6">Figure 23.6(a)</a> shows the graph <em>G</em>′ corresponding to the graph <em>G</em> of <a href="chapter023.xhtml#Fig_23-1">Figure 23.1</a>.</p>
<p>Now suppose that <em>G</em> and <em>G</em>′ have no negative-weight cycles. Define the function <em>h</em>(<em>v</em>) = δ(<em>s</em>, <em>v</em>) for all <em>v</em> ∈ <em>V</em>′. By the triangle inequality (Lemma 22.10 on page 633), we have <em>h</em>(<em>v</em>) ≤ <em>h</em>(<em>u</em>) + <em>w</em>(<em>u</em>, <em>v</em>) for all edges (<em>u</em>, <em>v</em>) ∈ <em>E</em>′. Thus, by defining reweighted edge weights <em><span class="font1">ŵ</span></em> according to equation (23.10), we have <em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) = <em>w</em>(<em>u</em>, <em>v</em>) + <em>h</em>(<em>u</em>) − <em>h</em>(<em>v</em>) ≥ 0, thereby satisfying the second property. <a href="chapter023.xhtml#Fig_23-6">Figure 23.6(b)</a> shows the graph <em>G</em>′ from <a href="chapter023.xhtml#Fig_23-6">Figure 23.6(a)</a> with reweighted edges.</p>
<p class="level4"><strong>Computing all-pairs shortest paths</strong></p>
<p class="noindent">Johnson’s algorithm to compute all-pairs shortest paths uses the Bellman-Ford algorithm (<a href="chapter022.xhtml#Sec_22.1">Section 22.1</a>) and Dijkstra’s algorithm (<a href="chapter022.xhtml#Sec_22.3">Section 22.3</a>) as subroutines. The pseudocode appears in the procedure J<small>OHNSON</small> on page 666. It assumes implicitly that the edges are stored in adjacency lists. The algorithm returns the usual |<em>V</em>| × |<em>V</em>| matrix <em>D</em> = (<em>d<sub>ij</sub></em>), where <em>d<sub>ij</sub></em> = δ(<em>i</em>, <em>j</em>), or it reports that the input graph contains a negative-weight cycle. As is typical for an all-pairs shortest-paths algorithm, it assumes that the vertices are numbered from 1 to |<em>V</em>|.</p>
<a id="p665"/>
<div class="divimage">
<p class="fig-imga" id="Fig_23-6"><img alt="art" src="images/Art_P744.jpg"/></p>
<p class="caption"><strong>Figure 23.6</strong> Johnson’s all-pairs shortest-paths algorithm run on the graph of <a href="chapter023.xhtml#Fig_23-1">Figure 23.1</a>. Vertex numbers appear outside the vertices. <strong>(a)</strong> The graph <em>G</em>′ with the original weight function <em>w</em>. The new vertex <em>s</em> is blue. Within each vertex <em>v</em> is <em>h</em>(<em>v</em>) = δ(<em>s</em>, <em>v</em>). <strong>(b)</strong> After reweighting each edge (<em>u</em>, <em>v</em>) with weight function <em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) = <em>w</em>(<em>u</em>, <em>v</em>) + <em>h</em>(<em>u</em>) − <em>h</em>(<em>v</em>). <strong>(c)–(g)</strong> The result of running Dijkstra’s algorithm on each vertex of <em>G</em> using weight function <em><span class="font1">ŵ</span></em>. In each part, the source vertex <em>u</em> is blue, and blue edges belong to the shortest-paths tree computed by the algorithm. Within each vertex <em>v</em> are the values <img alt="art" src="images/Art_P745.jpg"/> and δ(<em>u</em>, <em>v</em>), separated by a slash. The value <em>d<sub>uv</sub></em> = δ(<em>u</em>, <em>v</em>) is equal to <img alt="art" src="images/Art_P746.jpg"/>.</p>
</div>
<a id="p666"/>
<div class="pull-quote1">
<p class="box-heading">J<small>OHNSON</small>(<em>G</em>, <em>w</em>)</p>
<table class="table1">
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  1</span></p></td>
<td class="td1"><p class="noindent">compute <em>G</em>′, where <em>G</em>′.<em>V</em> = <em>G.V</em> ∪ {<em>s</em>},</p></td>
</tr>
<tr>
<td class="td1"/>
<td class="td1"><p class="p2"><em>G</em>′.<em>E</em> = <em>G.E</em> ∪ {(<em>s</em>, <em>v</em>) : <em>v</em> ∈ <em>G.V</em>}, and</p></td>
</tr>
<tr>
<td class="td1"/>
<td class="td1"><p class="p2"><em>w</em>(<em>s</em>, <em>v</em>) = 0 for all <em>v</em> ∈ <em>G.V</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  2</span></p></td>
<td class="td1"><p class="noindent"><strong>if</strong> B<small>ELLMAN</small>-F<small>ORD</small>(<em>G</em>′, <em>w</em>, <em>s</em>) == <small>FALSE</small></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  3</span></p></td>
<td class="td1"><p class="p2">print “the input graph contains a negative-weight cycle”</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  4</span></p></td>
<td class="td1"><p class="noindent"><strong>else for</strong> each vertex <em>v</em> ∈ <em>G</em>′.<em>V</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  5</span></p></td>
<td class="td1"><p class="p3">set <em>h</em>(<em>v</em>) to the value of δ(<em>s</em>, <em>v</em>)</p></td>
</tr>
<tr>
<td class="td1"/>
<td class="td1"><p class="p4">computed by the Bellman-Ford algorithm</p></td>
</tr>
<tr>
<td class="td1"><span class="x-small">  6</span></td>
<td class="td1"><p class="p2"><strong>for</strong> each edge (<em>u</em>, <em>v</em>) ∈ <em>G</em>′.<em>E</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  7</span></p></td>
<td class="td1"><p class="p3"><em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) = <em>w</em>(<em>u</em>, <em>v</em>) + <em>h</em>(<em>u</em>) − <em>h</em>(<em>v</em>)</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  8</span></p></td>
<td class="td1"><p class="p2">let <em>D</em> = (<em>d<sub>uv</sub></em>) be a new <em>n</em> × <em>n</em> matrix</p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">  9</span></p></td>
<td class="td1"><p class="p2"><strong>for</strong> each vertex <em>u</em> ∈ <em>G.V</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">10</span></p></td>
<td class="td1"><p class="p3">run D<small>IJKSTRA</small>(<em>G</em>, <em><span class="font1">ŵ</span></em>, <em>u</em>) to compute <img alt="art" src="images/Art_P747.jpg"/> for all <em>v</em> ∈ <em>G.V</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">11</span></p></td>
<td class="td1"><p class="p3">for each vertex <em>v</em> ∈ <em>G.V</em></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">12</span></p></td>
<td class="td1"><p class="p4"><img alt="art" src="images/Art_P748.jpg"/></p></td>
</tr>
<tr>
<td class="td1w"><p class="noindent"><span class="x-small">13</span></p></td>
<td class="td1"><p class="noindent"><strong>return</strong> <em>D</em></p></td>
</tr>
</table>
</div>
<p>The J<small>OHNSON</small> procedure simply performs the actions specified earlier. Line 1 produces <em>G</em>′. Line 2 runs the Bellman-Ford algorithm on <em>G</em>′ with weight function <em>w</em> and source vertex <em>s</em>. If <em>G</em>′, and hence <em>G</em>, contains a negative-weight cycle, line 3 reports the problem. Lines 4–12 assume that <em>G</em>′ contains no negative-weight cycles. Lines 4–5 set <em>h</em>(<em>v</em>) to the shortest-path weight δ(<em>s</em>, <em>v</em>) computed by the Bellman-Ford algorithm for all <em>v</em> ∈ <em>V</em>′. Lines 6–7 compute the new weights <em><span class="font1">ŵ</span></em>. For each pair of vertices <em>u</em>, <em>v</em> ∈ <em>V</em>, the <strong>for</strong> loop of lines 9–12 computes the shortest-path weight <img alt="art" src="images/Art_P749.jpg"/> by calling Dijkstra’s algorithm once from each vertex in <em>V</em>. Line 12 stores in matrix entry <em>d<sub>uv</sub></em> the correct shortest-path weight δ(<em>u</em>, <em>v</em>), calculated using equation (23.11). Finally, line 13 returns the completed <em>D</em> matrix. <a href="chapter023.xhtml#Fig_23-6">Figure 23.6</a> depicts the execution of Johnson’s algorithm.</p>
<p>If the min-priority queue in Dijkstra’s algorithm is implemented by a Fibonacci heap, Johnson’s algorithm runs in <em>O</em>(<em>V</em><sup>2</sup> lg <em>V</em> + <em>VE</em>) time. The simpler binary min-heap implementation yields a running time of <em>O</em>(<em>VE</em> lg <em>V</em>), which is still asymptotically faster than the Floyd-Warshall algorithm if the graph is sparse.</p>
<p class="exe"><strong>Exercises</strong></p>
<p class="level3"><strong><em>23.3-1</em></strong></p>
<p class="noindent">Use Johnson’s algorithm to find the shortest paths between all pairs of vertices in the graph of <a href="chapter023.xhtml#Fig_23-2">Figure 23.2</a>. Show the values of <em>h</em> and <em><span class="font1">ŵ</span></em> computed by the algorithm.</p>
<a id="p667"/>
<p class="level3"><strong><em>23.3-2</em></strong></p>
<p class="noindent">What is the purpose of adding the new vertex <em>s</em> to <em>V</em>, yielding <em>V</em>′?</p>
<p class="level3"><strong><em>23.3-3</em></strong></p>
<p class="noindent">Suppose that <em>w</em>(<em>u</em>, <em>v</em>) ≥ 0 for all edges (<em>u</em>, <em>v</em>) ∈ <em>E</em>. What is the relationship between the weight functions <em>w</em> and <em><span class="font1">ŵ</span></em>?</p>
<p class="level3"><strong><em>23.3-4</em></strong></p>
<p class="noindent">Professor Greenstreet claims that there is a simpler way to reweight edges than the method used in Johnson’s algorithm. Letting <em>w</em>* = min {<em>w</em>(<em>u</em>, <em>v</em>) : (<em>u</em>, <em>v</em>) ∈ <em>E</em>}, just define <em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) = <em>w</em>(<em>u</em>, <em>v</em>) − <em>w</em>* for all edges (<em>u</em>, <em>v</em>) ∈ <em>E</em>. What is wrong with the professor’s method of reweighting?</p>
<p class="level3"><strong><em>23.3-5</em></strong></p>
<p class="noindent">Show that if <em>G</em> contains a 0-weight cycle <em>c</em>, then <em><span class="font1">ŵ</span></em>(<em>u</em>, <em>v</em>) = 0 for every edge (<em>u</em>, <em>v</em>) in <em>c</em>.</p>
<p class="level3"><strong><em>23.3-6</em></strong></p>
<p class="noindent">Professor Michener claims that there is no need to create a new source vertex in line 1 of J<small>OHNSON</small>. He suggests using <em>G</em>′ = <em>G</em> instead and letting <em>s</em> be any vertex. Give an example of a weighted, directed graph <em>G</em> for which incorporating the professor’s idea into J<small>OHNSON</small> causes incorrect answers. Assume that ∞ − ∞ is undefined, and in particular, it is not 0. Then show that if <em>G</em> is strongly connected (every vertex is reachable from every other vertex), the results returned by J<small>OHNSON</small> with the professor’s modification are correct.</p>
</section>
<p class="line1"/>
<section title="Problems">
<p class="level1" id="h1-139"><strong>Problems</strong></p>
<section title="23-1 Transitive closure of a dynamic graph">
<p class="level2"><strong><em>23-1     Transitive closure of a dynamic graph</em></strong></p>
<p class="noindent">You wish to maintain the transitive closure of a directed graph <em>G</em> = (<em>V</em>, <em>E</em>) as you insert edges into <em>E</em>. That is, after inserting an edge, you update the transitive closure of the edges inserted so far. Start with <em>G</em> having no edges initially, and represent the transitive closure by a boolean matrix.</p>
<p class="nl-1list-d"><strong><em>a.</em></strong> Show how to update the transitive closure <em>G</em>* = (<em>V</em>, <em>E</em>*) of a graph <em>G</em> = (<em>V</em>, <em>E</em>) in <em>O</em>(<em>V</em><sup>2</sup>) time when a new edge is added to <em>G</em>.</p>
<p class="nl-1list-d"><strong><em>b.</em></strong> Give an example of a graph <em>G</em> and an edge <em>e</em> such that Ω(<em>V</em><sup>2</sup>) time is required to update the transitive closure after inserting <em>e</em> into <em>G</em>, no matter what algorithm is used.</p>
<a id="p668"/>
<p class="nl-1list-d"><strong><em>c.</em></strong> Give an algorithm for updating the transitive closure as edges are inserted into the graph. For any sequence of <em>r</em> insertions, your algorithm should run in time <img alt="art" src="images/Art_P750.jpg"/>, where <em>t<sub>i</sub></em> is the time to update the transitive closure upon inserting the <em>i</em>th edge. Prove that your algorithm attains this time bound.</p>
</section>
<section title="23-2 Shortest paths in ϵ-dense graphs">
<p class="level2"><strong><em>23-2     Shortest paths in <em><span class="font1">ϵ</span></em>-dense graphs</em></strong></p>
<p class="noindent">A graph <em>G</em> = (<em>V</em>, <em>E</em>) is <span class="blue"><strong><em><span class="font1">ϵ</span>-dense</em></strong></span> if |<em>E</em>| = Θ(<em>V</em><sup>1+<em><span class="font1">ϵ</span></em></sup>) for some constant in the range 0 &lt; <em><span class="font1">ϵ</span></em> ≤ 1. <em>d</em>-ary min-heaps (see Problem 6-2 on page 179) provide a way to match the running times of Fibonacci-heap-based shortest-path algorithms on <em><span class="font1">ϵ</span></em>-dense graphs without using as complicated a data structure.</p>
<p class="nl-1list-d"><strong><em>a.</em></strong> What are the asymptotic running times for the operations I<small>NSERT</small>, E<small>XTRACT</small>-M<small>IN</small>, and D<small>ECREASE</small>-K<small>EY</small>, as a function of <em>d</em> and the number <em>n</em> of elements in a <em>d</em>-ary min-heap? What are these running times if you choose <em>d</em> = Θ(<em>n<sup>π</sup></em>) for some constant 0 &lt; <em>α</em> ≤ 1? Compare these running times to the amortized costs of these operations for a Fibonacci heap.</p>
<p class="nl-1list-d"><strong><em>b.</em></strong> Show how to compute shortest paths from a single source on an <em><span class="font1">ϵ</span></em>-dense directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with no negative-weight edges in <em>O</em>(<em>E</em>) time. (<em>Hint:</em> Pick <em>d</em> as a function of <em><span class="font1">ϵ</span></em>.)</p>
<p class="nl-1list-d"><strong><em>c.</em></strong> Show how to solve the all-pairs shortest-paths problem on an <em><span class="font1">ϵ</span></em>-dense directed graph <em>G</em> = (<em>V</em>, <em>E</em>) with no negative-weight edges in <em>O</em>(<em>VE</em>) time.</p>
<p class="nl-1list-d"><strong><em>d.</em></strong> Show how to solve the all-pairs shortest-paths problem in <em>O</em>(<em>VE</em>) time on an <em><span class="font1">ϵ</span></em>-dense directed graph <em>G</em> = (<em>V</em>, <em>E</em>) that may have negative-weight edges but has no negative-weight cycles.</p>
</section>
</section>
<p class="line1"/>
<section title="Chapter notes">
<p class="level1" id="h1-140"><strong>Chapter notes</strong></p>
<p class="noindent">Lawler [<a epub:type="noteref" href="bibliography001.xhtml#endnote_276">276</a>] has a good discussion of the all-pairs shortest-paths problem. He attributes the matrix-multiplication algorithm to the folklore. The Floyd-Warshall algorithm is due to Floyd [<a epub:type="noteref" href="bibliography001.xhtml#endnote_144">144</a>], who based it on a theorem of Warshall [<a epub:type="noteref" href="bibliography001.xhtml#endnote_450">450</a>] that describes how to compute the transitive closure of boolean matrices. Johnson’s algorithm is taken from [<a epub:type="noteref" href="bibliography001.xhtml#endnote_238">238</a>].</p>
<p>Several researchers have given improved algorithms for computing shortest paths via matrix multiplication. Fredman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_153">153</a>] shows how to solve the all-pairs shortest paths problem using <em>O</em>(<em>V</em><sup>5/2</sup>) comparisons between sums of edge weights and obtains an algorithm that runs in <em>O</em>(<em>V</em><sup>3</sup>lg lg <em>V</em>/lg <em>V</em>/<sup>1/3</sup>) time, which is slightly better than the running time of the Floyd-Warshall algorithm. This bound <a id="p669"/>has been improved several times, and the fastest algorithm is now by Williams [<a epub:type="noteref" href="bibliography001.xhtml#endnote_457">457</a>], with a running time of <img alt="art" src="images/Art_P751.jpg"/>.</p>
<p>Another line of research demonstrates how to apply algorithms for fast matrix multiplication (see the chapter notes for <a href="chapter004.xhtml">Chapter 4</a>) to the all-pairs shortest paths problem. Let <em>O</em>(<em>n</em><sup>ω</sup>) be the running time of the fastest algorithm for multiplying two <em>n</em> × <em>n</em> matrices. Galil and Margalit [<a epub:type="noteref" href="bibliography001.xhtml#endnote_170">170</a>, <a epub:type="noteref" href="bibliography001.xhtml#endnote_171">171</a>] and Seidel [<a epub:type="noteref" href="bibliography001.xhtml#endnote_403">403</a>] designed algorithms that solve the all-pairs shortest paths problem in undirected, unweighted graphs in (<em>V</em><sup>ω</sup><em>p</em>(<em>V</em>)) time, where <em>p</em>(<em>n</em>) denotes a particular function that is polylogarithmically bounded in <em>n</em>. In dense graphs, these algorithms are faster than the <em>O</em>(<em>VE</em>) time needed to perform |<em>V</em>| breadth-first searches. Several researchers have extended these results to give algorithms for solving the all-pairs shortest paths problem in undirected graphs in which the edge weights are integers in the range {1, 2, … , <em>W</em>}. The asymptotically fastest such algorithm, by Shoshan and Zwick [<a epub:type="noteref" href="bibliography001.xhtml#endnote_410">410</a>], runs in <em>O</em>(<em>W V</em><sup>ω</sup><em>p</em>(<em>V W</em>)) time. In directed graphs, the best algorithm to date is due to Zwick [<a epub:type="noteref" href="bibliography001.xhtml#endnote_467">467</a>] and runs in <em>Õ</em>(<em>W</em><sup>1/(4−ω)</sup><em>V</em><sup>2+1/(4−ω)</sup>) time.</p>
<p>Karger, Koller, and Phillips [<a epub:type="noteref" href="bibliography001.xhtml#endnote_244">244</a>] and independently McGeoch [<a epub:type="noteref" href="bibliography001.xhtml#endnote_320">320</a>] have given a time bound that depends on <em>E</em>*, the set of edges in <em>E</em> that participate in some shortest path. Given a graph with nonnegative edge weights, their algorithms run in <em>O</em>(<em>VE</em>* + <em>V</em><sup>2</sup> lg <em>V</em>) time and improve upon running Dijkstra’s algorithm |<em>V</em>| times when |<em>E</em>*| = <em>o</em>(<em>E</em>). Pettie [<a epub:type="noteref" href="bibliography001.xhtml#endnote_355">355</a>] uses an approach based on component hierarchies to achieve a running time of <em>O</em>(<em>VE</em> + <em>V</em><sup>2</sup> lg lg <em>V</em>), and the same running time is also achieved by Hagerup [<a epub:type="noteref" href="bibliography001.xhtml#endnote_205">205</a>].</p>
<p>Baswana, Hariharan, and Sen [<a epub:type="noteref" href="bibliography001.xhtml#endnote_37">37</a>] examined decremental algorithms, which allow a sequence of intermixed edge deletions and queries, for maintaining all-pairs shortest paths and transitive-closure information. When a path exists, their randomized transitive-closure algorithm can fail to report it with probability 1/<em>n<sup>c</sup></em> for an arbitrary <em>c</em> &gt; 0. The query times are <em>O</em>(1) with high probability. For transitive closure, the amortized time for each update is <em>O</em>(<em>V</em><sup>4/3</sup> lg<sup>1/3</sup><em>V</em>). By comparison, Problem 23-1, in which edges are inserted, asks for an incremental algorithm. For all-pairs shortest paths, the update times depend on the queries. For queries just giving the shortest-path weights, the amortized time per update is <em>O</em>(<em>V</em><sup>3</sup>/<em>E</em> lg<sup>2</sup><em>V</em>). To report the actual shortest path, the amortized update time is min <img alt="art" src="images/Art_P752.jpg"/>. Demetrescu and Italiano [<a epub:type="noteref" href="bibliography001.xhtml#endnote_111">111</a>] showed how to handle update and query operations when edges are both inserted and deleted, as long as the range of edge weights is bounded.</p>
<p>Aho, Hopcroft, and Ullman [<a epub:type="noteref" href="bibliography001.xhtml#endnote_5">5</a>] defined an algebraic structure known as a “closed semiring,” which serves as a general framework for solving path problems in directed graphs. Both the Floyd-Warshall algorithm and the transitive-closure algorithm from <a href="chapter023.xhtml#Sec_23.2">Section 23.2</a> are instantiations of an all-pairs algorithm based on closed semirings. Maggs and Plotkin [<a epub:type="noteref" href="bibliography001.xhtml#endnote_309">309</a>] showed how to find minimum spanning trees using a closed semiring.</p>
<p class="footnote" id="footnote_1"><a href="#footnote_ref_1"><sup>1</sup></a> According to a report cited by U.S. Department of Transportation Federal Highway Administration, “a reasonable ‘rule of thumb’ is one signalized intersection per 1,000 population.”</p>
<p class="footnote1" id="footnote_2"><a href="#footnote_ref_2"><sup>2</sup></a> An algebraic <span class="blue"><strong><em>semiring</em></strong></span> contains operations ⊕, which is commutative with identity <em>I</em><sub>⊕</sub>, and ⊕, with identity <em>I</em><sub>⊕</sub>, where ⊕ distributes over ⊕ on both the left and right, and where <em>I</em><sub>⊕</sub>⊕<em>x</em> = <em>x</em>⊕<em>I</em><sub>⊕</sub> = <em>I</em><sub>⊕</sub> for all <em>x</em>. Standard matrix multiplication, as in M<small>ATRIX</small>-M<small>ULTIPLY</small>, uses the semiring with + for ⊕, ⊕ for ⊕, 0 for <em>I</em><sub>⊕</sub>, and 1 for <em>I</em><sub>⊕</sub>. The procedure E<small>XTEND</small>-S<small>HORTEST</small>-P<small>ATHS</small> uses another semiring, known as the <span class="blue"><strong><em>tropical semiring</em></strong></span>, with min for ⊕, + for ⊕, ∞ for <em>I</em><sub>⊕</sub>, and 0 for <em>I</em><sub>⊕</sub>.</p>
</section>
</section>
</div>
</body>
</html>